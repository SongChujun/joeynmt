2020-07-30 02:49:38,718 Hello! This is Joey-NMT.
2020-07-30 02:49:38,724 Total params: 5370241
2020-07-30 02:49:38,725 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder_2.layer_norm.bias', 'encoder_2.layer_norm.weight', 'encoder_2.layers.0.feed_forward.layer_norm.bias', 'encoder_2.layers.0.feed_forward.layer_norm.weight', 'encoder_2.layers.0.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.0.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.0.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.0.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.0.layer_norm.bias', 'encoder_2.layers.0.layer_norm.weight', 'encoder_2.layers.0.src_src_att.k_layer.bias', 'encoder_2.layers.0.src_src_att.k_layer.weight', 'encoder_2.layers.0.src_src_att.output_layer.bias', 'encoder_2.layers.0.src_src_att.output_layer.weight', 'encoder_2.layers.0.src_src_att.q_layer.bias', 'encoder_2.layers.0.src_src_att.q_layer.weight', 'encoder_2.layers.0.src_src_att.v_layer.bias', 'encoder_2.layers.0.src_src_att.v_layer.weight', 'encoder_2.layers.1.feed_forward.layer_norm.bias', 'encoder_2.layers.1.feed_forward.layer_norm.weight', 'encoder_2.layers.1.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.1.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.1.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.1.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.1.layer_norm.bias', 'encoder_2.layers.1.layer_norm.weight', 'encoder_2.layers.1.src_src_att.k_layer.bias', 'encoder_2.layers.1.src_src_att.k_layer.weight', 'encoder_2.layers.1.src_src_att.output_layer.bias', 'encoder_2.layers.1.src_src_att.output_layer.weight', 'encoder_2.layers.1.src_src_att.q_layer.bias', 'encoder_2.layers.1.src_src_att.q_layer.weight', 'encoder_2.layers.1.src_src_att.v_layer.bias', 'encoder_2.layers.1.src_src_att.v_layer.weight', 'encoder_2.layers.2.feed_forward.layer_norm.bias', 'encoder_2.layers.2.feed_forward.layer_norm.weight', 'encoder_2.layers.2.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.2.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.2.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.2.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.2.layer_norm.bias', 'encoder_2.layers.2.layer_norm.weight', 'encoder_2.layers.2.src_src_att.k_layer.bias', 'encoder_2.layers.2.src_src_att.k_layer.weight', 'encoder_2.layers.2.src_src_att.output_layer.bias', 'encoder_2.layers.2.src_src_att.output_layer.weight', 'encoder_2.layers.2.src_src_att.q_layer.bias', 'encoder_2.layers.2.src_src_att.q_layer.weight', 'encoder_2.layers.2.src_src_att.v_layer.bias', 'encoder_2.layers.2.src_src_att.v_layer.weight', 'encoder_2.layers.3.feed_forward.layer_norm.bias', 'encoder_2.layers.3.feed_forward.layer_norm.weight', 'encoder_2.layers.3.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.3.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.3.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.3.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.3.layer_norm.bias', 'encoder_2.layers.3.layer_norm.weight', 'encoder_2.layers.3.src_src_att.k_layer.bias', 'encoder_2.layers.3.src_src_att.k_layer.weight', 'encoder_2.layers.3.src_src_att.output_layer.bias', 'encoder_2.layers.3.src_src_att.output_layer.weight', 'encoder_2.layers.3.src_src_att.q_layer.bias', 'encoder_2.layers.3.src_src_att.q_layer.weight', 'encoder_2.layers.3.src_src_att.v_layer.bias', 'encoder_2.layers.3.src_src_att.v_layer.weight', 'encoder_2.layers.4.feed_forward.layer_norm.bias', 'encoder_2.layers.4.feed_forward.layer_norm.weight', 'encoder_2.layers.4.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.4.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.4.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.4.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.4.layer_norm.bias', 'encoder_2.layers.4.layer_norm.weight', 'encoder_2.layers.4.src_src_att.k_layer.bias', 'encoder_2.layers.4.src_src_att.k_layer.weight', 'encoder_2.layers.4.src_src_att.output_layer.bias', 'encoder_2.layers.4.src_src_att.output_layer.weight', 'encoder_2.layers.4.src_src_att.q_layer.bias', 'encoder_2.layers.4.src_src_att.q_layer.weight', 'encoder_2.layers.4.src_src_att.v_layer.bias', 'encoder_2.layers.4.src_src_att.v_layer.weight', 'encoder_2.layers.5.feed_forward.layer_norm.bias', 'encoder_2.layers.5.feed_forward.layer_norm.weight', 'encoder_2.layers.5.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.5.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.5.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.5.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.5.layer_norm.bias', 'encoder_2.layers.5.layer_norm.weight', 'encoder_2.layers.5.src_src_att.k_layer.bias', 'encoder_2.layers.5.src_src_att.k_layer.weight', 'encoder_2.layers.5.src_src_att.output_layer.bias', 'encoder_2.layers.5.src_src_att.output_layer.weight', 'encoder_2.layers.5.src_src_att.q_layer.bias', 'encoder_2.layers.5.src_src_att.q_layer.weight', 'encoder_2.layers.5.src_src_att.v_layer.bias', 'encoder_2.layers.5.src_src_att.v_layer.weight', 'last_layer.W_g.weight', 'last_layer.b_g', 'last_layer.feed_forward.layer_norm.bias', 'last_layer.feed_forward.layer_norm.weight', 'last_layer.feed_forward.pwff_layer.0.bias', 'last_layer.feed_forward.pwff_layer.0.weight', 'last_layer.feed_forward.pwff_layer.3.bias', 'last_layer.feed_forward.pwff_layer.3.weight', 'last_layer.layer_norm.bias', 'last_layer.layer_norm.weight', 'last_layer.src2_src_att.k_layer.bias', 'last_layer.src2_src_att.k_layer.weight', 'last_layer.src2_src_att.output_layer.bias', 'last_layer.src2_src_att.output_layer.weight', 'last_layer.src2_src_att.q_layer.bias', 'last_layer.src2_src_att.q_layer.weight', 'last_layer.src2_src_att.v_layer.bias', 'last_layer.src2_src_att.v_layer.weight', 'last_layer.src_src_att.k_layer.bias', 'last_layer.src_src_att.k_layer.weight', 'last_layer.src_src_att.output_layer.bias', 'last_layer.src_src_att.output_layer.weight', 'last_layer.src_src_att.q_layer.bias', 'last_layer.src_src_att.q_layer.weight', 'last_layer.src_src_att.v_layer.bias', 'last_layer.src_src_att.v_layer.weight', 'last_layer_norm.bias', 'last_layer_norm.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-07-30 02:49:41,978 cfg.data.dev                       : chatnmt/multi_encoder/dev.tags.bpe.10000
2020-07-30 02:49:41,978 cfg.data.level                     : bpe
2020-07-30 02:49:41,978 cfg.data.lowercase                 : False
2020-07-30 02:49:41,978 cfg.data.max_sent_length           : 100
2020-07-30 02:49:41,978 cfg.data.src                       : en
2020-07-30 02:49:41,978 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-07-30 02:49:41,978 cfg.data.train                     : chatnmt/multi_encoder/train.tags.bpe.10000
2020-07-30 02:49:41,978 cfg.data.trg                       : de
2020-07-30 02:49:41,978 cfg.model.bias_initializer         : zeros
2020-07-30 02:49:41,978 cfg.model.decoder.dropout          : 0.1
2020-07-30 02:49:41,978 cfg.model.decoder.embeddings.dropout : 0.0
2020-07-30 02:49:41,978 cfg.model.decoder.embeddings.embedding_dim : 128
2020-07-30 02:49:41,978 cfg.model.decoder.embeddings.scale : True
2020-07-30 02:49:41,978 cfg.model.decoder.ff_size          : 512
2020-07-30 02:49:41,979 cfg.model.decoder.freeze           : False
2020-07-30 02:49:41,979 cfg.model.decoder.hidden_size      : 128
2020-07-30 02:49:41,979 cfg.model.decoder.num_heads        : 2
2020-07-30 02:49:41,979 cfg.model.decoder.num_layers       : 6
2020-07-30 02:49:41,979 cfg.model.decoder.type             : transformer
2020-07-30 02:49:41,979 cfg.model.embed_init_gain          : 1.0
2020-07-30 02:49:41,979 cfg.model.embed_initializer        : xavier
2020-07-30 02:49:41,979 cfg.model.encoder.dropout          : 0.1
2020-07-30 02:49:41,979 cfg.model.encoder.embeddings.dropout : 0.0
2020-07-30 02:49:41,979 cfg.model.encoder.embeddings.embedding_dim : 128
2020-07-30 02:49:41,979 cfg.model.encoder.embeddings.scale : True
2020-07-30 02:49:41,979 cfg.model.encoder.ff_size          : 512
2020-07-30 02:49:41,979 cfg.model.encoder.freeze           : False
2020-07-30 02:49:41,979 cfg.model.encoder.hidden_size      : 128
2020-07-30 02:49:41,979 cfg.model.encoder.multi_encoder    : True
2020-07-30 02:49:41,979 cfg.model.encoder.num_heads        : 4
2020-07-30 02:49:41,979 cfg.model.encoder.num_layers       : 6
2020-07-30 02:49:41,979 cfg.model.encoder.type             : transformer
2020-07-30 02:49:41,979 cfg.model.init_gain                : 1.0
2020-07-30 02:49:41,979 cfg.model.initializer              : xavier
2020-07-30 02:49:41,979 cfg.model.tied_embeddings          : False
2020-07-30 02:49:41,979 cfg.model.tied_softmax             : True
2020-07-30 02:49:41,979 cfg.name                           : transformer
2020-07-30 02:49:41,979 cfg.testing.alpha                  : 1.0
2020-07-30 02:49:41,979 cfg.testing.beam_size              : 5
2020-07-30 02:49:41,979 cfg.training.adam_betas            : [0.9, 0.999]
2020-07-30 02:49:41,979 cfg.training.batch_multiplier      : 1
2020-07-30 02:49:41,979 cfg.training.batch_size            : 256
2020-07-30 02:49:41,979 cfg.training.batch_type            : token
2020-07-30 02:49:41,980 cfg.training.decrease_factor       : 0.7
2020-07-30 02:49:41,980 cfg.training.early_stopping_metric : ppl
2020-07-30 02:49:41,980 cfg.training.epochs                : 20
2020-07-30 02:49:41,980 cfg.training.eval_metric           : bleu
2020-07-30 02:49:41,980 cfg.training.keep_last_ckpts       : 3
2020-07-30 02:49:41,980 cfg.training.label_smoothing       : 0.1
2020-07-30 02:49:41,980 cfg.training.learning_rate         : 0.0002
2020-07-30 02:49:41,980 cfg.training.learning_rate_min     : 1e-08
2020-07-30 02:49:41,980 cfg.training.logging_freq          : 100
2020-07-30 02:49:41,980 cfg.training.loss                  : crossentropy
2020-07-30 02:49:41,980 cfg.training.max_output_length     : 100
2020-07-30 02:49:41,980 cfg.training.model_dir             : models/viznet/4_2_0.1_128_128_256
2020-07-30 02:49:41,980 cfg.training.normalization         : tokens
2020-07-30 02:49:41,980 cfg.training.optimizer             : adam
2020-07-30 02:49:41,980 cfg.training.overwrite             : True
2020-07-30 02:49:41,980 cfg.training.patience              : 8
2020-07-30 02:49:41,980 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-07-30 02:49:41,980 cfg.training.random_seed           : 42
2020-07-30 02:49:41,980 cfg.training.scheduling            : plateau
2020-07-30 02:49:41,980 cfg.training.shuffle               : True
2020-07-30 02:49:41,980 cfg.training.use_cuda              : True
2020-07-30 02:49:41,980 cfg.training.validation_freq       : 750
2020-07-30 02:49:41,980 cfg.training.weight_decay          : 0.0
2020-07-30 02:49:41,980 Data set sizes: 
	train 10283,
	valid 1602,
	test 1220
2020-07-30 02:49:41,980 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-07-30 02:49:41,980 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-07-30 02:49:41,981 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-07-30 02:49:41,981 Number of Src words (types): 4562
2020-07-30 02:49:41,981 Number of Trg words (types): 5877
2020-07-30 02:49:41,981 Model(
	encoder=TransformerEncoder(num_layers=5, num_heads=4),
	decoder=TransformerDecoder(num_layers=6, num_heads=2),
	src_embed=Embeddings(embedding_dim=128, vocab_size=4562),
	trg_embed=Embeddings(embedding_dim=128, vocab_size=5877))
2020-07-30 02:49:41,986 EPOCH 1
2020-07-30 02:49:51,197 Epoch   1 Step:      100 Batch Loss:     5.743029 Tokens per Sec:     1896, Lr: 0.000200
2020-07-30 02:50:00,064 Epoch   1 Step:      200 Batch Loss:     4.351329 Tokens per Sec:     1995, Lr: 0.000200
2020-07-30 02:50:09,105 Epoch   1 Step:      300 Batch Loss:     2.812205 Tokens per Sec:     1907, Lr: 0.000200
2020-07-30 02:50:18,169 Epoch   1 Step:      400 Batch Loss:     5.191096 Tokens per Sec:     1926, Lr: 0.000200
2020-07-30 02:50:27,115 Epoch   1 Step:      500 Batch Loss:     4.814770 Tokens per Sec:     1963, Lr: 0.000200
2020-07-30 02:50:35,945 Epoch   1 Step:      600 Batch Loss:     3.619043 Tokens per Sec:     1977, Lr: 0.000200
2020-07-30 02:50:45,084 Epoch   1 Step:      700 Batch Loss:     5.864853 Tokens per Sec:     1903, Lr: 0.000200
2020-07-30 02:54:00,192 Hooray! New best validation result [ppl]!
2020-07-30 02:54:00,192 Saving new checkpoint.
2020-07-30 02:54:00,312 Example #0
2020-07-30 02:54:00,312 	Raw source:     ['hello', '.']
2020-07-30 02:54:00,312 	Raw hypothesis: ['ja', '.']
2020-07-30 02:54:00,312 	Source:     hello .
2020-07-30 02:54:00,312 	Reference:  hallo ,
2020-07-30 02:54:00,313 	Hypothesis: ja .
2020-07-30 02:54:00,313 Example #1
2020-07-30 02:54:00,313 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-07-30 02:54:00,313 	Raw hypothesis: ['hallo', ',', 'ich', 'ich', 'ich', 'ihnen', 'helfen', '?']
2020-07-30 02:54:00,313 	Source:     hi , how can i help you ?
2020-07-30 02:54:00,313 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-07-30 02:54:00,313 	Hypothesis: hallo , ich ich ich ihnen helfen ?
2020-07-30 02:54:00,313 Example #2
2020-07-30 02:54:00,313 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-07-30 02:54:00,313 	Raw hypothesis: ['ja', ',', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich', 'ich']
2020-07-30 02:54:00,313 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-07-30 02:54:00,313 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-07-30 02:54:00,313 	Hypothesis: ja , ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich ich
2020-07-30 02:54:00,313 Example #3
2020-07-30 02:54:00,313 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-30 02:54:00,313 	Raw hypothesis: ['hallo', ',', 'ich', 'ich', 'sie', 'sie', 'sie', 'sie', '?']
2020-07-30 02:54:00,313 	Source:     ok , what type of restaurant are you looking for ?
2020-07-30 02:54:00,313 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-07-30 02:54:00,313 	Hypothesis: hallo , ich ich sie sie sie sie ?
2020-07-30 02:54:00,313 Validation result (greedy) at epoch   1, step      750: bleu:   0.33, loss: 95001.3594, ppl:  87.4505, duration: 190.6966s
2020-07-30 02:54:00,412 Epoch   1: total training loss 3721.60
2020-07-30 02:54:00,412 EPOCH 2
2020-07-30 02:54:04,932 Epoch   2 Step:      800 Batch Loss:     3.882852 Tokens per Sec:     1893, Lr: 0.000200
2020-07-30 02:54:13,935 Epoch   2 Step:      900 Batch Loss:     3.859403 Tokens per Sec:     1955, Lr: 0.000200
2020-07-30 02:54:22,725 Epoch   2 Step:     1000 Batch Loss:     5.084410 Tokens per Sec:     2010, Lr: 0.000200
2020-07-30 02:54:31,593 Epoch   2 Step:     1100 Batch Loss:     4.265074 Tokens per Sec:     1962, Lr: 0.000200
2020-07-30 02:54:40,477 Epoch   2 Step:     1200 Batch Loss:     4.043225 Tokens per Sec:     1967, Lr: 0.000200
2020-07-30 02:54:49,356 Epoch   2 Step:     1300 Batch Loss:     2.911884 Tokens per Sec:     1988, Lr: 0.000200
2020-07-30 02:54:58,800 Epoch   2 Step:     1400 Batch Loss:     2.702932 Tokens per Sec:     1831, Lr: 0.000200
2020-07-30 02:55:07,837 Epoch   2 Step:     1500 Batch Loss:     3.641198 Tokens per Sec:     1920, Lr: 0.000200
2020-07-30 02:56:33,066 Hooray! New best validation result [ppl]!
2020-07-30 02:56:33,066 Saving new checkpoint.
2020-07-30 02:56:33,401 Example #0
2020-07-30 02:56:33,401 	Raw source:     ['hello', '.']
2020-07-30 02:56:33,401 	Raw hypothesis: ['hallo', '.']
2020-07-30 02:56:33,401 	Source:     hello .
2020-07-30 02:56:33,401 	Reference:  hallo ,
2020-07-30 02:56:33,401 	Hypothesis: hallo .
2020-07-30 02:56:33,401 Example #1
2020-07-30 02:56:33,401 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-07-30 02:56:33,401 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-07-30 02:56:33,402 	Source:     hi , how can i help you ?
2020-07-30 02:56:33,402 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-07-30 02:56:33,402 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-07-30 02:56:33,402 Example #2
2020-07-30 02:56:33,402 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-07-30 02:56:33,402 	Raw hypothesis: ['ja', ',', 'ich', 'möchte', 'ich', 'möchte', 'einen', 'einen', 'termin', ',', 'ich', 'möchte', 'einen', 'einen', 'pizzen', '.']
2020-07-30 02:56:33,402 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-07-30 02:56:33,402 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-07-30 02:56:33,402 	Hypothesis: ja , ich möchte ich möchte einen einen termin , ich möchte einen einen pizzen .
2020-07-30 02:56:33,402 Example #3
2020-07-30 02:56:33,402 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-30 02:56:33,402 	Raw hypothesis: ['okay', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-07-30 02:56:33,402 	Source:     ok , what type of restaurant are you looking for ?
2020-07-30 02:56:33,402 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-07-30 02:56:33,402 	Hypothesis: okay , wie kann ich ihnen helfen ?
2020-07-30 02:56:33,402 Validation result (greedy) at epoch   2, step     1500: bleu:   4.93, loss: 82711.9375, ppl:  49.0428, duration: 85.5649s
2020-07-30 02:56:33,504 Epoch   2: total training loss 2993.80
2020-07-30 02:56:33,504 EPOCH 3
2020-07-30 02:56:42,429 Epoch   3 Step:     1600 Batch Loss:     3.813852 Tokens per Sec:     1937, Lr: 0.000200
2020-07-30 02:56:51,752 Epoch   3 Step:     1700 Batch Loss:     4.764858 Tokens per Sec:     1871, Lr: 0.000200
2020-07-30 02:57:00,727 Epoch   3 Step:     1800 Batch Loss:     1.921239 Tokens per Sec:     1938, Lr: 0.000200
2020-07-30 02:57:09,960 Epoch   3 Step:     1900 Batch Loss:     5.399199 Tokens per Sec:     1906, Lr: 0.000200
2020-07-30 02:57:19,028 Epoch   3 Step:     2000 Batch Loss:     3.522587 Tokens per Sec:     1903, Lr: 0.000200
2020-07-30 02:57:28,217 Epoch   3 Step:     2100 Batch Loss:     4.053411 Tokens per Sec:     1948, Lr: 0.000200
2020-07-30 02:57:37,278 Epoch   3 Step:     2200 Batch Loss:     2.987964 Tokens per Sec:     1948, Lr: 0.000200
2020-07-30 02:59:20,825 Hooray! New best validation result [ppl]!
2020-07-30 02:59:20,825 Saving new checkpoint.
2020-07-30 02:59:21,252 Example #0
2020-07-30 02:59:21,252 	Raw source:     ['hello', '.']
2020-07-30 02:59:21,252 	Raw hypothesis: ['hallo', '.']
2020-07-30 02:59:21,252 	Source:     hello .
2020-07-30 02:59:21,252 	Reference:  hallo ,
2020-07-30 02:59:21,252 	Hypothesis: hallo .
2020-07-30 02:59:21,252 Example #1
2020-07-30 02:59:21,252 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-07-30 02:59:21,252 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-07-30 02:59:21,252 	Source:     hi , how can i help you ?
2020-07-30 02:59:21,252 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-07-30 02:59:21,252 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-07-30 02:59:21,252 Example #2
2020-07-30 02:59:21,252 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-07-30 02:59:21,252 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'einen', 'moment', ',', 'eine', 'pizzen', 'in', 'der', 'einem', 'pizzen', 'in', 'der', 'einem', 'pizzen', 'in', 'der', 'einem', 'auto', 'in', 'der', 'einem', 'auto', 'in', 'der', 'einem', 'auto', 'imports', '.']
2020-07-30 02:59:21,253 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-07-30 02:59:21,253 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-07-30 02:59:21,253 	Hypothesis: hallo , ich möchte einen moment , eine pizzen in der einem pizzen in der einem pizzen in der einem auto in der einem auto in der einem auto imports .
2020-07-30 02:59:21,253 Example #3
2020-07-30 02:59:21,253 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-30 02:59:21,253 	Raw hypothesis: ['ok', ',', 'und', 'welche', 'art', 'möchten', 'sie', '?']
2020-07-30 02:59:21,253 	Source:     ok , what type of restaurant are you looking for ?
2020-07-30 02:59:21,253 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-07-30 02:59:21,253 	Hypothesis: ok , und welche art möchten sie ?
2020-07-30 02:59:21,253 Validation result (greedy) at epoch   3, step     2250: bleu:   6.26, loss: 73667.1172, ppl:  32.0409, duration: 99.2141s
2020-07-30 02:59:21,347 Epoch   3: total training loss 2578.18
2020-07-30 02:59:21,347 EPOCH 4
2020-07-30 02:59:25,891 Epoch   4 Step:     2300 Batch Loss:     2.201735 Tokens per Sec:     1904, Lr: 0.000200
2020-07-30 02:59:35,098 Epoch   4 Step:     2400 Batch Loss:     2.420239 Tokens per Sec:     1881, Lr: 0.000200
2020-07-30 02:59:44,320 Epoch   4 Step:     2500 Batch Loss:     3.545276 Tokens per Sec:     1876, Lr: 0.000200
2020-07-30 02:59:53,360 Epoch   4 Step:     2600 Batch Loss:     2.696612 Tokens per Sec:     1957, Lr: 0.000200
2020-07-30 03:00:02,818 Epoch   4 Step:     2700 Batch Loss:     2.341918 Tokens per Sec:     1872, Lr: 0.000200
2020-07-30 03:00:11,859 Epoch   4 Step:     2800 Batch Loss:     3.862818 Tokens per Sec:     1925, Lr: 0.000200
2020-07-30 03:00:20,942 Epoch   4 Step:     2900 Batch Loss:     2.293284 Tokens per Sec:     1950, Lr: 0.000200
2020-07-30 03:00:29,798 Epoch   4: total training loss 2274.14
2020-07-30 03:00:29,799 EPOCH 5
2020-07-30 03:00:29,913 Epoch   5 Step:     3000 Batch Loss:     3.635283 Tokens per Sec:     1524, Lr: 0.000200
2020-07-30 03:01:37,393 Hooray! New best validation result [ppl]!
2020-07-30 03:01:37,393 Saving new checkpoint.
2020-07-30 03:01:37,740 Wanted to delete old checkpoint models/viznet/4_2_0.1_128_128_256/750.ckpt but file does not exist.
2020-07-30 03:01:37,741 Example #0
2020-07-30 03:01:37,741 	Raw source:     ['hello', '.']
2020-07-30 03:01:37,741 	Raw hypothesis: ['hallo', '.']
2020-07-30 03:01:37,741 	Source:     hello .
2020-07-30 03:01:37,741 	Reference:  hallo ,
2020-07-30 03:01:37,741 	Hypothesis: hallo .
2020-07-30 03:01:37,741 Example #1
2020-07-30 03:01:37,741 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-07-30 03:01:37,741 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-07-30 03:01:37,741 	Source:     hi , how can i help you ?
2020-07-30 03:01:37,741 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-07-30 03:01:37,741 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-07-30 03:01:37,741 Example #2
2020-07-30 03:01:37,742 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-07-30 03:01:37,742 	Raw hypothesis: ['hallo', ',', 'ich', 'habe', 'einen', 'moment', ',', 'einen', 'moment', ',', 'ich', 'habe', 'ein', 'paar', 'pizzen', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-07-30 03:01:37,742 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-07-30 03:01:37,742 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-07-30 03:01:37,742 	Hypothesis: hallo , ich habe einen moment , einen moment , ich habe ein paar pizzen in san francisco , kalifornien .
2020-07-30 03:01:37,742 Example #3
2020-07-30 03:01:37,742 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-30 03:01:37,742 	Raw hypothesis: ['ok', ',', 'und', 'welche', 'art', 'von', 'essen', 'möchten', 'sie', '?']
2020-07-30 03:01:37,742 	Source:     ok , what type of restaurant are you looking for ?
2020-07-30 03:01:37,742 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-07-30 03:01:37,742 	Hypothesis: ok , und welche art von essen möchten sie ?
2020-07-30 03:01:37,742 Validation result (greedy) at epoch   5, step     3000: bleu:  11.90, loss: 67107.3906, ppl:  23.5304, duration: 67.8280s
2020-07-30 03:01:46,715 Epoch   5 Step:     3100 Batch Loss:     3.625878 Tokens per Sec:     1910, Lr: 0.000200
2020-07-30 03:01:55,720 Epoch   5 Step:     3200 Batch Loss:     3.212014 Tokens per Sec:     2006, Lr: 0.000200
2020-07-30 03:02:04,522 Epoch   5 Step:     3300 Batch Loss:     1.868972 Tokens per Sec:     2013, Lr: 0.000200
2020-07-30 03:02:13,330 Epoch   5 Step:     3400 Batch Loss:     2.085439 Tokens per Sec:     1965, Lr: 0.000200
2020-07-30 03:02:22,234 Epoch   5 Step:     3500 Batch Loss:     1.732816 Tokens per Sec:     1987, Lr: 0.000200
2020-07-30 03:02:31,155 Epoch   5 Step:     3600 Batch Loss:     3.412418 Tokens per Sec:     1946, Lr: 0.000200
2020-07-30 03:02:39,751 Epoch   5 Step:     3700 Batch Loss:     3.219461 Tokens per Sec:     2034, Lr: 0.000200
2020-07-30 03:02:43,973 Epoch   5: total training loss 2047.16
2020-07-30 03:02:43,974 EPOCH 6
2020-07-30 03:03:49,502 Hooray! New best validation result [ppl]!
2020-07-30 03:03:49,502 Saving new checkpoint.
2020-07-30 03:03:49,933 Wanted to delete old checkpoint models/viznet/4_2_0.1_128_128_256/1500.ckpt but file does not exist.
2020-07-30 03:03:49,934 Example #0
2020-07-30 03:03:49,934 	Raw source:     ['hello', '.']
2020-07-30 03:03:49,935 	Raw hypothesis: ['hallo', '.']
2020-07-30 03:03:49,935 	Source:     hello .
2020-07-30 03:03:49,935 	Reference:  hallo ,
2020-07-30 03:03:49,935 	Hypothesis: hallo .
2020-07-30 03:03:49,935 Example #1
2020-07-30 03:03:49,935 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-07-30 03:03:49,935 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-07-30 03:03:49,935 	Source:     hi , how can i help you ?
2020-07-30 03:03:49,935 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-07-30 03:03:49,935 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-07-30 03:03:49,935 Example #2
2020-07-30 03:03:49,935 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-07-30 03:03:49,935 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-07-30 03:03:49,935 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-07-30 03:03:49,935 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-07-30 03:03:49,935 	Hypothesis: hallo , ich möchte ein restaurant in san francisco , kalifornien .
2020-07-30 03:03:49,935 Example #3
2020-07-30 03:03:49,935 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-30 03:03:49,935 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'essen', 'möchten', 'sie', '?']
2020-07-30 03:03:49,935 	Source:     ok , what type of restaurant are you looking for ?
2020-07-30 03:03:49,935 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-07-30 03:03:49,935 	Hypothesis: ok , welche art von essen möchten sie ?
2020-07-30 03:03:49,936 Validation result (greedy) at epoch   6, step     3750: bleu:  15.25, loss: 62379.6914, ppl:  18.8364, duration: 65.7585s
2020-07-30 03:03:54,441 Epoch   6 Step:     3800 Batch Loss:     2.840772 Tokens per Sec:     1921, Lr: 0.000200
2020-07-30 03:04:03,646 Epoch   6 Step:     3900 Batch Loss:     1.641505 Tokens per Sec:     1909, Lr: 0.000200
2020-07-30 03:04:12,987 Epoch   6 Step:     4000 Batch Loss:     1.827862 Tokens per Sec:     1828, Lr: 0.000200
2020-07-30 03:04:22,214 Epoch   6 Step:     4100 Batch Loss:     3.610471 Tokens per Sec:     1911, Lr: 0.000200
2020-07-30 03:04:31,308 Epoch   6 Step:     4200 Batch Loss:     1.420567 Tokens per Sec:     1935, Lr: 0.000200
2020-07-30 03:04:40,507 Epoch   6 Step:     4300 Batch Loss:     1.356777 Tokens per Sec:     1913, Lr: 0.000200
2020-07-30 03:04:49,532 Epoch   6 Step:     4400 Batch Loss:     2.714850 Tokens per Sec:     1962, Lr: 0.000200
2020-07-30 03:04:58,648 Epoch   6: total training loss 1864.52
2020-07-30 03:04:58,649 EPOCH 7
2020-07-30 03:04:58,836 Epoch   7 Step:     4500 Batch Loss:     1.405540 Tokens per Sec:     1770, Lr: 0.000200
2020-07-30 03:06:00,663 Hooray! New best validation result [ppl]!
2020-07-30 03:06:00,663 Saving new checkpoint.
2020-07-30 03:06:01,087 Wanted to delete old checkpoint models/viznet/4_2_0.1_128_128_256/2250.ckpt but file does not exist.
2020-07-30 03:06:01,088 Example #0
2020-07-30 03:06:01,088 	Raw source:     ['hello', '.']
2020-07-30 03:06:01,088 	Raw hypothesis: ['hallo', '.']
2020-07-30 03:06:01,088 	Source:     hello .
2020-07-30 03:06:01,088 	Reference:  hallo ,
2020-07-30 03:06:01,088 	Hypothesis: hallo .
2020-07-30 03:06:01,088 Example #1
2020-07-30 03:06:01,089 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-07-30 03:06:01,089 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-07-30 03:06:01,089 	Source:     hi , how can i help you ?
2020-07-30 03:06:01,089 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-07-30 03:06:01,089 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-07-30 03:06:01,089 Example #2
2020-07-30 03:06:01,089 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-07-30 03:06:01,089 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-07-30 03:06:01,089 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-07-30 03:06:01,089 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-07-30 03:06:01,089 	Hypothesis: hallo , ich möchte ein restaurant in san francisco , kalifornien , kalifornien .
2020-07-30 03:06:01,089 Example #3
2020-07-30 03:06:01,089 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-30 03:06:01,089 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'für', 'sie', '?']
2020-07-30 03:06:01,089 	Source:     ok , what type of restaurant are you looking for ?
2020-07-30 03:06:01,089 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-07-30 03:06:01,089 	Hypothesis: ok , welche art von restaurant für sie ?
2020-07-30 03:06:01,089 Validation result (greedy) at epoch   7, step     4500: bleu:  18.71, loss: 59169.3789, ppl:  16.1950, duration: 62.2529s
2020-07-30 03:06:10,057 Epoch   7 Step:     4600 Batch Loss:     3.351368 Tokens per Sec:     1960, Lr: 0.000200
2020-07-30 03:06:18,932 Epoch   7 Step:     4700 Batch Loss:     2.727649 Tokens per Sec:     1994, Lr: 0.000200
2020-07-30 03:06:27,992 Epoch   7 Step:     4800 Batch Loss:     2.077413 Tokens per Sec:     1931, Lr: 0.000200
2020-07-30 03:06:36,860 Epoch   7 Step:     4900 Batch Loss:     3.515943 Tokens per Sec:     1928, Lr: 0.000200
2020-07-30 03:06:45,909 Epoch   7 Step:     5000 Batch Loss:     3.159066 Tokens per Sec:     1925, Lr: 0.000200
2020-07-30 03:06:55,197 Epoch   7 Step:     5100 Batch Loss:     2.209082 Tokens per Sec:     1875, Lr: 0.000200
2020-07-30 03:07:04,220 Epoch   7 Step:     5200 Batch Loss:     2.053644 Tokens per Sec:     1959, Lr: 0.000200
2020-07-30 03:07:08,587 Epoch   7: total training loss 1712.76
2020-07-30 03:07:08,587 EPOCH 8
2020-07-30 03:08:12,367 Hooray! New best validation result [ppl]!
2020-07-30 03:08:12,368 Saving new checkpoint.
2020-07-30 03:08:12,791 Wanted to delete old checkpoint models/viznet/4_2_0.1_128_128_256/3000.ckpt but file does not exist.
2020-07-30 03:08:12,792 Example #0
2020-07-30 03:08:12,793 	Raw source:     ['hello', '.']
2020-07-30 03:08:12,793 	Raw hypothesis: ['hallo', '.']
2020-07-30 03:08:12,793 	Source:     hello .
2020-07-30 03:08:12,793 	Reference:  hallo ,
2020-07-30 03:08:12,793 	Hypothesis: hallo .
2020-07-30 03:08:12,793 Example #1
2020-07-30 03:08:12,793 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-07-30 03:08:12,793 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-07-30 03:08:12,793 	Source:     hi , how can i help you ?
2020-07-30 03:08:12,793 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-07-30 03:08:12,793 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-07-30 03:08:12,793 Example #2
2020-07-30 03:08:12,793 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-07-30 03:08:12,793 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'nach', 'einem', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-07-30 03:08:12,793 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-07-30 03:08:12,793 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-07-30 03:08:12,793 	Hypothesis: hallo , ich suche nach einem restaurant in san francisco , kalifornien .
2020-07-30 03:08:12,793 Example #3
2020-07-30 03:08:12,793 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-30 03:08:12,793 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'haben', 'sie', '?']
2020-07-30 03:08:12,793 	Source:     ok , what type of restaurant are you looking for ?
2020-07-30 03:08:12,793 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-07-30 03:08:12,793 	Hypothesis: ok , welche art von restaurant haben sie ?
2020-07-30 03:08:12,793 Validation result (greedy) at epoch   8, step     5250: bleu:  20.46, loss: 56848.4531, ppl:  14.5192, duration: 64.0204s
2020-07-30 03:08:17,286 Epoch   8 Step:     5300 Batch Loss:     2.376202 Tokens per Sec:     1926, Lr: 0.000200
2020-07-30 03:08:26,476 Epoch   8 Step:     5400 Batch Loss:     2.840002 Tokens per Sec:     1890, Lr: 0.000200
2020-07-30 03:08:35,252 Epoch   8 Step:     5500 Batch Loss:     2.568111 Tokens per Sec:     1992, Lr: 0.000200
2020-07-30 03:08:44,047 Epoch   8 Step:     5600 Batch Loss:     1.243831 Tokens per Sec:     1968, Lr: 0.000200
2020-07-30 03:08:53,038 Epoch   8 Step:     5700 Batch Loss:     3.501634 Tokens per Sec:     1914, Lr: 0.000200
2020-07-30 03:09:01,706 Epoch   8 Step:     5800 Batch Loss:     1.595326 Tokens per Sec:     2029, Lr: 0.000200
2020-07-30 03:09:10,606 Epoch   8 Step:     5900 Batch Loss:     2.043797 Tokens per Sec:     1954, Lr: 0.000200
