name: "chatnmt-concat-bpe"

data:
    src: "en"
    trg: "de"
    train: "chatnmt/concat/train_concat_prev.tags.bpe.10000"
    dev: "chatnmt/concat/dev_concat_prev.tags.bpe.10000" 
    test: "chatnmt/concat/test_concat_prev.tags.bpe.10000"
    level: "bpe"
    lowercase: True
    max_sent_length: 62
    src_voc_min_freq: 1
    src_voc_limit: 32000
    trg_voc_min_freq: 1
    trg_voc_limit: 32000

testing:
    beam_size: 5
    alpha: 1.0

training:
    optimizer: "adam"
    normalization: "tokens"
    learning_rate: 0.0002
    batch_size: 80
    scheduling: "plateau"
    patience: 8
    #clip_grad_norm: 1.0
    weight_decay: 0.0
    decrease_factor: 0.7
    early_stopping_metric: "loss"
    epochs: 100
    validation_freq: 2000
    logging_freq: 500
    eval_metric: "bleu"
    model_dir: "models/chatnmt_concat"
    overwrite: False
    shuffle: True
    use_cuda: True
    max_output_length: 80
    print_valid_sents: [0, 1, 2, 3, 4]

model:
    encoder:
        rnn_type: "gru"
        embeddings:
            embedding_dim: 620
            scale: False
        hidden_size: 500
        bidirectional: True
        dropout: 0.0
        num_layers: 1
    decoder:
        rnn_type: "gru"
        embeddings:
            embedding_dim: 620
            scale: False
        emb_scale: False
        hidden_size: 1000
        dropout: 0.0
        hidden_dropout: 0.2
        num_layers: 1
        input_feeding: True
        init_hidden: "bridge"
        attention: "bahdanau"
