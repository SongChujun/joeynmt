2020-07-05 16:10:00,516 Hello! This is Joey-NMT.
2020-07-05 16:10:05,964 Total params: 63947777
2020-07-05 16:10:05,965 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder_2.layer_norm.bias', 'encoder_2.layer_norm.weight', 'encoder_2.layers.0.feed_forward.layer_norm.bias', 'encoder_2.layers.0.feed_forward.layer_norm.weight', 'encoder_2.layers.0.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.0.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.0.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.0.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.0.layer_norm.bias', 'encoder_2.layers.0.layer_norm.weight', 'encoder_2.layers.0.src_src_att.k_layer.bias', 'encoder_2.layers.0.src_src_att.k_layer.weight', 'encoder_2.layers.0.src_src_att.output_layer.bias', 'encoder_2.layers.0.src_src_att.output_layer.weight', 'encoder_2.layers.0.src_src_att.q_layer.bias', 'encoder_2.layers.0.src_src_att.q_layer.weight', 'encoder_2.layers.0.src_src_att.v_layer.bias', 'encoder_2.layers.0.src_src_att.v_layer.weight', 'encoder_2.layers.1.feed_forward.layer_norm.bias', 'encoder_2.layers.1.feed_forward.layer_norm.weight', 'encoder_2.layers.1.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.1.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.1.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.1.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.1.layer_norm.bias', 'encoder_2.layers.1.layer_norm.weight', 'encoder_2.layers.1.src_src_att.k_layer.bias', 'encoder_2.layers.1.src_src_att.k_layer.weight', 'encoder_2.layers.1.src_src_att.output_layer.bias', 'encoder_2.layers.1.src_src_att.output_layer.weight', 'encoder_2.layers.1.src_src_att.q_layer.bias', 'encoder_2.layers.1.src_src_att.q_layer.weight', 'encoder_2.layers.1.src_src_att.v_layer.bias', 'encoder_2.layers.1.src_src_att.v_layer.weight', 'encoder_2.layers.2.feed_forward.layer_norm.bias', 'encoder_2.layers.2.feed_forward.layer_norm.weight', 'encoder_2.layers.2.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.2.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.2.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.2.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.2.layer_norm.bias', 'encoder_2.layers.2.layer_norm.weight', 'encoder_2.layers.2.src_src_att.k_layer.bias', 'encoder_2.layers.2.src_src_att.k_layer.weight', 'encoder_2.layers.2.src_src_att.output_layer.bias', 'encoder_2.layers.2.src_src_att.output_layer.weight', 'encoder_2.layers.2.src_src_att.q_layer.bias', 'encoder_2.layers.2.src_src_att.q_layer.weight', 'encoder_2.layers.2.src_src_att.v_layer.bias', 'encoder_2.layers.2.src_src_att.v_layer.weight', 'last_layer.W_g.weight', 'last_layer.b_g', 'last_layer.feed_forward.layer_norm.bias', 'last_layer.feed_forward.layer_norm.weight', 'last_layer.feed_forward.pwff_layer.0.bias', 'last_layer.feed_forward.pwff_layer.0.weight', 'last_layer.feed_forward.pwff_layer.3.bias', 'last_layer.feed_forward.pwff_layer.3.weight', 'last_layer.layer_norm.bias', 'last_layer.layer_norm.weight', 'last_layer.src2_src_att.k_layer.bias', 'last_layer.src2_src_att.k_layer.weight', 'last_layer.src2_src_att.output_layer.bias', 'last_layer.src2_src_att.output_layer.weight', 'last_layer.src2_src_att.q_layer.bias', 'last_layer.src2_src_att.q_layer.weight', 'last_layer.src2_src_att.v_layer.bias', 'last_layer.src2_src_att.v_layer.weight', 'last_layer.src_src_att.k_layer.bias', 'last_layer.src_src_att.k_layer.weight', 'last_layer.src_src_att.output_layer.bias', 'last_layer.src_src_att.output_layer.weight', 'last_layer.src_src_att.q_layer.bias', 'last_layer.src_src_att.q_layer.weight', 'last_layer.src_src_att.v_layer.bias', 'last_layer.src_src_att.v_layer.weight', 'last_layer_norm.bias', 'last_layer_norm.weight', 'src_embed.lut.weight']
2020-07-05 16:10:08,185 cfg.name                           : transformer_multi_enc_ende
2020-07-05 16:10:08,185 cfg.data.src                       : en
2020-07-05 16:10:08,185 cfg.data.trg                       : de
2020-07-05 16:10:08,185 cfg.data.train                     : chatnmt/official_split/wmt17bpe__boundaries/train.tags.bpe.wmt-ende-best
2020-07-05 16:10:08,185 cfg.data.dev                       : chatnmt/official_split/wmt17bpe__boundaries/dev.tags.bpe.wmt-ende-best
2020-07-05 16:10:08,185 cfg.data.test                      : chatnmt/official_split/wmt17bpe__boundaries/test.tags.bpe.wmt-ende-best
2020-07-05 16:10:08,185 cfg.data.level                     : bpe
2020-07-05 16:10:08,185 cfg.data.lowercase                 : False
2020-07-05 16:10:08,185 cfg.data.max_sent_length           : 100
2020-07-05 16:10:08,185 cfg.data.src_vocab                 : models/wmt_ende_transformer/src_vocab.txt
2020-07-05 16:10:08,185 cfg.data.trg_vocab                 : models/wmt_ende_transformer/trg_vocab.txt
2020-07-05 16:10:08,185 cfg.testing.beam_size              : 5
2020-07-05 16:10:08,185 cfg.testing.alpha                  : 1.0
2020-07-05 16:10:08,185 cfg.training.random_seed           : 42
2020-07-05 16:10:08,185 cfg.training.optimizer             : adam
2020-07-05 16:10:08,185 cfg.training.normalization         : tokens
2020-07-05 16:10:08,185 cfg.training.adam_betas            : [0.9, 0.999]
2020-07-05 16:10:08,185 cfg.training.scheduling            : plateau
2020-07-05 16:10:08,185 cfg.training.patience              : 8
2020-07-05 16:10:08,185 cfg.training.decrease_factor       : 0.7
2020-07-05 16:10:08,185 cfg.training.loss                  : crossentropy
2020-07-05 16:10:08,185 cfg.training.learning_rate         : 0.0002
2020-07-05 16:10:08,185 cfg.training.learning_rate_min     : 1e-08
2020-07-05 16:10:08,185 cfg.training.weight_decay          : 0.0
2020-07-05 16:10:08,185 cfg.training.label_smoothing       : 0.1
2020-07-05 16:10:08,185 cfg.training.batch_size            : 2048
2020-07-05 16:10:08,185 cfg.training.batch_type            : token
2020-07-05 16:10:08,185 cfg.training.batch_multiplier      : 1
2020-07-05 16:10:08,185 cfg.training.early_stopping_metric : ppl
2020-07-05 16:10:08,185 cfg.training.epochs                : 50
2020-07-05 16:10:08,186 cfg.training.validation_freq       : 1000
2020-07-05 16:10:08,186 cfg.training.logging_freq          : 100
2020-07-05 16:10:08,186 cfg.training.eval_metric           : bleu
2020-07-05 16:10:08,186 cfg.training.model_dir             : models/wmt20/tfm_menc_b2048_ende/
2020-07-05 16:10:08,186 cfg.training.overwrite             : False
2020-07-05 16:10:08,186 cfg.training.shuffle               : True
2020-07-05 16:10:08,186 cfg.training.use_cuda              : True
2020-07-05 16:10:08,186 cfg.training.max_output_length     : 100
2020-07-05 16:10:08,186 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-07-05 16:10:08,186 cfg.training.keep_last_ckpts       : 3
2020-07-05 16:10:08,186 cfg.model.initializer              : xavier
2020-07-05 16:10:08,186 cfg.model.bias_initializer         : zeros
2020-07-05 16:10:08,186 cfg.model.init_gain                : 1.0
2020-07-05 16:10:08,186 cfg.model.embed_initializer        : xavier
2020-07-05 16:10:08,186 cfg.model.embed_init_gain          : 1.0
2020-07-05 16:10:08,186 cfg.model.tied_embeddings          : True
2020-07-05 16:10:08,186 cfg.model.tied_softmax             : True
2020-07-05 16:10:08,186 cfg.model.encoder.type             : transformer
2020-07-05 16:10:08,186 cfg.model.encoder.num_layers       : 3
2020-07-05 16:10:08,186 cfg.model.encoder.num_heads        : 8
2020-07-05 16:10:08,186 cfg.model.encoder.embeddings.embedding_dim : 512
2020-07-05 16:10:08,186 cfg.model.encoder.embeddings.scale : True
2020-07-05 16:10:08,186 cfg.model.encoder.embeddings.dropout : 0.0
2020-07-05 16:10:08,186 cfg.model.encoder.hidden_size      : 512
2020-07-05 16:10:08,186 cfg.model.encoder.ff_size          : 2048
2020-07-05 16:10:08,186 cfg.model.encoder.dropout          : 0.1
2020-07-05 16:10:08,186 cfg.model.encoder.freeze           : False
2020-07-05 16:10:08,186 cfg.model.encoder.multi_encoder    : True
2020-07-05 16:10:08,186 cfg.model.decoder.type             : transformer
2020-07-05 16:10:08,186 cfg.model.decoder.num_layers       : 6
2020-07-05 16:10:08,186 cfg.model.decoder.num_heads        : 8
2020-07-05 16:10:08,186 cfg.model.decoder.embeddings.embedding_dim : 512
2020-07-05 16:10:08,186 cfg.model.decoder.embeddings.scale : True
2020-07-05 16:10:08,186 cfg.model.decoder.embeddings.dropout : 0.0
2020-07-05 16:10:08,186 cfg.model.decoder.hidden_size      : 512
2020-07-05 16:10:08,186 cfg.model.decoder.ff_size          : 2048
2020-07-05 16:10:08,186 cfg.model.decoder.dropout          : 0.1
2020-07-05 16:10:08,186 cfg.model.decoder.freeze           : False
2020-07-05 16:10:08,186 Data set sizes: 
	train 11488,
	valid 850,
	test 0
2020-07-05 16:10:08,186 First training example:
	[SRC] H@@ i there ! How can I help ?
	[TRG] Hall@@ o ! Wie kann ich helfen ?
2020-07-05 16:10:08,187 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) the (7) in (8) of (9) der
2020-07-05 16:10:08,187 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) the (7) in (8) of (9) der
2020-07-05 16:10:08,187 Number of Src words (types): 36628
2020-07-05 16:10:08,187 Number of Trg words (types): 36628
2020-07-05 16:10:08,187 Model(
	encoder=TransformerEncoder(num_layers=2, num_heads=8),
	decoder=TransformerDecoder(num_layers=6, num_heads=8),
	src_embed=Embeddings(embedding_dim=512, vocab_size=36628),
	trg_embed=Embeddings(embedding_dim=512, vocab_size=36628))
2020-07-05 16:10:08,215 EPOCH 1
2020-07-05 16:10:26,827 Epoch   1 Step:      100 Batch Loss:     3.600308 Tokens per Sec:     6986, Lr: 0.000200
2020-07-05 16:10:32,600 Epoch   1: total training loss 801.96
2020-07-05 16:10:32,600 EPOCH 2
2020-07-05 16:10:44,705 Epoch   2 Step:      200 Batch Loss:     6.130980 Tokens per Sec:     7188, Lr: 0.000200
2020-07-05 16:10:56,025 Epoch   2: total training loss 676.68
2020-07-05 16:10:56,026 EPOCH 3
2020-07-05 16:11:02,111 Epoch   3 Step:      300 Batch Loss:     5.069223 Tokens per Sec:     7559, Lr: 0.000200
2020-07-05 16:11:19,493 Epoch   3: total training loss 622.26
2020-07-05 16:11:19,494 EPOCH 4
2020-07-05 16:11:19,861 Epoch   4 Step:      400 Batch Loss:     4.851006 Tokens per Sec:     5990, Lr: 0.000200
2020-07-05 16:11:37,717 Epoch   4 Step:      500 Batch Loss:     3.910278 Tokens per Sec:     7446, Lr: 0.000200
2020-07-05 16:11:43,091 Epoch   4: total training loss 551.99
2020-07-05 16:11:43,091 EPOCH 5
2020-07-05 16:11:55,835 Epoch   5 Step:      600 Batch Loss:     4.167861 Tokens per Sec:     7273, Lr: 0.000200
2020-07-05 16:12:06,990 Epoch   5: total training loss 496.96
2020-07-05 16:12:06,990 EPOCH 6
2020-07-05 16:12:13,951 Epoch   6 Step:      700 Batch Loss:     2.779180 Tokens per Sec:     7310, Lr: 0.000200
2020-07-05 16:12:31,417 Epoch   6: total training loss 449.78
2020-07-05 16:12:31,417 EPOCH 7
2020-07-05 16:12:32,873 Epoch   7 Step:      800 Batch Loss:     3.536651 Tokens per Sec:     6510, Lr: 0.000200
2020-07-05 16:12:51,298 Epoch   7 Step:      900 Batch Loss:     3.021766 Tokens per Sec:     7097, Lr: 0.000200
2020-07-05 16:12:55,880 Epoch   7: total training loss 414.89
2020-07-05 16:12:55,881 EPOCH 8
2020-07-05 16:13:09,962 Epoch   8 Step:     1000 Batch Loss:     2.071802 Tokens per Sec:     6956, Lr: 0.000200
2020-07-05 16:13:22,507 Hooray! New best validation result [ppl]!
2020-07-05 16:13:22,507 Saving new checkpoint.
2020-07-05 16:13:30,841 Example #0
2020-07-05 16:13:30,841 	Raw source:     ['H@@', 'i', ',', 'how', 'can', 'I', 'help', 'you', '?']
2020-07-05 16:13:30,841 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'Ihnen', 'helfen', '?']
2020-07-05 16:13:30,841 	Source:     Hi , how can I help you ?
2020-07-05 16:13:30,841 	Reference:  Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:13:30,842 	Hypothesis: Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:13:30,842 Example #1
2020-07-05 16:13:30,842 	Raw source:     ['O@@', 'k', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-05 16:13:30,842 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'Ihnen', 'helfen', '?']
2020-07-05 16:13:30,842 	Source:     Ok , what type of restaurant are you looking for ?
2020-07-05 16:13:30,842 	Reference:  Ok . Welche Art von Restaurant suchen Sie denn genau ?
2020-07-05 16:13:30,842 	Hypothesis: Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:13:30,842 Example #2
2020-07-05 16:13:30,842 	Raw source:     ['S@@', 'ure', ',', 'give', 'me', 'a', 'second', ',', 'I', 'will', 'be', 'right', 'back', 'with', 'a', 'couple', 'of', 'options', '.']
2020-07-05 16:13:30,842 	Raw hypothesis: ['Ok@@', 'ay', ',', 'ich', 'habe', 'ein', 'U@@', 'ber', 'X@@', 'L', ',', 'Kalifor@@', 'nien', '.']
2020-07-05 16:13:30,842 	Source:     Sure , give me a second , I will be right back with a couple of options .
2020-07-05 16:13:30,842 	Reference:  Klar , geben Sie mir eine Sekunde , ich bin gleich zurück mit ein paar Optionen .
2020-07-05 16:13:30,842 	Hypothesis: Okay , ich habe ein Uber XL , Kalifornien .
2020-07-05 16:13:30,842 Example #3
2020-07-05 16:13:30,842 	Raw source:     ['I', 'found', ':', 'Se@@', 'as@@', 'ons', '52', ',', 'a', 'Rot@@', 'ating', 'menu', 'of', 'seasonal', 'American', 'dishes', 'alongside', 'International', 'wines', 'in', 'an', 'up@@', 'scale', 'setting', '.', 'I', 'also', 'found', ':', 'P@@', 'lu@@', 'to', "'s", ':', 'a', 'Local', 'counter-@@', 'serve', 'chain', 'featuring', 'buil@@', 'd-@@', 'your@@', '-@@', 'own', 'sal@@', 'ads', '&', 'sand@@', 'wich@@', 'es', 'in', 'a', 'cas@@', 'ual', ',', 'modern', 'setting', '.']
2020-07-05 16:13:30,842 	Raw hypothesis: ['Ich', 'möchte', 'ein', 'paar', 'P@@', 'iz@@', 'zen', ',', 'eine', 'P@@', 'iz@@', 'zen', ',', 'eine', 'P@@', 'izza', ',', 'eine', 'P@@', 'izza', ',', 'eine', 'P@@', 'izza', '.']
2020-07-05 16:13:30,843 	Source:     I found : Seasons 52 , a Rotating menu of seasonal American dishes alongside International wines in an upscale setting . I also found : Pluto 's : a Local counter-serve chain featuring build-your-own salads & sandwiches in a casual , modern setting .
2020-07-05 16:13:30,843 	Reference:  Ich fand : Seasons 52 , ein wechselndes Menü mit saisonalen amerikanischen Gerichten neben internationalen Weinen in einer gehobenen Umgebung . Ich habe auch : Pluto ' s : eine lokale Counter-Service-Kette , die Salate & Sandwiches zum Selbermachen in einem ungezwungenen , modernen Ambiente anbietet , gefunden .
2020-07-05 16:13:30,843 	Hypothesis: Ich möchte ein paar Pizzen , eine Pizzen , eine Pizza , eine Pizza , eine Pizza .
2020-07-05 16:13:30,843 Validation result (greedy) at epoch   8, step     1000: bleu:   6.19, loss: 45384.3633, ppl:  22.8139, duration: 20.8802s
2020-07-05 16:13:41,563 Epoch   8: total training loss 382.20
2020-07-05 16:13:41,564 EPOCH 9
2020-07-05 16:13:49,787 Epoch   9 Step:     1100 Batch Loss:     2.841543 Tokens per Sec:     6418, Lr: 0.000200
2020-07-05 16:14:07,034 Epoch   9: total training loss 360.49
2020-07-05 16:14:07,035 EPOCH 10
2020-07-05 16:14:08,418 Epoch  10 Step:     1200 Batch Loss:     2.787028 Tokens per Sec:     7347, Lr: 0.000200
2020-07-05 16:14:28,432 Epoch  10 Step:     1300 Batch Loss:     1.886821 Tokens per Sec:     6599, Lr: 0.000200
2020-07-05 16:14:32,730 Epoch  10: total training loss 316.61
2020-07-05 16:14:32,730 EPOCH 11
2020-07-05 16:14:46,968 Epoch  11 Step:     1400 Batch Loss:     2.627589 Tokens per Sec:     6879, Lr: 0.000200
2020-07-05 16:14:57,827 Epoch  11: total training loss 299.02
2020-07-05 16:14:57,827 EPOCH 12
2020-07-05 16:15:05,975 Epoch  12 Step:     1500 Batch Loss:     2.095953 Tokens per Sec:     6557, Lr: 0.000200
2020-07-05 16:15:23,027 Epoch  12: total training loss 273.84
2020-07-05 16:15:23,027 EPOCH 13
2020-07-05 16:15:24,653 Epoch  13 Step:     1600 Batch Loss:     0.365742 Tokens per Sec:     5561, Lr: 0.000200
2020-07-05 16:15:44,059 Epoch  13 Step:     1700 Batch Loss:     2.239607 Tokens per Sec:     6701, Lr: 0.000200
2020-07-05 16:15:49,189 Epoch  13: total training loss 245.41
2020-07-05 16:15:49,190 EPOCH 14
2020-07-05 16:16:02,937 Epoch  14 Step:     1800 Batch Loss:     2.047020 Tokens per Sec:     7103, Lr: 0.000200
2020-07-05 16:16:14,700 Epoch  14: total training loss 220.19
2020-07-05 16:16:14,701 EPOCH 15
2020-07-05 16:16:23,131 Epoch  15 Step:     1900 Batch Loss:     1.745508 Tokens per Sec:     6504, Lr: 0.000200
2020-07-05 16:16:41,363 Epoch  15: total training loss 201.88
2020-07-05 16:16:41,363 EPOCH 16
2020-07-05 16:16:43,326 Epoch  16 Step:     2000 Batch Loss:     0.943904 Tokens per Sec:     6753, Lr: 0.000200
2020-07-05 16:17:34,156 Hooray! New best validation result [ppl]!
2020-07-05 16:17:34,157 Saving new checkpoint.
2020-07-05 16:17:42,514 Example #0
2020-07-05 16:17:42,514 	Raw source:     ['H@@', 'i', ',', 'how', 'can', 'I', 'help', 'you', '?']
2020-07-05 16:17:42,514 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'Ihnen', 'helfen', '?']
2020-07-05 16:17:42,514 	Source:     Hi , how can I help you ?
2020-07-05 16:17:42,514 	Reference:  Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:17:42,514 	Hypothesis: Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:17:42,514 Example #1
2020-07-05 16:17:42,514 	Raw source:     ['O@@', 'k', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-05 16:17:42,514 	Raw hypothesis: ['O@@', 'k', ',', 'welche', 'Art', 'von', 'Restaurant', 'suchen', 'Sie', '?']
2020-07-05 16:17:42,514 	Source:     Ok , what type of restaurant are you looking for ?
2020-07-05 16:17:42,515 	Reference:  Ok . Welche Art von Restaurant suchen Sie denn genau ?
2020-07-05 16:17:42,515 	Hypothesis: Ok , welche Art von Restaurant suchen Sie ?
2020-07-05 16:17:42,515 Example #2
2020-07-05 16:17:42,515 	Raw source:     ['S@@', 'ure', ',', 'give', 'me', 'a', 'second', ',', 'I', 'will', 'be', 'right', 'back', 'with', 'a', 'couple', 'of', 'options', '.']
2020-07-05 16:17:42,515 	Raw hypothesis: ['Si@@', 'cher', ',', 'geben', 'Sie', 'mir', 'einen', 'Moment', ',', 'während', 'ich', 'das', 'für', 'Sie', 'suche', '.']
2020-07-05 16:17:42,515 	Source:     Sure , give me a second , I will be right back with a couple of options .
2020-07-05 16:17:42,515 	Reference:  Klar , geben Sie mir eine Sekunde , ich bin gleich zurück mit ein paar Optionen .
2020-07-05 16:17:42,515 	Hypothesis: Sicher , geben Sie mir einen Moment , während ich das für Sie suche .
2020-07-05 16:17:42,515 Example #3
2020-07-05 16:17:42,515 	Raw source:     ['I', 'found', ':', 'Se@@', 'as@@', 'ons', '52', ',', 'a', 'Rot@@', 'ating', 'menu', 'of', 'seasonal', 'American', 'dishes', 'alongside', 'International', 'wines', 'in', 'an', 'up@@', 'scale', 'setting', '.', 'I', 'also', 'found', ':', 'P@@', 'lu@@', 'to', "'s", ':', 'a', 'Local', 'counter-@@', 'serve', 'chain', 'featuring', 'buil@@', 'd-@@', 'your@@', '-@@', 'own', 'sal@@', 'ads', '&', 'sand@@', 'wich@@', 'es', 'in', 'a', 'cas@@', 'ual', ',', 'modern', 'setting', '.']
2020-07-05 16:17:42,515 	Raw hypothesis: ['Ich', 'habe', 'eine', 'Me@@', 'at', 'Lo@@', 'vers', ',', 'die', 'eine', 'andere', 'mit', 'einer', 'umfangreichen', 'Speis@@', 'ek@@', 'arte', 'mit', 'einer', 'umfangreichen', 'Speis@@', 'ek@@', 'arte', 'mit', 'einer', 'umfangreichen', 'Speis@@', 'ek@@', 'arte', 'mit', 'einer', 'Terrasse', ',', 'die', 'zweite', 'heißt', 'Sand@@', 'wich@@', 'es', 'anbietet', '.', 'Ich', 'habe', 'eine', 'andere', 'Option', 'für', 'die', 'zweite', 'heißt', 'Ro@@', 'gue', ',', 'die', 'zweite', 'heißt', 'Ro@@', 'gue', ',', 'die', 'zweite', 'heißt', 'Ro@@', 'gue', '.']
2020-07-05 16:17:42,515 	Source:     I found : Seasons 52 , a Rotating menu of seasonal American dishes alongside International wines in an upscale setting . I also found : Pluto 's : a Local counter-serve chain featuring build-your-own salads & sandwiches in a casual , modern setting .
2020-07-05 16:17:42,515 	Reference:  Ich fand : Seasons 52 , ein wechselndes Menü mit saisonalen amerikanischen Gerichten neben internationalen Weinen in einer gehobenen Umgebung . Ich habe auch : Pluto ' s : eine lokale Counter-Service-Kette , die Salate & Sandwiches zum Selbermachen in einem ungezwungenen , modernen Ambiente anbietet , gefunden .
2020-07-05 16:17:42,515 	Hypothesis: Ich habe eine Meat Lovers , die eine andere mit einer umfangreichen Speisekarte mit einer umfangreichen Speisekarte mit einer umfangreichen Speisekarte mit einer Terrasse , die zweite heißt Sandwiches anbietet . Ich habe eine andere Option für die zweite heißt Rogue , die zweite heißt Rogue , die zweite heißt Rogue .
2020-07-05 16:17:42,515 Validation result (greedy) at epoch  16, step     2000: bleu:  21.95, loss: 30955.2734, ppl:   8.4408, duration: 59.1883s
2020-07-05 16:18:02,482 Epoch  16 Step:     2100 Batch Loss:     1.652024 Tokens per Sec:     6510, Lr: 0.000200
2020-07-05 16:18:06,810 Epoch  16: total training loss 179.64
2020-07-05 16:18:06,810 EPOCH 17
2020-07-05 16:18:22,546 Epoch  17 Step:     2200 Batch Loss:     0.634913 Tokens per Sec:     6557, Lr: 0.000200
2020-07-05 16:18:33,494 Epoch  17: total training loss 161.73
2020-07-05 16:18:33,495 EPOCH 18
2020-07-05 16:18:43,073 Epoch  18 Step:     2300 Batch Loss:     1.713673 Tokens per Sec:     6279, Lr: 0.000200
2020-07-05 16:18:59,724 Epoch  18: total training loss 151.31
2020-07-05 16:18:59,725 EPOCH 19
2020-07-05 16:19:01,996 Epoch  19 Step:     2400 Batch Loss:     0.830300 Tokens per Sec:     7247, Lr: 0.000200
2020-07-05 16:19:22,377 Epoch  19 Step:     2500 Batch Loss:     0.813277 Tokens per Sec:     6340, Lr: 0.000200
2020-07-05 16:19:26,457 Epoch  19: total training loss 138.10
2020-07-05 16:19:26,457 EPOCH 20
2020-07-05 16:19:42,841 Epoch  20 Step:     2600 Batch Loss:     0.534968 Tokens per Sec:     6364, Lr: 0.000200
2020-07-05 16:19:53,209 Epoch  20: total training loss 119.00
2020-07-05 16:19:53,210 EPOCH 21
2020-07-05 16:20:02,772 Epoch  21 Step:     2700 Batch Loss:     0.940473 Tokens per Sec:     6237, Lr: 0.000200
2020-07-05 16:20:19,893 Epoch  21: total training loss 107.33
2020-07-05 16:20:19,893 EPOCH 22
2020-07-05 16:20:22,578 Epoch  22 Step:     2800 Batch Loss:     0.831801 Tokens per Sec:     6837, Lr: 0.000200
2020-07-05 16:20:43,203 Epoch  22 Step:     2900 Batch Loss:     0.706702 Tokens per Sec:     6269, Lr: 0.000200
2020-07-05 16:20:47,030 Epoch  22: total training loss 97.17
2020-07-05 16:20:47,030 EPOCH 23
2020-07-05 16:21:02,249 Epoch  23 Step:     3000 Batch Loss:     0.467733 Tokens per Sec:     6904, Lr: 0.000200
2020-07-05 16:21:41,250 Hooray! New best validation result [ppl]!
2020-07-05 16:21:41,251 Saving new checkpoint.
2020-07-05 16:21:49,691 Example #0
2020-07-05 16:21:49,692 	Raw source:     ['H@@', 'i', ',', 'how', 'can', 'I', 'help', 'you', '?']
2020-07-05 16:21:49,692 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'Ihnen', 'helfen', '?']
2020-07-05 16:21:49,692 	Source:     Hi , how can I help you ?
2020-07-05 16:21:49,692 	Reference:  Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:21:49,692 	Hypothesis: Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:21:49,692 Example #1
2020-07-05 16:21:49,692 	Raw source:     ['O@@', 'k', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-05 16:21:49,692 	Raw hypothesis: ['O@@', 'k', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie', '?']
2020-07-05 16:21:49,692 	Source:     Ok , what type of restaurant are you looking for ?
2020-07-05 16:21:49,692 	Reference:  Ok . Welche Art von Restaurant suchen Sie denn genau ?
2020-07-05 16:21:49,693 	Hypothesis: Ok , nach welcher Art von Restaurant suchen Sie ?
2020-07-05 16:21:49,693 Example #2
2020-07-05 16:21:49,693 	Raw source:     ['S@@', 'ure', ',', 'give', 'me', 'a', 'second', ',', 'I', 'will', 'be', 'right', 'back', 'with', 'a', 'couple', 'of', 'options', '.']
2020-07-05 16:21:49,693 	Raw hypothesis: ['K@@', 'lar', ',', 'geben', 'Sie', 'mir', 'einen', 'Moment', ',', 'während', 'ich', 'das', 'für', 'Sie', 'suche', ',', 'ein', 'paar', 'Optionen', 'für', 'Sie', 'heraus@@', 'suchen', '.']
2020-07-05 16:21:49,693 	Source:     Sure , give me a second , I will be right back with a couple of options .
2020-07-05 16:21:49,693 	Reference:  Klar , geben Sie mir eine Sekunde , ich bin gleich zurück mit ein paar Optionen .
2020-07-05 16:21:49,693 	Hypothesis: Klar , geben Sie mir einen Moment , während ich das für Sie suche , ein paar Optionen für Sie heraussuchen .
2020-07-05 16:21:49,693 Example #3
2020-07-05 16:21:49,693 	Raw source:     ['I', 'found', ':', 'Se@@', 'as@@', 'ons', '52', ',', 'a', 'Rot@@', 'ating', 'menu', 'of', 'seasonal', 'American', 'dishes', 'alongside', 'International', 'wines', 'in', 'an', 'up@@', 'scale', 'setting', '.', 'I', 'also', 'found', ':', 'P@@', 'lu@@', 'to', "'s", ':', 'a', 'Local', 'counter-@@', 'serve', 'chain', 'featuring', 'buil@@', 'd-@@', 'your@@', '-@@', 'own', 'sal@@', 'ads', '&', 'sand@@', 'wich@@', 'es', 'in', 'a', 'cas@@', 'ual', ',', 'modern', 'setting', '.']
2020-07-05 16:21:49,693 	Raw hypothesis: ['Ich', 'habe', 'Frank', 'gefunden', ':', '"', 'Se@@', 'as@@', 'ons', '52', '"', ',', 'eine', 'umfangreiche', 'Wein@@', 'karte', 'im', 'Mittelpunkt', 'dieser', 'Ch@@', 'ill-@@', '"', 'gefunden', ':', 'Ein', 'geho@@', 'ben@@', 'er', 'F@@', 'ish', "'", 's', 'im', 'Erd@@', 'geschoss', 'und', 'im', 'Erd@@', 'geschoss', 'W@@', 'einen', 'ge@@', 'fun@@', 'den@@', '.@@', 'Es', 'tut', 'mir', 'leid', ',', 'das', 'wirklich', 'te@@', '.@@', 'Ich', 'habe', 'auch', 'eine', 'andere', 'amerikanische', 'Küche', ',', 'das', 'Sus@@', 'hi@@', '-B@@', 'ar', ',', 'das', 'eine', 'große', 'Auswahl', 'an', 'einem', 'Mittag@@', 's@@', 'bereitet', '.']
2020-07-05 16:21:49,693 	Source:     I found : Seasons 52 , a Rotating menu of seasonal American dishes alongside International wines in an upscale setting . I also found : Pluto 's : a Local counter-serve chain featuring build-your-own salads & sandwiches in a casual , modern setting .
2020-07-05 16:21:49,693 	Reference:  Ich fand : Seasons 52 , ein wechselndes Menü mit saisonalen amerikanischen Gerichten neben internationalen Weinen in einer gehobenen Umgebung . Ich habe auch : Pluto ' s : eine lokale Counter-Service-Kette , die Salate & Sandwiches zum Selbermachen in einem ungezwungenen , modernen Ambiente anbietet , gefunden .
2020-07-05 16:21:49,693 	Hypothesis: Ich habe Frank gefunden : " Seasons 52 " , eine umfangreiche Weinkarte im Mittelpunkt dieser Chill-" gefunden : Ein gehobener Fish ' s im Erdgeschoss und im Erdgeschoss Weinen gefunden.Es tut mir leid , das wirklich te.Ich habe auch eine andere amerikanische Küche , das Sushi-Bar , das eine große Auswahl an einem Mittagsbereitet .
2020-07-05 16:21:49,693 Validation result (greedy) at epoch  23, step     3000: bleu:  31.03, loss: 27704.0820, ppl:   6.7467, duration: 47.4431s
2020-07-05 16:21:59,402 Epoch  23: total training loss 85.96
2020-07-05 16:21:59,403 EPOCH 24
2020-07-05 16:22:08,654 Epoch  24 Step:     3100 Batch Loss:     0.155755 Tokens per Sec:     6798, Lr: 0.000200
2020-07-05 16:22:24,344 Epoch  24: total training loss 76.33
2020-07-05 16:22:24,345 EPOCH 25
2020-07-05 16:22:27,244 Epoch  25 Step:     3200 Batch Loss:     0.590831 Tokens per Sec:     7423, Lr: 0.000200
2020-07-05 16:22:45,752 Epoch  25 Step:     3300 Batch Loss:     0.601386 Tokens per Sec:     7026, Lr: 0.000200
2020-07-05 16:22:48,789 Epoch  25: total training loss 69.92
2020-07-05 16:22:48,790 EPOCH 26
2020-07-05 16:23:03,317 Epoch  26 Step:     3400 Batch Loss:     0.504863 Tokens per Sec:     7453, Lr: 0.000200
2020-07-05 16:23:12,076 Epoch  26: total training loss 60.37
2020-07-05 16:23:12,077 EPOCH 27
2020-07-05 16:23:21,517 Epoch  27 Step:     3500 Batch Loss:     0.104048 Tokens per Sec:     6874, Lr: 0.000200
2020-07-05 16:23:36,521 Epoch  27: total training loss 56.30
2020-07-05 16:23:36,521 EPOCH 28
2020-07-05 16:23:40,072 Epoch  28 Step:     3600 Batch Loss:     0.301586 Tokens per Sec:     6365, Lr: 0.000200
2020-07-05 16:23:57,980 Epoch  28 Step:     3700 Batch Loss:     0.110442 Tokens per Sec:     7376, Lr: 0.000200
2020-07-05 16:24:00,383 Epoch  28: total training loss 48.50
2020-07-05 16:24:00,383 EPOCH 29
2020-07-05 16:24:16,030 Epoch  29 Step:     3800 Batch Loss:     0.349617 Tokens per Sec:     7211, Lr: 0.000200
2020-07-05 16:24:24,423 Epoch  29: total training loss 45.74
2020-07-05 16:24:24,424 EPOCH 30
2020-07-05 16:24:34,216 Epoch  30 Step:     3900 Batch Loss:     0.309449 Tokens per Sec:     7189, Lr: 0.000200
2020-07-05 16:24:48,356 Epoch  30: total training loss 40.70
2020-07-05 16:24:48,356 EPOCH 31
2020-07-05 16:24:52,099 Epoch  31 Step:     4000 Batch Loss:     0.204429 Tokens per Sec:     7098, Lr: 0.000200
2020-07-05 16:25:20,856 Example #0
2020-07-05 16:25:20,856 	Raw source:     ['H@@', 'i', ',', 'how', 'can', 'I', 'help', 'you', '?']
2020-07-05 16:25:20,856 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'Ihnen', 'helfen', '?']
2020-07-05 16:25:20,856 	Source:     Hi , how can I help you ?
2020-07-05 16:25:20,856 	Reference:  Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:25:20,857 	Hypothesis: Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:25:20,857 Example #1
2020-07-05 16:25:20,857 	Raw source:     ['O@@', 'k', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-05 16:25:20,857 	Raw hypothesis: ['O@@', 'k', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie', '?']
2020-07-05 16:25:20,857 	Source:     Ok , what type of restaurant are you looking for ?
2020-07-05 16:25:20,857 	Reference:  Ok . Welche Art von Restaurant suchen Sie denn genau ?
2020-07-05 16:25:20,857 	Hypothesis: Ok , nach welcher Art von Restaurant suchen Sie ?
2020-07-05 16:25:20,857 Example #2
2020-07-05 16:25:20,857 	Raw source:     ['S@@', 'ure', ',', 'give', 'me', 'a', 'second', ',', 'I', 'will', 'be', 'right', 'back', 'with', 'a', 'couple', 'of', 'options', '.']
2020-07-05 16:25:20,857 	Raw hypothesis: ['K@@', 'lar', ',', 'geben', 'Sie', 'mir', 'einen', 'Moment', ',', 'um', 'das', 'eine', 'Sek@@', 'unde', ',', 'damit', 'ich', 'ein', 'paar', 'Optionen', 'mit', 'einem', 'paar', 'Optionen', 'gefunden', '.']
2020-07-05 16:25:20,857 	Source:     Sure , give me a second , I will be right back with a couple of options .
2020-07-05 16:25:20,857 	Reference:  Klar , geben Sie mir eine Sekunde , ich bin gleich zurück mit ein paar Optionen .
2020-07-05 16:25:20,857 	Hypothesis: Klar , geben Sie mir einen Moment , um das eine Sekunde , damit ich ein paar Optionen mit einem paar Optionen gefunden .
2020-07-05 16:25:20,857 Example #3
2020-07-05 16:25:20,857 	Raw source:     ['I', 'found', ':', 'Se@@', 'as@@', 'ons', '52', ',', 'a', 'Rot@@', 'ating', 'menu', 'of', 'seasonal', 'American', 'dishes', 'alongside', 'International', 'wines', 'in', 'an', 'up@@', 'scale', 'setting', '.', 'I', 'also', 'found', ':', 'P@@', 'lu@@', 'to', "'s", ':', 'a', 'Local', 'counter-@@', 'serve', 'chain', 'featuring', 'buil@@', 'd-@@', 'your@@', '-@@', 'own', 'sal@@', 'ads', '&', 'sand@@', 'wich@@', 'es', 'in', 'a', 'cas@@', 'ual', ',', 'modern', 'setting', '.']
2020-07-05 16:25:20,857 	Raw hypothesis: ['Ich', 'habe', 'folgendes', 'gefunden', ',', 'Se@@', 'as@@', 'ons', '52', ',', 'eine', 'Che@@', 'es@@', 'ec@@', 'ake', 'Fac@@', 'tory', 'in', 'einem', 'form@@', 'ell@@', 'eren', 'Raum', 'mit', 'internationalen', 'K@@', 'ette', '&', 'Spezialitäten', 'mit', 'einer', 'Roh@@', 'kost@@', 'bar', '&', 'ein@@', 'fall@@', 'en.@@', 'Ich', 'habe', 'auch', 'eine', 'Sal@@', 'ate', 'und', 'es', 'stehen', 'im', 'Ober@@', 'geschoss', 'sowie', 'eine', 'umfangreiche', 'Speis@@', 'ek@@', 'arte', '&', 'Bar', '.']
2020-07-05 16:25:20,857 	Source:     I found : Seasons 52 , a Rotating menu of seasonal American dishes alongside International wines in an upscale setting . I also found : Pluto 's : a Local counter-serve chain featuring build-your-own salads & sandwiches in a casual , modern setting .
2020-07-05 16:25:20,857 	Reference:  Ich fand : Seasons 52 , ein wechselndes Menü mit saisonalen amerikanischen Gerichten neben internationalen Weinen in einer gehobenen Umgebung . Ich habe auch : Pluto ' s : eine lokale Counter-Service-Kette , die Salate & Sandwiches zum Selbermachen in einem ungezwungenen , modernen Ambiente anbietet , gefunden .
2020-07-05 16:25:20,857 	Hypothesis: Ich habe folgendes gefunden , Seasons 52 , eine Cheesecake Factory in einem formelleren Raum mit internationalen Kette & Spezialitäten mit einer Rohkostbar & einfallen.Ich habe auch eine Salate und es stehen im Obergeschoss sowie eine umfangreiche Speisekarte & Bar .
2020-07-05 16:25:20,857 Validation result (greedy) at epoch  31, step     4000: bleu:  34.82, loss: 28097.0664, ppl:   6.9318, duration: 28.7577s
2020-07-05 16:25:39,264 Epoch  31 Step:     4100 Batch Loss:     0.309924 Tokens per Sec:     7088, Lr: 0.000200
2020-07-05 16:25:41,346 Epoch  31: total training loss 36.67
2020-07-05 16:25:41,346 EPOCH 32
2020-07-05 16:25:56,910 Epoch  32 Step:     4200 Batch Loss:     0.182471 Tokens per Sec:     7367, Lr: 0.000200
2020-07-05 16:26:04,512 Epoch  32: total training loss 33.98
2020-07-05 16:26:04,513 EPOCH 33
2020-07-05 16:26:13,855 Epoch  33 Step:     4300 Batch Loss:     0.236251 Tokens per Sec:     7802, Lr: 0.000200
2020-07-05 16:26:27,305 Epoch  33: total training loss 31.26
2020-07-05 16:26:27,305 EPOCH 34
2020-07-05 16:26:31,838 Epoch  34 Step:     4400 Batch Loss:     0.204715 Tokens per Sec:     6992, Lr: 0.000200
2020-07-05 16:26:48,806 Epoch  34 Step:     4500 Batch Loss:     0.205512 Tokens per Sec:     7665, Lr: 0.000200
2020-07-05 16:26:49,937 Epoch  34: total training loss 31.12
2020-07-05 16:26:49,938 EPOCH 35
2020-07-05 16:27:05,950 Epoch  35 Step:     4600 Batch Loss:     0.198867 Tokens per Sec:     7512, Lr: 0.000200
2020-07-05 16:27:12,604 Epoch  35: total training loss 28.34
2020-07-05 16:27:12,604 EPOCH 36
2020-07-05 16:27:22,561 Epoch  36 Step:     4700 Batch Loss:     0.196125 Tokens per Sec:     7621, Lr: 0.000200
2020-07-05 16:27:35,388 Epoch  36: total training loss 26.70
2020-07-05 16:27:35,388 EPOCH 37
2020-07-05 16:27:39,876 Epoch  37 Step:     4800 Batch Loss:     0.171136 Tokens per Sec:     7349, Lr: 0.000200
2020-07-05 16:27:56,731 Epoch  37 Step:     4900 Batch Loss:     0.198246 Tokens per Sec:     7656, Lr: 0.000200
2020-07-05 16:27:58,249 Epoch  37: total training loss 25.04
2020-07-05 16:27:58,250 EPOCH 38
2020-07-05 16:28:14,319 Epoch  38 Step:     5000 Batch Loss:     0.215773 Tokens per Sec:     7445, Lr: 0.000200
2020-07-05 16:28:41,247 Example #0
2020-07-05 16:28:41,247 	Raw source:     ['H@@', 'i', ',', 'how', 'can', 'I', 'help', 'you', '?']
2020-07-05 16:28:41,247 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'Ihnen', 'helfen', '?']
2020-07-05 16:28:41,247 	Source:     Hi , how can I help you ?
2020-07-05 16:28:41,247 	Reference:  Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:28:41,247 	Hypothesis: Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:28:41,247 Example #1
2020-07-05 16:28:41,247 	Raw source:     ['O@@', 'k', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-05 16:28:41,247 	Raw hypothesis: ['O@@', 'k', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie', '?']
2020-07-05 16:28:41,247 	Source:     Ok , what type of restaurant are you looking for ?
2020-07-05 16:28:41,247 	Reference:  Ok . Welche Art von Restaurant suchen Sie denn genau ?
2020-07-05 16:28:41,247 	Hypothesis: Ok , nach welcher Art von Restaurant suchen Sie ?
2020-07-05 16:28:41,248 Example #2
2020-07-05 16:28:41,248 	Raw source:     ['S@@', 'ure', ',', 'give', 'me', 'a', 'second', ',', 'I', 'will', 'be', 'right', 'back', 'with', 'a', 'couple', 'of', 'options', '.']
2020-07-05 16:28:41,248 	Raw hypothesis: ['Si@@', 'cher', ',', 'geben', 'Sie', 'mir', 'bitte', 'einen', 'Moment', ',', 'damit', 'ich', 'ein', 'paar', 'Optionen', 'mit', 'einem', 'paar', 'paar', 'Optionen', 'gefunden', 'ist', '.']
2020-07-05 16:28:41,248 	Source:     Sure , give me a second , I will be right back with a couple of options .
2020-07-05 16:28:41,248 	Reference:  Klar , geben Sie mir eine Sekunde , ich bin gleich zurück mit ein paar Optionen .
2020-07-05 16:28:41,248 	Hypothesis: Sicher , geben Sie mir bitte einen Moment , damit ich ein paar Optionen mit einem paar paar Optionen gefunden ist .
2020-07-05 16:28:41,248 Example #3
2020-07-05 16:28:41,248 	Raw source:     ['I', 'found', ':', 'Se@@', 'as@@', 'ons', '52', ',', 'a', 'Rot@@', 'ating', 'menu', 'of', 'seasonal', 'American', 'dishes', 'alongside', 'International', 'wines', 'in', 'an', 'up@@', 'scale', 'setting', '.', 'I', 'also', 'found', ':', 'P@@', 'lu@@', 'to', "'s", ':', 'a', 'Local', 'counter-@@', 'serve', 'chain', 'featuring', 'buil@@', 'd-@@', 'your@@', '-@@', 'own', 'sal@@', 'ads', '&', 'sand@@', 'wich@@', 'es', 'in', 'a', 'cas@@', 'ual', ',', 'modern', 'setting', '.']
2020-07-05 16:28:41,248 	Raw hypothesis: ['Ich', 'fand', 'folgendes', 'gefunden', ',', '"', 'Se@@', 'as@@', 'ons', '52', '"', ',', 'wechsel@@', 'n@@', 'des', 'Menü', 'mit', 'sa@@', 'ison@@', 'alen', ',', 'im', 'oberen', 'Stock@@', 'werk', 'und', 'einer', 'geho@@', 'ben@@', 'em', 'Rahmen', '.', 'Ich', 'habe', 'auch', 'eine', 'sa@@', 'ison@@', 'alen', ',', 'Ma@@', 'de@@', 't@@', 'was', 'auch', 'P@@', 'izza', 'serviert', '.']
2020-07-05 16:28:41,248 	Source:     I found : Seasons 52 , a Rotating menu of seasonal American dishes alongside International wines in an upscale setting . I also found : Pluto 's : a Local counter-serve chain featuring build-your-own salads & sandwiches in a casual , modern setting .
2020-07-05 16:28:41,248 	Reference:  Ich fand : Seasons 52 , ein wechselndes Menü mit saisonalen amerikanischen Gerichten neben internationalen Weinen in einer gehobenen Umgebung . Ich habe auch : Pluto ' s : eine lokale Counter-Service-Kette , die Salate & Sandwiches zum Selbermachen in einem ungezwungenen , modernen Ambiente anbietet , gefunden .
2020-07-05 16:28:41,248 	Hypothesis: Ich fand folgendes gefunden , " Seasons 52 " , wechselndes Menü mit saisonalen , im oberen Stockwerk und einer gehobenem Rahmen . Ich habe auch eine saisonalen , Madetwas auch Pizza serviert .
2020-07-05 16:28:41,248 Validation result (greedy) at epoch  38, step     5000: bleu:  35.53, loss: 28362.2598, ppl:   7.0597, duration: 26.9284s
2020-07-05 16:28:48,139 Epoch  38: total training loss 24.32
2020-07-05 16:28:48,140 EPOCH 39
2020-07-05 16:28:58,423 Epoch  39 Step:     5100 Batch Loss:     0.170113 Tokens per Sec:     7388, Lr: 0.000200
2020-07-05 16:29:10,867 Epoch  39: total training loss 22.67
2020-07-05 16:29:10,868 EPOCH 40
2020-07-05 16:29:15,786 Epoch  40 Step:     5200 Batch Loss:     0.172243 Tokens per Sec:     7025, Lr: 0.000200
2020-07-05 16:29:32,538 Epoch  40 Step:     5300 Batch Loss:     0.178148 Tokens per Sec:     7766, Lr: 0.000200
2020-07-05 16:29:33,749 Epoch  40: total training loss 21.67
2020-07-05 16:29:33,750 EPOCH 41
2020-07-05 16:29:49,917 Epoch  41 Step:     5400 Batch Loss:     0.183873 Tokens per Sec:     7533, Lr: 0.000200
2020-07-05 16:29:56,382 Epoch  41: total training loss 21.91
2020-07-05 16:29:56,382 EPOCH 42
2020-07-05 16:30:06,528 Epoch  42 Step:     5500 Batch Loss:     0.147433 Tokens per Sec:     7853, Lr: 0.000200
2020-07-05 16:30:19,245 Epoch  42: total training loss 21.81
2020-07-05 16:30:19,246 EPOCH 43
2020-07-05 16:30:23,879 Epoch  43 Step:     5600 Batch Loss:     0.175924 Tokens per Sec:     7720, Lr: 0.000200
2020-07-05 16:30:41,248 Epoch  43 Step:     5700 Batch Loss:     0.160624 Tokens per Sec:     7568, Lr: 0.000200
2020-07-05 16:30:42,055 Epoch  43: total training loss 21.84
2020-07-05 16:30:42,055 EPOCH 44
2020-07-05 16:30:58,639 Epoch  44 Step:     5800 Batch Loss:     0.143604 Tokens per Sec:     7436, Lr: 0.000200
2020-07-05 16:31:04,962 Epoch  44: total training loss 19.73
2020-07-05 16:31:04,962 EPOCH 45
2020-07-05 16:31:15,691 Epoch  45 Step:     5900 Batch Loss:     0.142584 Tokens per Sec:     7613, Lr: 0.000200
2020-07-05 16:31:27,752 Epoch  45: total training loss 19.13
2020-07-05 16:31:27,753 EPOCH 46
2020-07-05 16:31:32,684 Epoch  46 Step:     6000 Batch Loss:     0.138232 Tokens per Sec:     8048, Lr: 0.000200
2020-07-05 16:31:56,033 Example #0
2020-07-05 16:31:56,033 	Raw source:     ['H@@', 'i', ',', 'how', 'can', 'I', 'help', 'you', '?']
2020-07-05 16:31:56,033 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'Ihnen', 'helfen', '?']
2020-07-05 16:31:56,033 	Source:     Hi , how can I help you ?
2020-07-05 16:31:56,033 	Reference:  Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:31:56,033 	Hypothesis: Hallo , wie kann ich Ihnen helfen ?
2020-07-05 16:31:56,033 Example #1
2020-07-05 16:31:56,033 	Raw source:     ['O@@', 'k', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-07-05 16:31:56,034 	Raw hypothesis: ['O@@', 'k', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie', '?']
2020-07-05 16:31:56,034 	Source:     Ok , what type of restaurant are you looking for ?
2020-07-05 16:31:56,034 	Reference:  Ok . Welche Art von Restaurant suchen Sie denn genau ?
2020-07-05 16:31:56,034 	Hypothesis: Ok , nach welcher Art von Restaurant suchen Sie ?
2020-07-05 16:31:56,034 Example #2
2020-07-05 16:31:56,034 	Raw source:     ['S@@', 'ure', ',', 'give', 'me', 'a', 'second', ',', 'I', 'will', 'be', 'right', 'back', 'with', 'a', 'couple', 'of', 'options', '.']
2020-07-05 16:31:56,034 	Raw hypothesis: ['Si@@', 'cher', ',', 'geben', 'Sie', 'mir', 'bitte', 'einen', 'Moment', ',', 'damit', 'ich', 'ein', 'paar', 'Optionen', 'mit', 'einer', 'paar', 'Optionen', 'gefunden', 'ist', '.']
2020-07-05 16:31:56,034 	Source:     Sure , give me a second , I will be right back with a couple of options .
2020-07-05 16:31:56,034 	Reference:  Klar , geben Sie mir eine Sekunde , ich bin gleich zurück mit ein paar Optionen .
2020-07-05 16:31:56,034 	Hypothesis: Sicher , geben Sie mir bitte einen Moment , damit ich ein paar Optionen mit einer paar Optionen gefunden ist .
2020-07-05 16:31:56,034 Example #3
2020-07-05 16:31:56,034 	Raw source:     ['I', 'found', ':', 'Se@@', 'as@@', 'ons', '52', ',', 'a', 'Rot@@', 'ating', 'menu', 'of', 'seasonal', 'American', 'dishes', 'alongside', 'International', 'wines', 'in', 'an', 'up@@', 'scale', 'setting', '.', 'I', 'also', 'found', ':', 'P@@', 'lu@@', 'to', "'s", ':', 'a', 'Local', 'counter-@@', 'serve', 'chain', 'featuring', 'buil@@', 'd-@@', 'your@@', '-@@', 'own', 'sal@@', 'ads', '&', 'sand@@', 'wich@@', 'es', 'in', 'a', 'cas@@', 'ual', ',', 'modern', 'setting', '.']
2020-07-05 16:31:56,034 	Raw hypothesis: ['Ich', 'habe', 'folgendes', 'gefunden', ':', '"', 'Se@@', 'as@@', 'ons', '52', '"', ',', 'wechsel@@', 'n@@', 'des', 'Menü', 'mit', 'sa@@', 'ison@@', 'alen', ',', 'im', 'Industri@@', 'al-@@', 'Wur@@', 'st', 'und', 'geho@@', 'ben@@', 'em', 'Rahmen', '.', 'Ich', 'habe', 'auch', 'folgendes', 'gefunden', ':', 'Ein', 'Industri@@', 'al-@@', 'Chi@@', 'cken', '&', 'P@@', 'izza', '.', 'Dies', 'ist', 'ein', 'Industri@@', 'al-@@', 'B@@', 'ac@@', 'on', 'and', 'S@@', 'ush@@', 'i', 'in', 'einer', 'umfangreichen', 'Liste', 'mit', 'traditionellen', 'chinesischen', 'K@@', 'ette', '.']
2020-07-05 16:31:56,034 	Source:     I found : Seasons 52 , a Rotating menu of seasonal American dishes alongside International wines in an upscale setting . I also found : Pluto 's : a Local counter-serve chain featuring build-your-own salads & sandwiches in a casual , modern setting .
2020-07-05 16:31:56,034 	Reference:  Ich fand : Seasons 52 , ein wechselndes Menü mit saisonalen amerikanischen Gerichten neben internationalen Weinen in einer gehobenen Umgebung . Ich habe auch : Pluto ' s : eine lokale Counter-Service-Kette , die Salate & Sandwiches zum Selbermachen in einem ungezwungenen , modernen Ambiente anbietet , gefunden .
2020-07-05 16:31:56,034 	Hypothesis: Ich habe folgendes gefunden : " Seasons 52 " , wechselndes Menü mit saisonalen , im Industrial-Wurst und gehobenem Rahmen . Ich habe auch folgendes gefunden : Ein Industrial-Chicken & Pizza . Dies ist ein Industrial-Bacon and Sushi in einer umfangreichen Liste mit traditionellen chinesischen Kette .
2020-07-05 16:31:56,034 Validation result (greedy) at epoch  46, step     6000: bleu:  37.18, loss: 28875.8066, ppl:   7.3140, duration: 23.3502s
2020-07-05 16:32:13,272 Epoch  46 Step:     6100 Batch Loss:     0.120678 Tokens per Sec:     7541, Lr: 0.000200
2020-07-05 16:32:13,717 Epoch  46: total training loss 17.71
2020-07-05 16:32:13,717 EPOCH 47
2020-07-05 16:32:30,633 Epoch  47 Step:     6200 Batch Loss:     0.132374 Tokens per Sec:     7592, Lr: 0.000200
2020-07-05 16:32:36,404 Epoch  47: total training loss 17.11
2020-07-05 16:32:36,404 EPOCH 48
2020-07-05 16:32:47,767 Epoch  48 Step:     6300 Batch Loss:     0.148494 Tokens per Sec:     7574, Lr: 0.000200
2020-07-05 16:32:59,166 Epoch  48: total training loss 16.59
2020-07-05 16:32:59,167 EPOCH 49
2020-07-05 16:33:04,884 Epoch  49 Step:     6400 Batch Loss:     0.122681 Tokens per Sec:     7744, Lr: 0.000200
2020-07-05 16:33:21,740 Epoch  49: total training loss 16.42
2020-07-05 16:33:21,741 EPOCH 50
2020-07-05 16:33:21,883 Epoch  50 Step:     6500 Batch Loss:     0.116971 Tokens per Sec:    11341, Lr: 0.000200
2020-07-05 16:33:38,963 Epoch  50 Step:     6600 Batch Loss:     0.120197 Tokens per Sec:     7622, Lr: 0.000200
2020-07-05 16:33:44,458 Epoch  50: total training loss 15.77
2020-07-05 16:33:44,458 Training ended after  50 epochs.
2020-07-05 16:33:44,458 Best validation result (greedy) at step     3000:   6.75 ppl.
2020-07-05 16:34:31,422  dev bleu:  35.15 [Beam search decoding with beam size = 5 and alpha = 1.0]
2020-07-05 16:34:31,427 Translations saved to: models/wmt20/tfm_menc_b2048_ende/00003000.hyps.dev
2020-07-05 16:34:31,429 test bleu:  -1.00 [Beam search decoding with beam size = 5 and alpha = 1.0]
2020-07-05 16:34:31,430 Translations saved to: models/wmt20/tfm_menc_b2048_ende/00003000.hyps.test
