2020-07-13 12:21:48,364 Hello! This is Joey-NMT.
2020-07-13 12:21:48,370 Total params: 62894080
2020-07-13 12:21:48,371 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2020-07-13 12:21:51,825 Loading model from models/wmt_ende_transformer/best.ckpt
2020-07-13 12:21:52,325 Reset optimizer.
2020-07-13 12:21:52,325 Reset scheduler.
2020-07-13 12:21:52,325 Reset tracking of the best checkpoint.
2020-07-13 12:21:52,339 cfg.name                           : transformer
2020-07-13 12:21:52,339 cfg.data.src                       : en
2020-07-13 12:21:52,339 cfg.data.trg                       : de
2020-07-13 12:21:52,339 cfg.data.train                     : chatnmt/official_split_line_by_line/wmt17bpe/news_bigrams_line_by_line
2020-07-13 12:21:52,339 cfg.data.dev                       : chatnmt/official_split_line_by_line/wmt17bpe/train.1400.tags.bpe.wmt-ende-best
2020-07-13 12:21:52,339 cfg.data.test                      : chatnmt/official_split/wmt17bpe/test.tags.bpe.wmt-ende-best
2020-07-13 12:21:52,339 cfg.data.level                     : bpe
2020-07-13 12:21:52,339 cfg.data.lowercase                 : False
2020-07-13 12:21:52,339 cfg.data.max_sent_length           : 100
2020-07-13 12:21:52,339 cfg.data.src_vocab                 : models/wmt_ende_transformer/src_vocab.txt
2020-07-13 12:21:52,339 cfg.data.trg_vocab                 : models/wmt_ende_transformer/trg_vocab.txt
2020-07-13 12:21:52,339 cfg.testing.beam_size              : 5
2020-07-13 12:21:52,339 cfg.testing.alpha                  : 1.0
2020-07-13 12:21:52,339 cfg.training.random_seed           : 42
2020-07-13 12:21:52,340 cfg.training.optimizer             : adam
2020-07-13 12:21:52,340 cfg.training.normalization         : tokens
2020-07-13 12:21:52,340 cfg.training.adam_betas            : [0.9, 0.999]
2020-07-13 12:21:52,340 cfg.training.scheduling            : plateau
2020-07-13 12:21:52,340 cfg.training.patience              : 8
2020-07-13 12:21:52,340 cfg.training.decrease_factor       : 0.7
2020-07-13 12:21:52,340 cfg.training.loss                  : crossentropy
2020-07-13 12:21:52,340 cfg.training.learning_rate         : 0.0002
2020-07-13 12:21:52,340 cfg.training.learning_rate_min     : 1e-08
2020-07-13 12:21:52,340 cfg.training.weight_decay          : 0.0
2020-07-13 12:21:52,340 cfg.training.label_smoothing       : 0.1
2020-07-13 12:21:52,340 cfg.training.batch_size            : 2048
2020-07-13 12:21:52,340 cfg.training.batch_type            : token
2020-07-13 12:21:52,340 cfg.training.batch_multiplier      : 1
2020-07-13 12:21:52,340 cfg.training.early_stopping_metric : ppl
2020-07-13 12:21:52,340 cfg.training.epochs                : 80
2020-07-13 12:21:52,340 cfg.training.validation_freq       : 100
2020-07-13 12:21:52,340 cfg.training.logging_freq          : 50
2020-07-13 12:21:52,340 cfg.training.eval_metric           : bleu
2020-07-13 12:21:52,340 cfg.training.model_dir             : models/wmt20/domainadaptation/main_tfm_b2048_ende_news_pretrained_senc/
2020-07-13 12:21:52,340 cfg.training.load_model            : models/wmt_ende_transformer/best.ckpt
2020-07-13 12:21:52,340 cfg.training.reset_best_ckpt       : True
2020-07-13 12:21:52,340 cfg.training.reset_scheduler       : True
2020-07-13 12:21:52,341 cfg.training.reset_optimizer       : True
2020-07-13 12:21:52,341 cfg.training.overwrite             : True
2020-07-13 12:21:52,341 cfg.training.shuffle               : True
2020-07-13 12:21:52,341 cfg.training.use_cuda              : True
2020-07-13 12:21:52,341 cfg.training.max_output_length     : 100
2020-07-13 12:21:52,341 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-07-13 12:21:52,341 cfg.training.keep_last_ckpts       : 3
2020-07-13 12:21:52,341 cfg.model.initializer              : xavier
2020-07-13 12:21:52,341 cfg.model.bias_initializer         : zeros
2020-07-13 12:21:52,341 cfg.model.init_gain                : 1.0
2020-07-13 12:21:52,341 cfg.model.embed_initializer        : xavier
2020-07-13 12:21:52,341 cfg.model.embed_init_gain          : 1.0
2020-07-13 12:21:52,341 cfg.model.tied_embeddings          : True
2020-07-13 12:21:52,341 cfg.model.tied_softmax             : True
2020-07-13 12:21:52,341 cfg.model.encoder.type             : transformer
2020-07-13 12:21:52,341 cfg.model.encoder.num_layers       : 6
2020-07-13 12:21:52,341 cfg.model.encoder.num_heads        : 8
2020-07-13 12:21:52,341 cfg.model.encoder.embeddings.embedding_dim : 512
2020-07-13 12:21:52,341 cfg.model.encoder.embeddings.scale : True
2020-07-13 12:21:52,341 cfg.model.encoder.embeddings.dropout : 0.0
2020-07-13 12:21:52,341 cfg.model.encoder.hidden_size      : 512
2020-07-13 12:21:52,341 cfg.model.encoder.ff_size          : 2048
2020-07-13 12:21:52,341 cfg.model.encoder.freeze           : False
2020-07-13 12:21:52,342 cfg.model.encoder.dropout          : 0.1
2020-07-13 12:21:52,342 cfg.model.decoder.type             : transformer
2020-07-13 12:21:52,342 cfg.model.decoder.num_layers       : 6
2020-07-13 12:21:52,342 cfg.model.decoder.num_heads        : 8
2020-07-13 12:21:52,342 cfg.model.decoder.embeddings.embedding_dim : 512
2020-07-13 12:21:52,342 cfg.model.decoder.embeddings.scale : True
2020-07-13 12:21:52,342 cfg.model.decoder.embeddings.dropout : 0.0
2020-07-13 12:21:52,342 cfg.model.decoder.hidden_size      : 512
2020-07-13 12:21:52,342 cfg.model.decoder.ff_size          : 2048
2020-07-13 12:21:52,342 cfg.model.decoder.freeze           : False
2020-07-13 12:21:52,342 cfg.model.decoder.dropout          : 0.1
2020-07-13 12:21:52,342 Data set sizes: 
	train 1303,
	valid 1400,
	test 0
2020-07-13 12:21:52,342 First training example:
	[SRC] Th@@ ak@@ sin and the L@@ ess@@ ons of Hong Kong
	[TRG] Th@@ ak@@ sin und die Lehren aus Hongkong
2020-07-13 12:21:52,342 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) the (7) in (8) of (9) der
2020-07-13 12:21:52,342 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) the (7) in (8) of (9) der
2020-07-13 12:21:52,342 Number of Src words (types): 36628
2020-07-13 12:21:52,343 Number of Trg words (types): 36628
2020-07-13 12:21:52,343 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=8),
	decoder=TransformerDecoder(num_layers=6, num_heads=8),
	src_embed=Embeddings(embedding_dim=512, vocab_size=36628),
	trg_embed=Embeddings(embedding_dim=512, vocab_size=36628))
2020-07-13 12:21:52,368 EPOCH 1
2020-07-13 12:21:54,868 Epoch   1: total training loss 22.58
2020-07-13 12:21:54,869 EPOCH 2
2020-07-13 12:21:57,262 Epoch   2: total training loss 16.81
2020-07-13 12:21:57,263 EPOCH 3
2020-07-13 12:21:58,343 Epoch   3 Step:  1360050 Batch Loss:     0.484254 Tokens per Sec:    11335, Lr: 0.000200
2020-07-13 12:21:59,651 Epoch   3: total training loss 13.90
2020-07-13 12:21:59,651 EPOCH 4
2020-07-13 12:22:02,048 Epoch   4: total training loss 11.84
2020-07-13 12:22:02,048 EPOCH 5
2020-07-13 12:22:04,327 Epoch   5 Step:  1360100 Batch Loss:     0.440438 Tokens per Sec:    11697, Lr: 0.000200
2020-07-13 12:22:23,038 Hooray! New best validation result [ppl]!
2020-07-13 12:22:23,038 Saving new checkpoint.
2020-07-13 12:22:23,926 Example #0
2020-07-13 12:22:23,926 	Raw source:     ['H@@', 'i', 'there', '!', 'How', 'can', 'I', 'help', '?']
2020-07-13 12:22:23,926 	Raw hypothesis: ['Wie', 'kann', 'ich', 'helfen', '?']
2020-07-13 12:22:23,926 	Source:     Hi there ! How can I help ?
2020-07-13 12:22:23,926 	Reference:  Hallo ! Wie kann ich helfen ?
2020-07-13 12:22:23,926 	Hypothesis: Wie kann ich helfen ?
2020-07-13 12:22:23,926 Example #1
2020-07-13 12:22:23,926 	Raw source:     ['H@@', 'ey', 'there', ',', 'I', 'need', 'to', 'take', 'my', 'car', 'to', 'mechan@@', 'ic', 'and', 'I', 'would', 'like', 'to', 'see', 'Intelli@@', 'gent', 'Auto', 'imports', '.']
2020-07-13 12:22:23,926 	Raw hypothesis: ['Hall@@', 'o', 'dort', ',', 'muss', 'ich', 'mein', 'Auto', 'zum', 'Mechan@@', 'i@@', 'ker', 'nehmen', 'und', 'ich', 'würde', 'gerne', 'Intelli@@', 'gent', 'Auto', 'Im@@', 'porte', 'sehen', '.']
2020-07-13 12:22:23,926 	Source:     Hey there , I need to take my car to mechanic and I would like to see Intelligent Auto imports .
2020-07-13 12:22:23,926 	Reference:  Hey , ich muss mein Auto zum Mechaniker bringen und ich würde gerne Intelligent Auto Imports besuchen .
2020-07-13 12:22:23,926 	Hypothesis: Hallo dort , muss ich mein Auto zum Mechaniker nehmen und ich würde gerne Intelligent Auto Importe sehen .
2020-07-13 12:22:23,926 Example #2
2020-07-13 12:22:23,926 	Raw source:     ['S@@', 'ure', '!', 'what', 'type', 'of', 'car', 'is', 'it', '?']
2020-07-13 12:22:23,926 	Raw hypothesis: ['K@@', 'lar', ',', 'was', 'für', 'ein', 'Auto', 'ist', 'es', '?']
2020-07-13 12:22:23,927 	Source:     Sure ! what type of car is it ?
2020-07-13 12:22:23,927 	Reference:  Sicher ! Was für ein Auto ist das ?
2020-07-13 12:22:23,927 	Hypothesis: Klar , was für ein Auto ist es ?
2020-07-13 12:22:23,927 Example #3
2020-07-13 12:22:23,927 	Raw source:     ['about', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:22:23,927 	Raw hypothesis: ['über', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:22:23,927 	Source:     about 2011 Neason Road .
2020-07-13 12:22:23,927 	Reference:  2011 Neason Road .
2020-07-13 12:22:23,927 	Hypothesis: über 2011 Neason Road .
2020-07-13 12:22:23,927 Validation result (greedy) at epoch   5, step  1360100: bleu:  31.40, loss: 21375.2090, ppl:   3.2433, duration: 19.5990s
2020-07-13 12:22:24,045 Epoch   5: total training loss 10.14
2020-07-13 12:22:24,046 EPOCH 6
2020-07-13 12:22:26,504 Epoch   6: total training loss 9.19
2020-07-13 12:22:26,505 EPOCH 7
2020-07-13 12:22:28,957 Epoch   7: total training loss 7.96
2020-07-13 12:22:28,958 EPOCH 8
2020-07-13 12:22:29,798 Epoch   8 Step:  1360150 Batch Loss:     0.283736 Tokens per Sec:    11321, Lr: 0.000200
2020-07-13 12:22:31,348 Epoch   8: total training loss 6.71
2020-07-13 12:22:31,349 EPOCH 9
2020-07-13 12:22:33,848 Epoch   9: total training loss 6.18
2020-07-13 12:22:33,849 EPOCH 10
2020-07-13 12:22:35,776 Epoch  10 Step:  1360200 Batch Loss:     0.302426 Tokens per Sec:    11651, Lr: 0.000200
2020-07-13 12:22:54,223 Example #0
2020-07-13 12:22:54,224 	Raw source:     ['H@@', 'i', 'there', '!', 'How', 'can', 'I', 'help', '?']
2020-07-13 12:22:54,224 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'helfen', '?']
2020-07-13 12:22:54,224 	Source:     Hi there ! How can I help ?
2020-07-13 12:22:54,224 	Reference:  Hallo ! Wie kann ich helfen ?
2020-07-13 12:22:54,224 	Hypothesis: Hallo , wie kann ich helfen ?
2020-07-13 12:22:54,224 Example #1
2020-07-13 12:22:54,224 	Raw source:     ['H@@', 'ey', 'there', ',', 'I', 'need', 'to', 'take', 'my', 'car', 'to', 'mechan@@', 'ic', 'and', 'I', 'would', 'like', 'to', 'see', 'Intelli@@', 'gent', 'Auto', 'imports', '.']
2020-07-13 12:22:54,224 	Raw hypothesis: ['Hall@@', 'o', 'dort', ',', 'muss', 'ich', 'mein', 'Auto', 'zum', 'Mechan@@', 'i@@', 'ker', 'nehmen', 'und', 'ich', 'würde', 'mir', 'die', 'Im@@', 'porte', 'von', 'Intelli@@', 'gent', 'Auto', 'wünschen', '.']
2020-07-13 12:22:54,224 	Source:     Hey there , I need to take my car to mechanic and I would like to see Intelligent Auto imports .
2020-07-13 12:22:54,224 	Reference:  Hey , ich muss mein Auto zum Mechaniker bringen und ich würde gerne Intelligent Auto Imports besuchen .
2020-07-13 12:22:54,224 	Hypothesis: Hallo dort , muss ich mein Auto zum Mechaniker nehmen und ich würde mir die Importe von Intelligent Auto wünschen .
2020-07-13 12:22:54,224 Example #2
2020-07-13 12:22:54,224 	Raw source:     ['S@@', 'ure', '!', 'what', 'type', 'of', 'car', 'is', 'it', '?']
2020-07-13 12:22:54,224 	Raw hypothesis: ['K@@', 'lar', ',', 'was', 'für', 'ein', 'Auto', 'ist', 'es', '?']
2020-07-13 12:22:54,224 	Source:     Sure ! what type of car is it ?
2020-07-13 12:22:54,224 	Reference:  Sicher ! Was für ein Auto ist das ?
2020-07-13 12:22:54,224 	Hypothesis: Klar , was für ein Auto ist es ?
2020-07-13 12:22:54,224 Example #3
2020-07-13 12:22:54,224 	Raw source:     ['about', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:22:54,225 	Raw hypothesis: ['über', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:22:54,225 	Source:     about 2011 Neason Road .
2020-07-13 12:22:54,225 	Reference:  2011 Neason Road .
2020-07-13 12:22:54,225 	Hypothesis: über 2011 Neason Road .
2020-07-13 12:22:54,225 Validation result (greedy) at epoch  10, step  1360200: bleu:  30.12, loss: 22720.6348, ppl:   3.4926, duration: 18.4476s
2020-07-13 12:22:54,770 Epoch  10: total training loss 5.52
2020-07-13 12:22:54,771 EPOCH 11
2020-07-13 12:22:57,247 Epoch  11: total training loss 4.93
2020-07-13 12:22:57,248 EPOCH 12
2020-07-13 12:22:59,655 Epoch  12: total training loss 4.30
2020-07-13 12:22:59,656 EPOCH 13
2020-07-13 12:23:00,150 Epoch  13 Step:  1360250 Batch Loss:     0.200935 Tokens per Sec:    11811, Lr: 0.000200
2020-07-13 12:23:02,131 Epoch  13: total training loss 4.09
2020-07-13 12:23:02,132 EPOCH 14
2020-07-13 12:23:04,621 Epoch  14: total training loss 3.78
2020-07-13 12:23:04,622 EPOCH 15
2020-07-13 12:23:06,084 Epoch  15 Step:  1360300 Batch Loss:     0.193357 Tokens per Sec:    11406, Lr: 0.000200
2020-07-13 12:23:24,445 Example #0
2020-07-13 12:23:24,445 	Raw source:     ['H@@', 'i', 'there', '!', 'How', 'can', 'I', 'help', '?']
2020-07-13 12:23:24,445 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'helfen', '?']
2020-07-13 12:23:24,445 	Source:     Hi there ! How can I help ?
2020-07-13 12:23:24,445 	Reference:  Hallo ! Wie kann ich helfen ?
2020-07-13 12:23:24,445 	Hypothesis: Hallo , wie kann ich helfen ?
2020-07-13 12:23:24,445 Example #1
2020-07-13 12:23:24,445 	Raw source:     ['H@@', 'ey', 'there', ',', 'I', 'need', 'to', 'take', 'my', 'car', 'to', 'mechan@@', 'ic', 'and', 'I', 'would', 'like', 'to', 'see', 'Intelli@@', 'gent', 'Auto', 'imports', '.']
2020-07-13 12:23:24,445 	Raw hypothesis: ['Hall@@', 'o', 'dort', ',', 'muss', 'ich', 'mein', 'Auto', 'zum', 'Mechan@@', 'i@@', 'ker', 'nehmen', 'und', 'ich', 'würde', 'gerne', 'Intelli@@', 'gent', 'Auto', 'Im@@', 'porte', 'sehen', '.']
2020-07-13 12:23:24,446 	Source:     Hey there , I need to take my car to mechanic and I would like to see Intelligent Auto imports .
2020-07-13 12:23:24,446 	Reference:  Hey , ich muss mein Auto zum Mechaniker bringen und ich würde gerne Intelligent Auto Imports besuchen .
2020-07-13 12:23:24,446 	Hypothesis: Hallo dort , muss ich mein Auto zum Mechaniker nehmen und ich würde gerne Intelligent Auto Importe sehen .
2020-07-13 12:23:24,446 Example #2
2020-07-13 12:23:24,446 	Raw source:     ['S@@', 'ure', '!', 'what', 'type', 'of', 'car', 'is', 'it', '?']
2020-07-13 12:23:24,446 	Raw hypothesis: ['K@@', 'lar', ',', 'was', 'für', 'ein', 'Auto', 'ist', 'es', '?']
2020-07-13 12:23:24,446 	Source:     Sure ! what type of car is it ?
2020-07-13 12:23:24,446 	Reference:  Sicher ! Was für ein Auto ist das ?
2020-07-13 12:23:24,446 	Hypothesis: Klar , was für ein Auto ist es ?
2020-07-13 12:23:24,446 Example #3
2020-07-13 12:23:24,446 	Raw source:     ['about', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:23:24,446 	Raw hypothesis: ['über', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:23:24,446 	Source:     about 2011 Neason Road .
2020-07-13 12:23:24,446 	Reference:  2011 Neason Road .
2020-07-13 12:23:24,446 	Hypothesis: über 2011 Neason Road .
2020-07-13 12:23:24,446 Validation result (greedy) at epoch  15, step  1360300: bleu:  29.01, loss: 23511.2109, ppl:   3.6480, duration: 18.3617s
2020-07-13 12:23:25,485 Epoch  15: total training loss 3.61
2020-07-13 12:23:25,485 EPOCH 16
2020-07-13 12:23:27,902 Epoch  16: total training loss 3.20
2020-07-13 12:23:27,902 EPOCH 17
2020-07-13 12:23:30,374 Epoch  17 Step:  1360350 Batch Loss:     0.104535 Tokens per Sec:    11279, Lr: 0.000200
2020-07-13 12:23:30,374 Epoch  17: total training loss 3.25
2020-07-13 12:23:30,375 EPOCH 18
2020-07-13 12:23:32,839 Epoch  18: total training loss 3.35
2020-07-13 12:23:32,840 EPOCH 19
2020-07-13 12:23:35,313 Epoch  19: total training loss 2.96
2020-07-13 12:23:35,313 EPOCH 20
2020-07-13 12:23:36,274 Epoch  20 Step:  1360400 Batch Loss:     0.154322 Tokens per Sec:    10911, Lr: 0.000200
2020-07-13 12:23:55,957 Example #0
2020-07-13 12:23:55,957 	Raw source:     ['H@@', 'i', 'there', '!', 'How', 'can', 'I', 'help', '?']
2020-07-13 12:23:55,957 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'helfen', '?']
2020-07-13 12:23:55,957 	Source:     Hi there ! How can I help ?
2020-07-13 12:23:55,957 	Reference:  Hallo ! Wie kann ich helfen ?
2020-07-13 12:23:55,957 	Hypothesis: Hallo , wie kann ich helfen ?
2020-07-13 12:23:55,958 Example #1
2020-07-13 12:23:55,958 	Raw source:     ['H@@', 'ey', 'there', ',', 'I', 'need', 'to', 'take', 'my', 'car', 'to', 'mechan@@', 'ic', 'and', 'I', 'would', 'like', 'to', 'see', 'Intelli@@', 'gent', 'Auto', 'imports', '.']
2020-07-13 12:23:55,958 	Raw hypothesis: ['Hall@@', 'o', 'dort', ',', 'muss', 'ich', 'mein', 'Auto', 'zum', 'Mechan@@', 'i@@', 'ker', 'nehmen', 'und', 'ich', 'würde', 'mir', 'gerne', 'Intelli@@', 'gent', 'Auto', 'Im@@', 'porte', 'ansehen', '.']
2020-07-13 12:23:55,958 	Source:     Hey there , I need to take my car to mechanic and I would like to see Intelligent Auto imports .
2020-07-13 12:23:55,958 	Reference:  Hey , ich muss mein Auto zum Mechaniker bringen und ich würde gerne Intelligent Auto Imports besuchen .
2020-07-13 12:23:55,958 	Hypothesis: Hallo dort , muss ich mein Auto zum Mechaniker nehmen und ich würde mir gerne Intelligent Auto Importe ansehen .
2020-07-13 12:23:55,958 Example #2
2020-07-13 12:23:55,958 	Raw source:     ['S@@', 'ure', '!', 'what', 'type', 'of', 'car', 'is', 'it', '?']
2020-07-13 12:23:55,958 	Raw hypothesis: ['K@@', 'lar', ',', 'was', 'für', 'ein', 'Auto', 'ist', 'es', '?']
2020-07-13 12:23:55,958 	Source:     Sure ! what type of car is it ?
2020-07-13 12:23:55,958 	Reference:  Sicher ! Was für ein Auto ist das ?
2020-07-13 12:23:55,958 	Hypothesis: Klar , was für ein Auto ist es ?
2020-07-13 12:23:55,958 Example #3
2020-07-13 12:23:55,958 	Raw source:     ['about', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:23:55,958 	Raw hypothesis: ['über', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:23:55,958 	Source:     about 2011 Neason Road .
2020-07-13 12:23:55,958 	Reference:  2011 Neason Road .
2020-07-13 12:23:55,958 	Hypothesis: über 2011 Neason Road .
2020-07-13 12:23:55,958 Validation result (greedy) at epoch  20, step  1360400: bleu:  28.73, loss: 23952.6211, ppl:   3.7377, duration: 19.6833s
2020-07-13 12:23:57,468 Epoch  20: total training loss 2.81
2020-07-13 12:23:57,469 EPOCH 21
2020-07-13 12:23:59,876 Epoch  21: total training loss 2.51
2020-07-13 12:23:59,877 EPOCH 22
2020-07-13 12:24:01,864 Epoch  22 Step:  1360450 Batch Loss:     0.133106 Tokens per Sec:    11165, Lr: 0.000200
2020-07-13 12:24:02,348 Epoch  22: total training loss 2.57
2020-07-13 12:24:02,348 EPOCH 23
2020-07-13 12:24:04,807 Epoch  23: total training loss 2.48
2020-07-13 12:24:04,808 EPOCH 24
2020-07-13 12:24:07,299 Epoch  24: total training loss 2.34
2020-07-13 12:24:07,300 EPOCH 25
2020-07-13 12:24:07,790 Epoch  25 Step:  1360500 Batch Loss:     0.124163 Tokens per Sec:    11167, Lr: 0.000200
2020-07-13 12:24:27,545 Example #0
2020-07-13 12:24:27,545 	Raw source:     ['H@@', 'i', 'there', '!', 'How', 'can', 'I', 'help', '?']
2020-07-13 12:24:27,545 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'helfen', '?']
2020-07-13 12:24:27,545 	Source:     Hi there ! How can I help ?
2020-07-13 12:24:27,545 	Reference:  Hallo ! Wie kann ich helfen ?
2020-07-13 12:24:27,545 	Hypothesis: Hallo , wie kann ich helfen ?
2020-07-13 12:24:27,545 Example #1
2020-07-13 12:24:27,545 	Raw source:     ['H@@', 'ey', 'there', ',', 'I', 'need', 'to', 'take', 'my', 'car', 'to', 'mechan@@', 'ic', 'and', 'I', 'would', 'like', 'to', 'see', 'Intelli@@', 'gent', 'Auto', 'imports', '.']
2020-07-13 12:24:27,545 	Raw hypothesis: ['Hall@@', 'o', 'dort', ',', 'muss', 'ich', 'mein', 'Auto', 'zum', 'Mechan@@', 'i@@', 'ker', 'nehmen', 'und', 'ich', 'würde', 'mir', 'gerne', 'Intelli@@', 'gent@@', 'es', 'Auto', 'impor@@', 'tieren', '.']
2020-07-13 12:24:27,545 	Source:     Hey there , I need to take my car to mechanic and I would like to see Intelligent Auto imports .
2020-07-13 12:24:27,545 	Reference:  Hey , ich muss mein Auto zum Mechaniker bringen und ich würde gerne Intelligent Auto Imports besuchen .
2020-07-13 12:24:27,545 	Hypothesis: Hallo dort , muss ich mein Auto zum Mechaniker nehmen und ich würde mir gerne Intelligentes Auto importieren .
2020-07-13 12:24:27,545 Example #2
2020-07-13 12:24:27,545 	Raw source:     ['S@@', 'ure', '!', 'what', 'type', 'of', 'car', 'is', 'it', '?']
2020-07-13 12:24:27,545 	Raw hypothesis: ['K@@', 'lar', ',', 'was', 'für', 'ein', 'Auto', 'ist', 'es', '?']
2020-07-13 12:24:27,545 	Source:     Sure ! what type of car is it ?
2020-07-13 12:24:27,546 	Reference:  Sicher ! Was für ein Auto ist das ?
2020-07-13 12:24:27,546 	Hypothesis: Klar , was für ein Auto ist es ?
2020-07-13 12:24:27,546 Example #3
2020-07-13 12:24:27,546 	Raw source:     ['about', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:24:27,546 	Raw hypothesis: ['über', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:24:27,546 	Source:     about 2011 Neason Road .
2020-07-13 12:24:27,546 	Reference:  2011 Neason Road .
2020-07-13 12:24:27,546 	Hypothesis: über 2011 Neason Road .
2020-07-13 12:24:27,546 Validation result (greedy) at epoch  25, step  1360500: bleu:  28.48, loss: 24721.0957, ppl:   3.8992, duration: 19.7547s
2020-07-13 12:24:29,470 Epoch  25: total training loss 2.17
2020-07-13 12:24:29,471 EPOCH 26
2020-07-13 12:24:31,871 Epoch  26: total training loss 2.12
2020-07-13 12:24:31,872 EPOCH 27
2020-07-13 12:24:33,551 Epoch  27 Step:  1360550 Batch Loss:     0.088932 Tokens per Sec:    11106, Lr: 0.000200
2020-07-13 12:24:34,284 Epoch  27: total training loss 2.04
2020-07-13 12:24:34,285 EPOCH 28
2020-07-13 12:24:36,748 Epoch  28: total training loss 2.11
2020-07-13 12:24:36,749 EPOCH 29
2020-07-13 12:24:39,228 Epoch  29: total training loss 2.06
2020-07-13 12:24:39,229 EPOCH 30
2020-07-13 12:24:39,478 Epoch  30 Step:  1360600 Batch Loss:     0.087697 Tokens per Sec:    10831, Lr: 0.000200
2020-07-13 12:24:59,171 Example #0
2020-07-13 12:24:59,171 	Raw source:     ['H@@', 'i', 'there', '!', 'How', 'can', 'I', 'help', '?']
2020-07-13 12:24:59,171 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'helfen', '?']
2020-07-13 12:24:59,171 	Source:     Hi there ! How can I help ?
2020-07-13 12:24:59,171 	Reference:  Hallo ! Wie kann ich helfen ?
2020-07-13 12:24:59,171 	Hypothesis: Hallo , wie kann ich helfen ?
2020-07-13 12:24:59,171 Example #1
2020-07-13 12:24:59,172 	Raw source:     ['H@@', 'ey', 'there', ',', 'I', 'need', 'to', 'take', 'my', 'car', 'to', 'mechan@@', 'ic', 'and', 'I', 'would', 'like', 'to', 'see', 'Intelli@@', 'gent', 'Auto', 'imports', '.']
2020-07-13 12:24:59,172 	Raw hypothesis: ['Hall@@', 'o', 'dort', ',', 'muss', 'ich', 'mein', 'Auto', 'zum', 'Mechan@@', 'i@@', 'ker', 'nehmen', 'und', 'ich', 'würde', 'mir', 'gerne', 'Intelli@@', 'gent@@', 'es', 'Auto', 'impor@@', 'tieren', '.']
2020-07-13 12:24:59,172 	Source:     Hey there , I need to take my car to mechanic and I would like to see Intelligent Auto imports .
2020-07-13 12:24:59,172 	Reference:  Hey , ich muss mein Auto zum Mechaniker bringen und ich würde gerne Intelligent Auto Imports besuchen .
2020-07-13 12:24:59,172 	Hypothesis: Hallo dort , muss ich mein Auto zum Mechaniker nehmen und ich würde mir gerne Intelligentes Auto importieren .
2020-07-13 12:24:59,172 Example #2
2020-07-13 12:24:59,172 	Raw source:     ['S@@', 'ure', '!', 'what', 'type', 'of', 'car', 'is', 'it', '?']
2020-07-13 12:24:59,172 	Raw hypothesis: ['K@@', 'lar', ',', 'was', 'für', 'ein', 'Auto', 'ist', 'es', '?']
2020-07-13 12:24:59,172 	Source:     Sure ! what type of car is it ?
2020-07-13 12:24:59,172 	Reference:  Sicher ! Was für ein Auto ist das ?
2020-07-13 12:24:59,172 	Hypothesis: Klar , was für ein Auto ist es ?
2020-07-13 12:24:59,172 Example #3
2020-07-13 12:24:59,172 	Raw source:     ['about', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:24:59,172 	Raw hypothesis: ['über', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:24:59,172 	Source:     about 2011 Neason Road .
2020-07-13 12:24:59,172 	Reference:  2011 Neason Road .
2020-07-13 12:24:59,172 	Hypothesis: über 2011 Neason Road .
2020-07-13 12:24:59,172 Validation result (greedy) at epoch  30, step  1360600: bleu:  27.43, loss: 25570.8730, ppl:   4.0859, duration: 19.6930s
2020-07-13 12:25:01,387 Epoch  30: total training loss 2.02
2020-07-13 12:25:01,388 EPOCH 31
2020-07-13 12:25:03,865 Epoch  31: total training loss 2.01
2020-07-13 12:25:03,865 EPOCH 32
2020-07-13 12:25:05,059 Epoch  32 Step:  1360650 Batch Loss:     0.085976 Tokens per Sec:    11357, Lr: 0.000200
2020-07-13 12:25:06,266 Epoch  32: total training loss 1.92
2020-07-13 12:25:06,266 EPOCH 33
2020-07-13 12:25:08,657 Epoch  33: total training loss 1.81
2020-07-13 12:25:08,658 EPOCH 34
2020-07-13 12:25:11,066 Epoch  34 Step:  1360700 Batch Loss:     0.087256 Tokens per Sec:    11576, Lr: 0.000200
2020-07-13 12:25:31,426 Example #0
2020-07-13 12:25:31,426 	Raw source:     ['H@@', 'i', 'there', '!', 'How', 'can', 'I', 'help', '?']
2020-07-13 12:25:31,426 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'helfen', '?']
2020-07-13 12:25:31,427 	Source:     Hi there ! How can I help ?
2020-07-13 12:25:31,427 	Reference:  Hallo ! Wie kann ich helfen ?
2020-07-13 12:25:31,427 	Hypothesis: Hallo , wie kann ich helfen ?
2020-07-13 12:25:31,427 Example #1
2020-07-13 12:25:31,427 	Raw source:     ['H@@', 'ey', 'there', ',', 'I', 'need', 'to', 'take', 'my', 'car', 'to', 'mechan@@', 'ic', 'and', 'I', 'would', 'like', 'to', 'see', 'Intelli@@', 'gent', 'Auto', 'imports', '.']
2020-07-13 12:25:31,427 	Raw hypothesis: ['Hall@@', 'o', 'dort', ',', 'muss', 'ich', 'mein', 'Auto', 'zum', 'Mechan@@', 'i@@', 'ker', 'nehmen', 'und', 'ich', 'würde', 'mir', 'gerne', 'Intelli@@', 'gent@@', 'es', 'Auto', 'impor@@', 'tieren', '.']
2020-07-13 12:25:31,427 	Source:     Hey there , I need to take my car to mechanic and I would like to see Intelligent Auto imports .
2020-07-13 12:25:31,427 	Reference:  Hey , ich muss mein Auto zum Mechaniker bringen und ich würde gerne Intelligent Auto Imports besuchen .
2020-07-13 12:25:31,427 	Hypothesis: Hallo dort , muss ich mein Auto zum Mechaniker nehmen und ich würde mir gerne Intelligentes Auto importieren .
2020-07-13 12:25:31,427 Example #2
2020-07-13 12:25:31,427 	Raw source:     ['S@@', 'ure', '!', 'what', 'type', 'of', 'car', 'is', 'it', '?']
2020-07-13 12:25:31,427 	Raw hypothesis: ['K@@', 'lar', ',', 'was', 'für', 'ein', 'Auto', 'ist', 'es', '?']
2020-07-13 12:25:31,427 	Source:     Sure ! what type of car is it ?
2020-07-13 12:25:31,427 	Reference:  Sicher ! Was für ein Auto ist das ?
2020-07-13 12:25:31,427 	Hypothesis: Klar , was für ein Auto ist es ?
2020-07-13 12:25:31,427 Example #3
2020-07-13 12:25:31,427 	Raw source:     ['about', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:25:31,427 	Raw hypothesis: ['über', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:25:31,427 	Source:     about 2011 Neason Road .
2020-07-13 12:25:31,427 	Reference:  2011 Neason Road .
2020-07-13 12:25:31,428 	Hypothesis: über 2011 Neason Road .
2020-07-13 12:25:31,428 Validation result (greedy) at epoch  34, step  1360700: bleu:  26.74, loss: 26402.4004, ppl:   4.2773, duration: 20.3607s
2020-07-13 12:25:31,429 Epoch  34: total training loss 1.76
2020-07-13 12:25:31,429 EPOCH 35
2020-07-13 12:25:33,903 Epoch  35: total training loss 1.82
2020-07-13 12:25:33,904 EPOCH 36
2020-07-13 12:25:36,378 Epoch  36: total training loss 1.81
2020-07-13 12:25:36,379 EPOCH 37
2020-07-13 12:25:37,333 Epoch  37 Step:  1360750 Batch Loss:     0.086379 Tokens per Sec:    11151, Lr: 0.000200
2020-07-13 12:25:38,839 Epoch  37: total training loss 1.75
2020-07-13 12:25:38,839 EPOCH 38
2020-07-13 12:25:41,230 Epoch  38: total training loss 1.63
2020-07-13 12:25:41,231 EPOCH 39
2020-07-13 12:25:43,233 Epoch  39 Step:  1360800 Batch Loss:     0.081912 Tokens per Sec:    11423, Lr: 0.000200
2020-07-13 12:26:02,650 Example #0
2020-07-13 12:26:02,651 	Raw source:     ['H@@', 'i', 'there', '!', 'How', 'can', 'I', 'help', '?']
2020-07-13 12:26:02,651 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'helfen', '?']
2020-07-13 12:26:02,651 	Source:     Hi there ! How can I help ?
2020-07-13 12:26:02,651 	Reference:  Hallo ! Wie kann ich helfen ?
2020-07-13 12:26:02,651 	Hypothesis: Hallo , wie kann ich helfen ?
2020-07-13 12:26:02,651 Example #1
2020-07-13 12:26:02,651 	Raw source:     ['H@@', 'ey', 'there', ',', 'I', 'need', 'to', 'take', 'my', 'car', 'to', 'mechan@@', 'ic', 'and', 'I', 'would', 'like', 'to', 'see', 'Intelli@@', 'gent', 'Auto', 'imports', '.']
2020-07-13 12:26:02,651 	Raw hypothesis: ['Hall@@', 'o', 'dort', ',', 'muss', 'ich', 'mein', 'Auto', 'zum', 'Mechan@@', 'i@@', 'ker', 'nehmen', 'und', 'ich', 'würde', 'mir', 'gerne', 'Intelli@@', 'gent@@', 'es', 'Auto', 'impor@@', 'tieren', '.']
2020-07-13 12:26:02,651 	Source:     Hey there , I need to take my car to mechanic and I would like to see Intelligent Auto imports .
2020-07-13 12:26:02,651 	Reference:  Hey , ich muss mein Auto zum Mechaniker bringen und ich würde gerne Intelligent Auto Imports besuchen .
2020-07-13 12:26:02,651 	Hypothesis: Hallo dort , muss ich mein Auto zum Mechaniker nehmen und ich würde mir gerne Intelligentes Auto importieren .
2020-07-13 12:26:02,651 Example #2
2020-07-13 12:26:02,651 	Raw source:     ['S@@', 'ure', '!', 'what', 'type', 'of', 'car', 'is', 'it', '?']
2020-07-13 12:26:02,651 	Raw hypothesis: ['K@@', 'lar', ',', 'was', 'für', 'ein', 'Auto', 'ist', 'es', '?']
2020-07-13 12:26:02,651 	Source:     Sure ! what type of car is it ?
2020-07-13 12:26:02,651 	Reference:  Sicher ! Was für ein Auto ist das ?
2020-07-13 12:26:02,651 	Hypothesis: Klar , was für ein Auto ist es ?
2020-07-13 12:26:02,651 Example #3
2020-07-13 12:26:02,651 	Raw source:     ['about', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:26:02,652 	Raw hypothesis: ['über', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:26:02,652 	Source:     about 2011 Neason Road .
2020-07-13 12:26:02,652 	Reference:  2011 Neason Road .
2020-07-13 12:26:02,652 	Hypothesis: über 2011 Neason Road .
2020-07-13 12:26:02,652 Validation result (greedy) at epoch  39, step  1360800: bleu:  26.46, loss: 26973.2773, ppl:   4.4138, duration: 19.4175s
2020-07-13 12:26:03,126 Epoch  39: total training loss 1.65
2020-07-13 12:26:03,127 EPOCH 40
2020-07-13 12:26:05,597 Epoch  40: total training loss 1.65
2020-07-13 12:26:05,598 EPOCH 41
2020-07-13 12:26:08,064 Epoch  41: total training loss 1.62
2020-07-13 12:26:08,064 EPOCH 42
2020-07-13 12:26:08,548 Epoch  42 Step:  1360850 Batch Loss:     0.069221 Tokens per Sec:    11039, Lr: 0.000200
2020-07-13 12:26:10,543 Epoch  42: total training loss 1.60
2020-07-13 12:26:10,544 EPOCH 43
2020-07-13 12:26:13,024 Epoch  43: total training loss 1.57
2020-07-13 12:26:13,025 EPOCH 44
2020-07-13 12:26:14,423 Epoch  44 Step:  1360900 Batch Loss:     0.075543 Tokens per Sec:    10948, Lr: 0.000200
2020-07-13 12:26:34,739 Example #0
2020-07-13 12:26:34,740 	Raw source:     ['H@@', 'i', 'there', '!', 'How', 'can', 'I', 'help', '?']
2020-07-13 12:26:34,740 	Raw hypothesis: ['Hall@@', 'o', ',', 'wie', 'kann', 'ich', 'helfen', '?']
2020-07-13 12:26:34,740 	Source:     Hi there ! How can I help ?
2020-07-13 12:26:34,740 	Reference:  Hallo ! Wie kann ich helfen ?
2020-07-13 12:26:34,740 	Hypothesis: Hallo , wie kann ich helfen ?
2020-07-13 12:26:34,740 Example #1
2020-07-13 12:26:34,740 	Raw source:     ['H@@', 'ey', 'there', ',', 'I', 'need', 'to', 'take', 'my', 'car', 'to', 'mechan@@', 'ic', 'and', 'I', 'would', 'like', 'to', 'see', 'Intelli@@', 'gent', 'Auto', 'imports', '.']
2020-07-13 12:26:34,740 	Raw hypothesis: ['Hall@@', 'o', 'dort', ',', 'muss', 'ich', 'mein', 'Auto', 'zum', 'Mechan@@', 'i@@', 'ker', 'nehmen', 'und', 'ich', 'würde', 'mir', 'gerne', 'Intelli@@', 'gent@@', 'es', 'Auto', 'impor@@', 'tieren', '.']
2020-07-13 12:26:34,740 	Source:     Hey there , I need to take my car to mechanic and I would like to see Intelligent Auto imports .
2020-07-13 12:26:34,740 	Reference:  Hey , ich muss mein Auto zum Mechaniker bringen und ich würde gerne Intelligent Auto Imports besuchen .
2020-07-13 12:26:34,740 	Hypothesis: Hallo dort , muss ich mein Auto zum Mechaniker nehmen und ich würde mir gerne Intelligentes Auto importieren .
2020-07-13 12:26:34,740 Example #2
2020-07-13 12:26:34,740 	Raw source:     ['S@@', 'ure', '!', 'what', 'type', 'of', 'car', 'is', 'it', '?']
2020-07-13 12:26:34,740 	Raw hypothesis: ['K@@', 'lar', ',', 'welche', 'Art', 'von', 'Autos', 'ist', 'es', '?']
2020-07-13 12:26:34,740 	Source:     Sure ! what type of car is it ?
2020-07-13 12:26:34,740 	Reference:  Sicher ! Was für ein Auto ist das ?
2020-07-13 12:26:34,740 	Hypothesis: Klar , welche Art von Autos ist es ?
2020-07-13 12:26:34,740 Example #3
2020-07-13 12:26:34,741 	Raw source:     ['about', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:26:34,741 	Raw hypothesis: ['über', '2011', 'Ne@@', 'as@@', 'on', 'Road', '.']
2020-07-13 12:26:34,741 	Source:     about 2011 Neason Road .
2020-07-13 12:26:34,741 	Reference:  2011 Neason Road .
2020-07-13 12:26:34,741 	Hypothesis: über 2011 Neason Road .
2020-07-13 12:26:34,741 Validation result (greedy) at epoch  44, step  1360900: bleu:  25.30, loss: 27780.3203, ppl:   4.6143, duration: 20.3169s
2020-07-13 12:26:35,817 Epoch  44: total training loss 1.57
2020-07-13 12:26:35,818 EPOCH 45
2020-07-13 12:26:38,290 Epoch  45: total training loss 1.57
2020-07-13 12:26:38,291 EPOCH 46
2020-07-13 12:26:40,645 Epoch  46 Step:  1360950 Batch Loss:     0.064315 Tokens per Sec:    11342, Lr: 0.000200
2020-07-13 12:26:40,762 Epoch  46: total training loss 1.51
2020-07-13 12:26:40,763 EPOCH 47
2020-07-13 12:26:43,235 Epoch  47: total training loss 1.48
2020-07-13 12:26:43,236 EPOCH 48
2020-07-13 12:26:45,629 Epoch  48: total training loss 1.39
2020-07-13 12:26:45,630 EPOCH 49
2020-07-13 12:26:46,593 Epoch  49 Step:  1361000 Batch Loss:     0.060164 Tokens per Sec:    11373, Lr: 0.000200
