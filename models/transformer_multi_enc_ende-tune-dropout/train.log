2020-06-30 05:02:47,102 Hello! This is Joey-NMT.
2020-06-30 05:02:51,385 Total params: 82862081
2020-06-30 05:02:51,389 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder_2.layer_norm.bias', 'encoder_2.layer_norm.weight', 'encoder_2.layers.0.feed_forward.layer_norm.bias', 'encoder_2.layers.0.feed_forward.layer_norm.weight', 'encoder_2.layers.0.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.0.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.0.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.0.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.0.layer_norm.bias', 'encoder_2.layers.0.layer_norm.weight', 'encoder_2.layers.0.src_src_att.k_layer.bias', 'encoder_2.layers.0.src_src_att.k_layer.weight', 'encoder_2.layers.0.src_src_att.output_layer.bias', 'encoder_2.layers.0.src_src_att.output_layer.weight', 'encoder_2.layers.0.src_src_att.q_layer.bias', 'encoder_2.layers.0.src_src_att.q_layer.weight', 'encoder_2.layers.0.src_src_att.v_layer.bias', 'encoder_2.layers.0.src_src_att.v_layer.weight', 'encoder_2.layers.1.feed_forward.layer_norm.bias', 'encoder_2.layers.1.feed_forward.layer_norm.weight', 'encoder_2.layers.1.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.1.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.1.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.1.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.1.layer_norm.bias', 'encoder_2.layers.1.layer_norm.weight', 'encoder_2.layers.1.src_src_att.k_layer.bias', 'encoder_2.layers.1.src_src_att.k_layer.weight', 'encoder_2.layers.1.src_src_att.output_layer.bias', 'encoder_2.layers.1.src_src_att.output_layer.weight', 'encoder_2.layers.1.src_src_att.q_layer.bias', 'encoder_2.layers.1.src_src_att.q_layer.weight', 'encoder_2.layers.1.src_src_att.v_layer.bias', 'encoder_2.layers.1.src_src_att.v_layer.weight', 'encoder_2.layers.2.feed_forward.layer_norm.bias', 'encoder_2.layers.2.feed_forward.layer_norm.weight', 'encoder_2.layers.2.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.2.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.2.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.2.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.2.layer_norm.bias', 'encoder_2.layers.2.layer_norm.weight', 'encoder_2.layers.2.src_src_att.k_layer.bias', 'encoder_2.layers.2.src_src_att.k_layer.weight', 'encoder_2.layers.2.src_src_att.output_layer.bias', 'encoder_2.layers.2.src_src_att.output_layer.weight', 'encoder_2.layers.2.src_src_att.q_layer.bias', 'encoder_2.layers.2.src_src_att.q_layer.weight', 'encoder_2.layers.2.src_src_att.v_layer.bias', 'encoder_2.layers.2.src_src_att.v_layer.weight', 'encoder_2.layers.3.feed_forward.layer_norm.bias', 'encoder_2.layers.3.feed_forward.layer_norm.weight', 'encoder_2.layers.3.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.3.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.3.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.3.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.3.layer_norm.bias', 'encoder_2.layers.3.layer_norm.weight', 'encoder_2.layers.3.src_src_att.k_layer.bias', 'encoder_2.layers.3.src_src_att.k_layer.weight', 'encoder_2.layers.3.src_src_att.output_layer.bias', 'encoder_2.layers.3.src_src_att.output_layer.weight', 'encoder_2.layers.3.src_src_att.q_layer.bias', 'encoder_2.layers.3.src_src_att.q_layer.weight', 'encoder_2.layers.3.src_src_att.v_layer.bias', 'encoder_2.layers.3.src_src_att.v_layer.weight', 'encoder_2.layers.4.feed_forward.layer_norm.bias', 'encoder_2.layers.4.feed_forward.layer_norm.weight', 'encoder_2.layers.4.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.4.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.4.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.4.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.4.layer_norm.bias', 'encoder_2.layers.4.layer_norm.weight', 'encoder_2.layers.4.src_src_att.k_layer.bias', 'encoder_2.layers.4.src_src_att.k_layer.weight', 'encoder_2.layers.4.src_src_att.output_layer.bias', 'encoder_2.layers.4.src_src_att.output_layer.weight', 'encoder_2.layers.4.src_src_att.q_layer.bias', 'encoder_2.layers.4.src_src_att.q_layer.weight', 'encoder_2.layers.4.src_src_att.v_layer.bias', 'encoder_2.layers.4.src_src_att.v_layer.weight', 'encoder_2.layers.5.feed_forward.layer_norm.bias', 'encoder_2.layers.5.feed_forward.layer_norm.weight', 'encoder_2.layers.5.feed_forward.pwff_layer.0.bias', 'encoder_2.layers.5.feed_forward.pwff_layer.0.weight', 'encoder_2.layers.5.feed_forward.pwff_layer.3.bias', 'encoder_2.layers.5.feed_forward.pwff_layer.3.weight', 'encoder_2.layers.5.layer_norm.bias', 'encoder_2.layers.5.layer_norm.weight', 'encoder_2.layers.5.src_src_att.k_layer.bias', 'encoder_2.layers.5.src_src_att.k_layer.weight', 'encoder_2.layers.5.src_src_att.output_layer.bias', 'encoder_2.layers.5.src_src_att.output_layer.weight', 'encoder_2.layers.5.src_src_att.q_layer.bias', 'encoder_2.layers.5.src_src_att.q_layer.weight', 'encoder_2.layers.5.src_src_att.v_layer.bias', 'encoder_2.layers.5.src_src_att.v_layer.weight', 'last_layer.W_g.weight', 'last_layer.b_g', 'last_layer.feed_forward.layer_norm.bias', 'last_layer.feed_forward.layer_norm.weight', 'last_layer.feed_forward.pwff_layer.0.bias', 'last_layer.feed_forward.pwff_layer.0.weight', 'last_layer.feed_forward.pwff_layer.3.bias', 'last_layer.feed_forward.pwff_layer.3.weight', 'last_layer.layer_norm.bias', 'last_layer.layer_norm.weight', 'last_layer.src2_src_att.k_layer.bias', 'last_layer.src2_src_att.k_layer.weight', 'last_layer.src2_src_att.output_layer.bias', 'last_layer.src2_src_att.output_layer.weight', 'last_layer.src2_src_att.q_layer.bias', 'last_layer.src2_src_att.q_layer.weight', 'last_layer.src2_src_att.v_layer.bias', 'last_layer.src2_src_att.v_layer.weight', 'last_layer.src_src_att.k_layer.bias', 'last_layer.src_src_att.k_layer.weight', 'last_layer.src_src_att.output_layer.bias', 'last_layer.src_src_att.output_layer.weight', 'last_layer.src_src_att.q_layer.bias', 'last_layer.src_src_att.q_layer.weight', 'last_layer.src_src_att.v_layer.bias', 'last_layer.src_src_att.v_layer.weight', 'last_layer_norm.bias', 'last_layer_norm.weight', 'src_embed.lut.weight']
2020-06-30 05:02:53,630 Loading model from models/wmt_ende_transformer/best.ckpt
2020-06-30 05:02:53,933 Reset optimizer.
2020-06-30 05:02:53,933 Reset scheduler.
2020-06-30 05:02:53,934 Reset tracking of the best checkpoint.
2020-06-30 05:02:53,940 cfg.name                           : transformer
2020-06-30 05:02:53,940 cfg.data.src                       : en
2020-06-30 05:02:53,940 cfg.data.trg                       : de
2020-06-30 05:02:53,940 cfg.data.train                     : chatnmt/prep/train.tags.bpe.wmt_ende_best
2020-06-30 05:02:53,940 cfg.data.dev                       : chatnmt/prep/dev.tags.bpe.wmt_ende_best
2020-06-30 05:02:53,940 cfg.data.test                      : chatnmt/prep/test.tags.bpe.wmt_ende_best
2020-06-30 05:02:53,940 cfg.data.level                     : bpe
2020-06-30 05:02:53,940 cfg.data.lowercase                 : False
2020-06-30 05:02:53,940 cfg.data.max_sent_length           : 100
2020-06-30 05:02:53,940 cfg.data.src_vocab                 : models/wmt_ende_transformer/src_vocab.txt
2020-06-30 05:02:53,940 cfg.data.trg_vocab                 : models/wmt_ende_transformer/trg_vocab.txt
2020-06-30 05:02:53,940 cfg.testing.beam_size              : 5
2020-06-30 05:02:53,940 cfg.testing.alpha                  : 1.0
2020-06-30 05:02:53,940 cfg.training.random_seed           : 42
2020-06-30 05:02:53,940 cfg.training.optimizer             : adam
2020-06-30 05:02:53,940 cfg.training.normalization         : tokens
2020-06-30 05:02:53,940 cfg.training.adam_betas            : [0.9, 0.999]
2020-06-30 05:02:53,940 cfg.training.scheduling            : plateau
2020-06-30 05:02:53,940 cfg.training.patience              : 8
2020-06-30 05:02:53,940 cfg.training.decrease_factor       : 0.7
2020-06-30 05:02:53,940 cfg.training.loss                  : crossentropy
2020-06-30 05:02:53,940 cfg.training.learning_rate         : 0.0002
2020-06-30 05:02:53,941 cfg.training.learning_rate_min     : 1e-08
2020-06-30 05:02:53,941 cfg.training.weight_decay          : 0.0
2020-06-30 05:02:53,941 cfg.training.label_smoothing       : 0.1
2020-06-30 05:02:53,941 cfg.training.batch_size            : 1024
2020-06-30 05:02:53,941 cfg.training.batch_type            : token
2020-06-30 05:02:53,941 cfg.training.batch_multiplier      : 1
2020-06-30 05:02:53,941 cfg.training.early_stopping_metric : ppl
2020-06-30 05:02:53,941 cfg.training.epochs                : 120
2020-06-30 05:02:53,941 cfg.training.validation_freq       : 1000
2020-06-30 05:02:53,941 cfg.training.logging_freq          : 100
2020-06-30 05:02:53,941 cfg.training.eval_metric           : bleu
2020-06-30 05:02:53,941 cfg.training.model_dir             : models/transformer_multi_enc_ende-tune-dropout
2020-06-30 05:02:53,941 cfg.training.load_model            : models/wmt_ende_transformer/best.ckpt
2020-06-30 05:02:53,941 cfg.training.reset_best_ckpt       : True
2020-06-30 05:02:53,941 cfg.training.reset_scheduler       : True
2020-06-30 05:02:53,941 cfg.training.reset_optimizer       : True
2020-06-30 05:02:53,941 cfg.training.overwrite             : False
2020-06-30 05:02:53,941 cfg.training.shuffle               : True
2020-06-30 05:02:53,941 cfg.training.use_cuda              : True
2020-06-30 05:02:53,941 cfg.training.max_output_length     : 100
2020-06-30 05:02:53,941 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-06-30 05:02:53,941 cfg.training.keep_last_ckpts       : 3
2020-06-30 05:02:53,941 cfg.model.initializer              : xavier
2020-06-30 05:02:53,941 cfg.model.bias_initializer         : zeros
2020-06-30 05:02:53,941 cfg.model.init_gain                : 1.0
2020-06-30 05:02:53,941 cfg.model.embed_initializer        : xavier
2020-06-30 05:02:53,941 cfg.model.embed_init_gain          : 1.0
2020-06-30 05:02:53,941 cfg.model.tied_embeddings          : True
2020-06-30 05:02:53,941 cfg.model.tied_softmax             : True
2020-06-30 05:02:53,941 cfg.model.encoder.type             : transformer
2020-06-30 05:02:53,941 cfg.model.encoder.num_layers       : 6
2020-06-30 05:02:53,941 cfg.model.encoder.num_heads        : 8
2020-06-30 05:02:53,941 cfg.model.encoder.embeddings.embedding_dim : 512
2020-06-30 05:02:53,941 cfg.model.encoder.embeddings.scale : True
2020-06-30 05:02:53,941 cfg.model.encoder.embeddings.dropout : 0.0
2020-06-30 05:02:53,941 cfg.model.encoder.hidden_size      : 512
2020-06-30 05:02:53,941 cfg.model.encoder.ff_size          : 2048
2020-06-30 05:02:53,941 cfg.model.encoder.dropout          : 0.2
2020-06-30 05:02:53,941 cfg.model.encoder.multi_encoder    : True
2020-06-30 05:02:53,941 cfg.model.decoder.type             : transformer
2020-06-30 05:02:53,941 cfg.model.decoder.num_layers       : 6
2020-06-30 05:02:53,941 cfg.model.decoder.num_heads        : 8
2020-06-30 05:02:53,942 cfg.model.decoder.embeddings.embedding_dim : 512
2020-06-30 05:02:53,942 cfg.model.decoder.embeddings.scale : True
2020-06-30 05:02:53,942 cfg.model.decoder.embeddings.dropout : 0.0
2020-06-30 05:02:53,942 cfg.model.decoder.hidden_size      : 512
2020-06-30 05:02:53,942 cfg.model.decoder.ff_size          : 2048
2020-06-30 05:02:53,942 cfg.model.decoder.dropout          : 0.1
2020-06-30 05:02:53,942 Data set sizes: 
	train 9747,
	valid 1523,
	test 1186
2020-06-30 05:02:53,942 First training example:
	[SRC] H@@ i there@@ ! How can I hel@@ p@@ ?
	[TRG] Hal@@ lo@@ ! Wie kann ich hel@@ fen@@ ?
2020-06-30 05:02:53,942 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) the (7) in (8) of (9) der
2020-06-30 05:02:53,942 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) the (7) in (8) of (9) der
2020-06-30 05:02:53,942 Number of Src words (types): 36628
2020-06-30 05:02:53,942 Number of Trg words (types): 36628
2020-06-30 05:02:53,942 Model(
	encoder=TransformerEncoder(num_layers=5, num_heads=8),
	decoder=TransformerDecoder(num_layers=6, num_heads=8),
	src_embed=Embeddings(embedding_dim=512, vocab_size=36628),
	trg_embed=Embeddings(embedding_dim=512, vocab_size=36628))
2020-06-30 05:02:53,969 EPOCH 1
2020-06-30 05:03:07,961 Epoch   1 Step:  1360100 Batch Loss:     4.370922 Tokens per Sec:     4788, Lr: 0.000200
2020-06-30 05:03:21,483 Epoch   1 Step:  1360200 Batch Loss:     2.736245 Tokens per Sec:     5038, Lr: 0.000200
2020-06-30 05:03:27,644 Epoch   1: total training loss 946.57
2020-06-30 05:03:27,645 EPOCH 2
2020-06-30 05:03:35,499 Epoch   2 Step:  1360300 Batch Loss:     1.920492 Tokens per Sec:     4984, Lr: 0.000200
2020-06-30 05:03:50,026 Epoch   2 Step:  1360400 Batch Loss:     1.914412 Tokens per Sec:     4670, Lr: 0.000200
2020-06-30 05:04:02,170 Epoch   2: total training loss 426.67
2020-06-30 05:04:02,171 EPOCH 3
2020-06-30 05:04:04,750 Epoch   3 Step:  1360500 Batch Loss:     1.449313 Tokens per Sec:     4514, Lr: 0.000200
2020-06-30 05:04:18,918 Epoch   3 Step:  1360600 Batch Loss:     1.273033 Tokens per Sec:     4756, Lr: 0.000200
2020-06-30 05:04:32,965 Epoch   3 Step:  1360700 Batch Loss:     1.565067 Tokens per Sec:     4807, Lr: 0.000200
2020-06-30 05:04:36,389 Epoch   3: total training loss 326.78
2020-06-30 05:04:36,390 EPOCH 4
2020-06-30 05:04:47,032 Epoch   4 Step:  1360800 Batch Loss:     0.889865 Tokens per Sec:     4771, Lr: 0.000200
2020-06-30 05:05:00,906 Epoch   4 Step:  1360900 Batch Loss:     1.303588 Tokens per Sec:     4835, Lr: 0.000200
2020-06-30 05:05:10,598 Epoch   4: total training loss 271.12
2020-06-30 05:05:10,599 EPOCH 5
2020-06-30 05:05:15,236 Epoch   5 Step:  1361000 Batch Loss:     1.183984 Tokens per Sec:     4766, Lr: 0.000200
2020-06-30 05:05:52,451 Hooray! New best validation result [ppl]!
2020-06-30 05:05:52,452 Saving new checkpoint.
2020-06-30 05:06:03,242 Example #0
2020-06-30 05:06:03,243 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:06:03,243 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:06:03,243 	Source:     Hello.
2020-06-30 05:06:03,243 	Reference:  Hallo,
2020-06-30 05:06:03,243 	Hypothesis: Hallo.
2020-06-30 05:06:03,243 Example #1
2020-06-30 05:06:03,243 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:06:03,243 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:06:03,243 	Source:     Hi, how can I help you?
2020-06-30 05:06:03,243 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:06:03,243 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:06:03,244 Example #2
2020-06-30 05:06:03,244 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:06:03,244 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'im', 'Ar@@', 'den', 'Fair', 'Einkaufs@@', 'zentrum', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:06:03,244 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:06:03,244 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:06:03,244 	Hypothesis: Hallo, ich suche ein Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:06:03,244 Example #3
2020-06-30 05:06:03,244 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:06:03,244 	Raw hypothesis: ['Ok@@', ',', 'welche', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:06:03,244 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:06:03,244 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:06:03,244 	Hypothesis: Ok, welche Art von Restaurant suchen Sie?
2020-06-30 05:06:03,244 Validation result (greedy) at epoch   5, step  1361000: bleu:  37.97, loss: 26697.7539, ppl:   2.8369, duration: 48.0075s
2020-06-30 05:06:17,642 Epoch   5 Step:  1361100 Batch Loss:     0.830300 Tokens per Sec:     4669, Lr: 0.000200
2020-06-30 05:06:32,116 Epoch   5 Step:  1361200 Batch Loss:     0.850890 Tokens per Sec:     4716, Lr: 0.000200
2020-06-30 05:06:33,486 Epoch   5: total training loss 236.69
2020-06-30 05:06:33,486 EPOCH 6
2020-06-30 05:06:46,811 Epoch   6 Step:  1361300 Batch Loss:     0.862506 Tokens per Sec:     4527, Lr: 0.000200
2020-06-30 05:07:00,886 Epoch   6 Step:  1361400 Batch Loss:     0.766237 Tokens per Sec:     4818, Lr: 0.000200
2020-06-30 05:07:08,513 Epoch   6: total training loss 211.51
2020-06-30 05:07:08,514 EPOCH 7
2020-06-30 05:07:15,130 Epoch   7 Step:  1361500 Batch Loss:     1.053486 Tokens per Sec:     4891, Lr: 0.000200
2020-06-30 05:07:30,070 Epoch   7 Step:  1361600 Batch Loss:     0.749156 Tokens per Sec:     4487, Lr: 0.000200
2020-06-30 05:07:44,320 Epoch   7: total training loss 194.30
2020-06-30 05:07:44,320 EPOCH 8
2020-06-30 05:07:44,854 Epoch   8 Step:  1361700 Batch Loss:     1.091746 Tokens per Sec:     5633, Lr: 0.000200
2020-06-30 05:07:59,156 Epoch   8 Step:  1361800 Batch Loss:     0.881000 Tokens per Sec:     4759, Lr: 0.000200
2020-06-30 05:08:14,177 Epoch   8 Step:  1361900 Batch Loss:     0.657157 Tokens per Sec:     4500, Lr: 0.000200
2020-06-30 05:08:19,515 Epoch   8: total training loss 172.21
2020-06-30 05:08:19,516 EPOCH 9
2020-06-30 05:08:28,428 Epoch   9 Step:  1362000 Batch Loss:     0.711412 Tokens per Sec:     4831, Lr: 0.000200
2020-06-30 05:09:07,022 Hooray! New best validation result [ppl]!
2020-06-30 05:09:07,022 Saving new checkpoint.
2020-06-30 05:09:18,032 Example #0
2020-06-30 05:09:18,033 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:09:18,033 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:09:18,033 	Source:     Hello.
2020-06-30 05:09:18,033 	Reference:  Hallo,
2020-06-30 05:09:18,033 	Hypothesis: Hallo.
2020-06-30 05:09:18,033 Example #1
2020-06-30 05:09:18,033 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:09:18,033 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:09:18,033 	Source:     Hi, how can I help you?
2020-06-30 05:09:18,034 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:09:18,034 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:09:18,034 Example #2
2020-06-30 05:09:18,034 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:09:18,034 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:09:18,034 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:09:18,034 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:09:18,034 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:09:18,034 Example #3
2020-06-30 05:09:18,034 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:09:18,034 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:09:18,034 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:09:18,034 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:09:18,034 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:09:18,035 Validation result (greedy) at epoch   9, step  1362000: bleu:  42.06, loss: 22420.4492, ppl:   2.4005, duration: 49.6053s
2020-06-30 05:09:32,527 Epoch   9 Step:  1362100 Batch Loss:     0.889240 Tokens per Sec:     4719, Lr: 0.000200
2020-06-30 05:09:43,583 Epoch   9: total training loss 158.37
2020-06-30 05:09:43,583 EPOCH 10
2020-06-30 05:09:47,084 Epoch  10 Step:  1362200 Batch Loss:     0.636598 Tokens per Sec:     4510, Lr: 0.000200
2020-06-30 05:10:01,627 Epoch  10 Step:  1362300 Batch Loss:     0.537902 Tokens per Sec:     4585, Lr: 0.000200
2020-06-30 05:10:15,844 Epoch  10 Step:  1362400 Batch Loss:     0.523430 Tokens per Sec:     4713, Lr: 0.000200
2020-06-30 05:10:18,733 Epoch  10: total training loss 148.76
2020-06-30 05:10:18,733 EPOCH 11
2020-06-30 05:10:30,357 Epoch  11 Step:  1362500 Batch Loss:     0.491795 Tokens per Sec:     4693, Lr: 0.000200
2020-06-30 05:10:44,731 Epoch  11 Step:  1362600 Batch Loss:     0.724136 Tokens per Sec:     4687, Lr: 0.000200
2020-06-30 05:10:53,853 Epoch  11: total training loss 136.80
2020-06-30 05:10:53,854 EPOCH 12
2020-06-30 05:10:59,284 Epoch  12 Step:  1362700 Batch Loss:     0.599010 Tokens per Sec:     4629, Lr: 0.000200
2020-06-30 05:11:13,634 Epoch  12 Step:  1362800 Batch Loss:     0.518087 Tokens per Sec:     4745, Lr: 0.000200
2020-06-30 05:11:28,397 Epoch  12 Step:  1362900 Batch Loss:     0.637270 Tokens per Sec:     4543, Lr: 0.000200
2020-06-30 05:11:29,192 Epoch  12: total training loss 128.07
2020-06-30 05:11:29,192 EPOCH 13
2020-06-30 05:11:42,719 Epoch  13 Step:  1363000 Batch Loss:     0.510038 Tokens per Sec:     4734, Lr: 0.000200
2020-06-30 05:12:21,890 Hooray! New best validation result [ppl]!
2020-06-30 05:12:21,890 Saving new checkpoint.
2020-06-30 05:12:32,584 Example #0
2020-06-30 05:12:32,584 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:12:32,584 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:12:32,584 	Source:     Hello.
2020-06-30 05:12:32,584 	Reference:  Hallo,
2020-06-30 05:12:32,584 	Hypothesis: Hallo.
2020-06-30 05:12:32,584 Example #1
2020-06-30 05:12:32,585 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:12:32,585 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:12:32,585 	Source:     Hi, how can I help you?
2020-06-30 05:12:32,585 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:12:32,585 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:12:32,585 Example #2
2020-06-30 05:12:32,585 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:12:32,585 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:12:32,585 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:12:32,585 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:12:32,585 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:12:32,585 Example #3
2020-06-30 05:12:32,585 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:12:32,585 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:12:32,585 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:12:32,585 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:12:32,585 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:12:32,586 Validation result (greedy) at epoch  13, step  1363000: bleu:  43.97, loss: 21455.0410, ppl:   2.3116, duration: 49.8660s
2020-06-30 05:12:46,996 Epoch  13 Step:  1363100 Batch Loss:     0.586723 Tokens per Sec:     4749, Lr: 0.000200
2020-06-30 05:12:53,895 Epoch  13: total training loss 118.53
2020-06-30 05:12:53,896 EPOCH 14
2020-06-30 05:13:01,350 Epoch  14 Step:  1363200 Batch Loss:     0.533242 Tokens per Sec:     4743, Lr: 0.000200
2020-06-30 05:13:15,875 Epoch  14 Step:  1363300 Batch Loss:     0.469481 Tokens per Sec:     4636, Lr: 0.000200
2020-06-30 05:13:28,723 Epoch  14: total training loss 110.10
2020-06-30 05:13:28,724 EPOCH 15
2020-06-30 05:13:30,444 Epoch  15 Step:  1363400 Batch Loss:     0.393269 Tokens per Sec:     4946, Lr: 0.000200
2020-06-30 05:13:44,681 Epoch  15 Step:  1363500 Batch Loss:     0.311413 Tokens per Sec:     4696, Lr: 0.000200
2020-06-30 05:13:59,537 Epoch  15 Step:  1363600 Batch Loss:     0.389610 Tokens per Sec:     4549, Lr: 0.000200
2020-06-30 05:14:03,682 Epoch  15: total training loss 104.05
2020-06-30 05:14:03,683 EPOCH 16
2020-06-30 05:14:14,019 Epoch  16 Step:  1363700 Batch Loss:     0.346032 Tokens per Sec:     4481, Lr: 0.000200
2020-06-30 05:14:28,695 Epoch  16 Step:  1363800 Batch Loss:     0.478578 Tokens per Sec:     4568, Lr: 0.000200
2020-06-30 05:14:38,748 Epoch  16: total training loss 98.05
2020-06-30 05:14:38,748 EPOCH 17
2020-06-30 05:14:42,804 Epoch  17 Step:  1363900 Batch Loss:     0.457146 Tokens per Sec:     4671, Lr: 0.000200
2020-06-30 05:14:57,419 Epoch  17 Step:  1364000 Batch Loss:     0.423311 Tokens per Sec:     4654, Lr: 0.000200
2020-06-30 05:15:40,589 Hooray! New best validation result [ppl]!
2020-06-30 05:15:40,590 Saving new checkpoint.
2020-06-30 05:15:51,479 Example #0
2020-06-30 05:15:51,479 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:15:51,479 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:15:51,479 	Source:     Hello.
2020-06-30 05:15:51,479 	Reference:  Hallo,
2020-06-30 05:15:51,479 	Hypothesis: Hallo.
2020-06-30 05:15:51,479 Example #1
2020-06-30 05:15:51,479 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:15:51,479 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:15:51,479 	Source:     Hi, how can I help you?
2020-06-30 05:15:51,480 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:15:51,480 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:15:51,480 Example #2
2020-06-30 05:15:51,480 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:15:51,480 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:15:51,480 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:15:51,480 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:15:51,480 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:15:51,480 Example #3
2020-06-30 05:15:51,480 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:15:51,480 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:15:51,480 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:15:51,480 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:15:51,480 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:15:51,480 Validation result (greedy) at epoch  17, step  1364000: bleu:  44.74, loss: 21375.0332, ppl:   2.3044, duration: 54.0601s
2020-06-30 05:16:05,623 Epoch  17 Step:  1364100 Batch Loss:     0.331926 Tokens per Sec:     4788, Lr: 0.000200
2020-06-30 05:16:07,431 Epoch  17: total training loss 91.33
2020-06-30 05:16:07,431 EPOCH 18
2020-06-30 05:16:20,429 Epoch  18 Step:  1364200 Batch Loss:     0.333280 Tokens per Sec:     4580, Lr: 0.000200
2020-06-30 05:16:34,715 Epoch  18 Step:  1364300 Batch Loss:     0.294316 Tokens per Sec:     4765, Lr: 0.000200
2020-06-30 05:16:42,170 Epoch  18: total training loss 84.85
2020-06-30 05:16:42,171 EPOCH 19
2020-06-30 05:16:49,447 Epoch  19 Step:  1364400 Batch Loss:     0.325151 Tokens per Sec:     4355, Lr: 0.000200
2020-06-30 05:17:04,033 Epoch  19 Step:  1364500 Batch Loss:     0.424093 Tokens per Sec:     4654, Lr: 0.000200
2020-06-30 05:17:17,503 Epoch  19: total training loss 81.02
2020-06-30 05:17:17,504 EPOCH 20
2020-06-30 05:17:18,051 Epoch  20 Step:  1364600 Batch Loss:     0.332631 Tokens per Sec:     5004, Lr: 0.000200
2020-06-30 05:17:32,602 Epoch  20 Step:  1364700 Batch Loss:     0.340604 Tokens per Sec:     4622, Lr: 0.000200
2020-06-30 05:17:46,870 Epoch  20 Step:  1364800 Batch Loss:     0.297949 Tokens per Sec:     4775, Lr: 0.000200
2020-06-30 05:17:52,723 Epoch  20: total training loss 76.93
2020-06-30 05:17:52,724 EPOCH 21
2020-06-30 05:18:01,628 Epoch  21 Step:  1364900 Batch Loss:     0.320149 Tokens per Sec:     4669, Lr: 0.000200
2020-06-30 05:18:16,030 Epoch  21 Step:  1365000 Batch Loss:     0.290531 Tokens per Sec:     4711, Lr: 0.000200
2020-06-30 05:18:56,430 Hooray! New best validation result [ppl]!
2020-06-30 05:18:56,431 Saving new checkpoint.
2020-06-30 05:19:07,308 Example #0
2020-06-30 05:19:07,308 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:19:07,309 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:19:07,309 	Source:     Hello.
2020-06-30 05:19:07,309 	Reference:  Hallo,
2020-06-30 05:19:07,309 	Hypothesis: Hallo.
2020-06-30 05:19:07,309 Example #1
2020-06-30 05:19:07,309 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:19:07,309 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:19:07,309 	Source:     Hi, how can I help you?
2020-06-30 05:19:07,309 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:19:07,309 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:19:07,309 Example #2
2020-06-30 05:19:07,309 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:19:07,309 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:19:07,309 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:19:07,309 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:19:07,310 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:19:07,310 Example #3
2020-06-30 05:19:07,310 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:19:07,310 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:19:07,310 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:19:07,310 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:19:07,310 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:19:07,310 Validation result (greedy) at epoch  21, step  1365000: bleu:  44.73, loss: 21218.5293, ppl:   2.2904, duration: 51.2789s
2020-06-30 05:19:18,780 Epoch  21: total training loss 71.75
2020-06-30 05:19:18,781 EPOCH 22
2020-06-30 05:19:21,854 Epoch  22 Step:  1365100 Batch Loss:     0.314930 Tokens per Sec:     4401, Lr: 0.000200
2020-06-30 05:19:35,493 Epoch  22 Step:  1365200 Batch Loss:     0.340111 Tokens per Sec:     5005, Lr: 0.000200
2020-06-30 05:19:49,094 Epoch  22 Step:  1365300 Batch Loss:     0.283430 Tokens per Sec:     4887, Lr: 0.000200
2020-06-30 05:19:52,034 Epoch  22: total training loss 67.10
2020-06-30 05:19:52,035 EPOCH 23
2020-06-30 05:20:02,871 Epoch  23 Step:  1365400 Batch Loss:     0.281792 Tokens per Sec:     4791, Lr: 0.000200
2020-06-30 05:20:17,326 Epoch  23 Step:  1365500 Batch Loss:     0.318344 Tokens per Sec:     4685, Lr: 0.000200
2020-06-30 05:20:26,754 Epoch  23: total training loss 63.17
2020-06-30 05:20:26,754 EPOCH 24
2020-06-30 05:20:32,055 Epoch  24 Step:  1365600 Batch Loss:     0.208734 Tokens per Sec:     4639, Lr: 0.000200
2020-06-30 05:20:46,339 Epoch  24 Step:  1365700 Batch Loss:     0.216207 Tokens per Sec:     4732, Lr: 0.000200
2020-06-30 05:21:00,626 Epoch  24 Step:  1365800 Batch Loss:     0.231729 Tokens per Sec:     4709, Lr: 0.000200
2020-06-30 05:21:01,514 Epoch  24: total training loss 59.76
2020-06-30 05:21:01,514 EPOCH 25
2020-06-30 05:21:15,471 Epoch  25 Step:  1365900 Batch Loss:     0.272521 Tokens per Sec:     4556, Lr: 0.000200
2020-06-30 05:21:29,578 Epoch  25 Step:  1366000 Batch Loss:     0.236253 Tokens per Sec:     4724, Lr: 0.000200
2020-06-30 05:22:08,684 Example #0
2020-06-30 05:22:08,685 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:22:08,685 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:22:08,685 	Source:     Hello.
2020-06-30 05:22:08,685 	Reference:  Hallo,
2020-06-30 05:22:08,685 	Hypothesis: Hallo.
2020-06-30 05:22:08,685 Example #1
2020-06-30 05:22:08,685 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:22:08,685 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:22:08,685 	Source:     Hi, how can I help you?
2020-06-30 05:22:08,685 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:22:08,685 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:22:08,685 Example #2
2020-06-30 05:22:08,685 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:22:08,685 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:22:08,685 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:22:08,685 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:22:08,685 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:22:08,685 Example #3
2020-06-30 05:22:08,685 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:22:08,685 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:22:08,685 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:22:08,685 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:22:08,685 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:22:08,685 Validation result (greedy) at epoch  25, step  1366000: bleu:  44.81, loss: 21893.8281, ppl:   2.3516, duration: 39.1062s
2020-06-30 05:22:15,399 Epoch  25: total training loss 57.25
2020-06-30 05:22:15,400 EPOCH 26
2020-06-30 05:22:22,629 Epoch  26 Step:  1366100 Batch Loss:     0.192936 Tokens per Sec:     4691, Lr: 0.000200
2020-06-30 05:22:36,800 Epoch  26 Step:  1366200 Batch Loss:     0.276316 Tokens per Sec:     4815, Lr: 0.000200
2020-06-30 05:22:50,230 Epoch  26: total training loss 53.36
2020-06-30 05:22:50,230 EPOCH 27
2020-06-30 05:22:51,526 Epoch  27 Step:  1366300 Batch Loss:     0.215148 Tokens per Sec:     5039, Lr: 0.000200
2020-06-30 05:23:05,820 Epoch  27 Step:  1366400 Batch Loss:     0.227102 Tokens per Sec:     4660, Lr: 0.000200
2020-06-30 05:23:20,231 Epoch  27 Step:  1366500 Batch Loss:     0.175876 Tokens per Sec:     4693, Lr: 0.000200
2020-06-30 05:23:25,091 Epoch  27: total training loss 50.77
2020-06-30 05:23:25,092 EPOCH 28
2020-06-30 05:23:34,161 Epoch  28 Step:  1366600 Batch Loss:     0.165981 Tokens per Sec:     4749, Lr: 0.000200
2020-06-30 05:23:48,456 Epoch  28 Step:  1366700 Batch Loss:     0.186339 Tokens per Sec:     4771, Lr: 0.000200
2020-06-30 05:23:59,636 Epoch  28: total training loss 47.64
2020-06-30 05:23:59,637 EPOCH 29
2020-06-30 05:24:02,928 Epoch  29 Step:  1366800 Batch Loss:     0.172736 Tokens per Sec:     4711, Lr: 0.000200
2020-06-30 05:24:17,551 Epoch  29 Step:  1366900 Batch Loss:     0.182547 Tokens per Sec:     4702, Lr: 0.000200
2020-06-30 05:24:32,361 Epoch  29 Step:  1367000 Batch Loss:     0.194617 Tokens per Sec:     4557, Lr: 0.000200
2020-06-30 05:25:12,666 Example #0
2020-06-30 05:25:12,666 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:25:12,666 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:25:12,666 	Source:     Hello.
2020-06-30 05:25:12,667 	Reference:  Hallo,
2020-06-30 05:25:12,667 	Hypothesis: Hallo.
2020-06-30 05:25:12,667 Example #1
2020-06-30 05:25:12,667 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:25:12,667 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:25:12,667 	Source:     Hi, how can I help you?
2020-06-30 05:25:12,667 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:25:12,667 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:25:12,667 Example #2
2020-06-30 05:25:12,667 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:25:12,667 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:25:12,667 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:25:12,667 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:25:12,667 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:25:12,667 Example #3
2020-06-30 05:25:12,667 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:25:12,668 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:25:12,668 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:25:12,668 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:25:12,668 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:25:12,668 Validation result (greedy) at epoch  29, step  1367000: bleu:  44.66, loss: 22680.4238, ppl:   2.4250, duration: 40.3061s
2020-06-30 05:25:15,351 Epoch  29: total training loss 44.67
2020-06-30 05:25:15,351 EPOCH 30
2020-06-30 05:25:27,154 Epoch  30 Step:  1367100 Batch Loss:     0.174941 Tokens per Sec:     4716, Lr: 0.000200
2020-06-30 05:25:42,326 Epoch  30 Step:  1367200 Batch Loss:     0.165368 Tokens per Sec:     4437, Lr: 0.000200
2020-06-30 05:25:50,886 Epoch  30: total training loss 42.28
2020-06-30 05:25:50,887 EPOCH 31
2020-06-30 05:25:56,680 Epoch  31 Step:  1367300 Batch Loss:     0.134547 Tokens per Sec:     4615, Lr: 0.000200
2020-06-30 05:26:11,670 Epoch  31 Step:  1367400 Batch Loss:     0.178856 Tokens per Sec:     4505, Lr: 0.000200
2020-06-30 05:26:26,357 Epoch  31 Step:  1367500 Batch Loss:     0.190805 Tokens per Sec:     4636, Lr: 0.000200
2020-06-30 05:26:26,461 Epoch  31: total training loss 40.29
2020-06-30 05:26:26,461 EPOCH 32
2020-06-30 05:26:41,093 Epoch  32 Step:  1367600 Batch Loss:     0.153046 Tokens per Sec:     4578, Lr: 0.000200
2020-06-30 05:26:55,761 Epoch  32 Step:  1367700 Batch Loss:     0.141512 Tokens per Sec:     4592, Lr: 0.000200
2020-06-30 05:27:02,163 Epoch  32: total training loss 38.78
2020-06-30 05:27:02,164 EPOCH 33
2020-06-30 05:27:10,794 Epoch  33 Step:  1367800 Batch Loss:     0.143162 Tokens per Sec:     4428, Lr: 0.000200
2020-06-30 05:27:25,614 Epoch  33 Step:  1367900 Batch Loss:     0.151970 Tokens per Sec:     4591, Lr: 0.000200
2020-06-30 05:27:37,995 Epoch  33: total training loss 36.03
2020-06-30 05:27:37,995 EPOCH 34
2020-06-30 05:27:40,340 Epoch  34 Step:  1368000 Batch Loss:     0.154893 Tokens per Sec:     4631, Lr: 0.000200
2020-06-30 05:28:18,908 Example #0
2020-06-30 05:28:18,908 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:28:18,908 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:28:18,908 	Source:     Hello.
2020-06-30 05:28:18,908 	Reference:  Hallo,
2020-06-30 05:28:18,908 	Hypothesis: Hallo.
2020-06-30 05:28:18,908 Example #1
2020-06-30 05:28:18,908 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:28:18,908 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:28:18,908 	Source:     Hi, how can I help you?
2020-06-30 05:28:18,908 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:28:18,908 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:28:18,908 Example #2
2020-06-30 05:28:18,908 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:28:18,908 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'M@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:28:18,908 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:28:18,908 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:28:18,909 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall in San Francisco, Kalifornien.
2020-06-30 05:28:18,909 Example #3
2020-06-30 05:28:18,909 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:28:18,909 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:28:18,909 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:28:18,909 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:28:18,909 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:28:18,909 Validation result (greedy) at epoch  34, step  1368000: bleu:  44.93, loss: 23239.6426, ppl:   2.4785, duration: 38.5683s
2020-06-30 05:28:33,979 Epoch  34 Step:  1368100 Batch Loss:     0.143247 Tokens per Sec:     4476, Lr: 0.000200
2020-06-30 05:28:48,611 Epoch  34 Step:  1368200 Batch Loss:     0.126799 Tokens per Sec:     4607, Lr: 0.000200
2020-06-30 05:28:52,692 Epoch  34: total training loss 34.88
2020-06-30 05:28:52,692 EPOCH 35
2020-06-30 05:29:03,363 Epoch  35 Step:  1368300 Batch Loss:     0.173181 Tokens per Sec:     4581, Lr: 0.000200
2020-06-30 05:29:17,785 Epoch  35 Step:  1368400 Batch Loss:     0.067456 Tokens per Sec:     4716, Lr: 0.000200
2020-06-30 05:29:28,013 Epoch  35: total training loss 33.64
2020-06-30 05:29:28,013 EPOCH 36
2020-06-30 05:29:32,328 Epoch  36 Step:  1368500 Batch Loss:     0.161796 Tokens per Sec:     4661, Lr: 0.000200
2020-06-30 05:29:46,447 Epoch  36 Step:  1368600 Batch Loss:     0.154082 Tokens per Sec:     4820, Lr: 0.000200
2020-06-30 05:30:00,949 Epoch  36 Step:  1368700 Batch Loss:     0.112188 Tokens per Sec:     4687, Lr: 0.000200
2020-06-30 05:30:02,579 Epoch  36: total training loss 31.79
2020-06-30 05:30:02,579 EPOCH 37
2020-06-30 05:30:15,181 Epoch  37 Step:  1368800 Batch Loss:     0.100801 Tokens per Sec:     4756, Lr: 0.000200
2020-06-30 05:30:29,520 Epoch  37 Step:  1368900 Batch Loss:     0.152625 Tokens per Sec:     4754, Lr: 0.000200
2020-06-30 05:30:37,285 Epoch  37: total training loss 30.28
2020-06-30 05:30:37,286 EPOCH 38
2020-06-30 05:30:44,010 Epoch  38 Step:  1369000 Batch Loss:     0.098137 Tokens per Sec:     4642, Lr: 0.000200
2020-06-30 05:31:22,242 Example #0
2020-06-30 05:31:22,243 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:31:22,243 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:31:22,243 	Source:     Hello.
2020-06-30 05:31:22,243 	Reference:  Hallo,
2020-06-30 05:31:22,243 	Hypothesis: Hallo.
2020-06-30 05:31:22,243 Example #1
2020-06-30 05:31:22,243 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:31:22,243 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:31:22,243 	Source:     Hi, how can I help you?
2020-06-30 05:31:22,243 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:31:22,243 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:31:22,243 Example #2
2020-06-30 05:31:22,243 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:31:22,243 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:31:22,243 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:31:22,243 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:31:22,243 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:31:22,243 Example #3
2020-06-30 05:31:22,243 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:31:22,243 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:31:22,243 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:31:22,243 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:31:22,243 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:31:22,243 Validation result (greedy) at epoch  38, step  1369000: bleu:  44.64, loss: 23636.3008, ppl:   2.5172, duration: 38.2329s
2020-06-30 05:31:36,379 Epoch  38 Step:  1369100 Batch Loss:     0.133833 Tokens per Sec:     4760, Lr: 0.000200
2020-06-30 05:31:50,295 Epoch  38: total training loss 29.45
2020-06-30 05:31:50,295 EPOCH 39
2020-06-30 05:31:50,784 Epoch  39 Step:  1369200 Batch Loss:     0.114595 Tokens per Sec:     5658, Lr: 0.000200
2020-06-30 05:32:05,648 Epoch  39 Step:  1369300 Batch Loss:     0.095857 Tokens per Sec:     4534, Lr: 0.000200
2020-06-30 05:32:20,189 Epoch  39 Step:  1369400 Batch Loss:     0.116628 Tokens per Sec:     4620, Lr: 0.000200
2020-06-30 05:32:25,730 Epoch  39: total training loss 28.22
2020-06-30 05:32:25,731 EPOCH 40
2020-06-30 05:32:34,870 Epoch  40 Step:  1369500 Batch Loss:     0.127588 Tokens per Sec:     4519, Lr: 0.000200
2020-06-30 05:32:48,727 Epoch  40 Step:  1369600 Batch Loss:     0.094134 Tokens per Sec:     4851, Lr: 0.000200
2020-06-30 05:33:00,818 Epoch  40: total training loss 27.34
2020-06-30 05:33:00,819 EPOCH 41
2020-06-30 05:33:03,239 Epoch  41 Step:  1369700 Batch Loss:     0.091617 Tokens per Sec:     5065, Lr: 0.000200
2020-06-30 05:33:17,870 Epoch  41 Step:  1369800 Batch Loss:     0.093944 Tokens per Sec:     4548, Lr: 0.000200
2020-06-30 05:33:32,039 Epoch  41 Step:  1369900 Batch Loss:     0.110377 Tokens per Sec:     4715, Lr: 0.000200
2020-06-30 05:33:35,710 Epoch  41: total training loss 26.45
2020-06-30 05:33:35,710 EPOCH 42
2020-06-30 05:33:46,212 Epoch  42 Step:  1370000 Batch Loss:     0.113125 Tokens per Sec:     4675, Lr: 0.000200
2020-06-30 05:34:25,194 Example #0
2020-06-30 05:34:25,195 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:34:25,195 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:34:25,195 	Source:     Hello.
2020-06-30 05:34:25,195 	Reference:  Hallo,
2020-06-30 05:34:25,195 	Hypothesis: Hallo.
2020-06-30 05:34:25,195 Example #1
2020-06-30 05:34:25,195 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:34:25,195 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:34:25,195 	Source:     Hi, how can I help you?
2020-06-30 05:34:25,195 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:34:25,195 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:34:25,195 Example #2
2020-06-30 05:34:25,195 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:34:25,195 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:34:25,195 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:34:25,195 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:34:25,195 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:34:25,195 Example #3
2020-06-30 05:34:25,195 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:34:25,195 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:34:25,195 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:34:25,195 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:34:25,195 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:34:25,195 Validation result (greedy) at epoch  42, step  1370000: bleu:  45.07, loss: 23987.0840, ppl:   2.5519, duration: 38.9825s
2020-06-30 05:34:39,517 Epoch  42 Step:  1370100 Batch Loss:     0.111365 Tokens per Sec:     4772, Lr: 0.000200
2020-06-30 05:34:49,411 Epoch  42: total training loss 25.40
2020-06-30 05:34:49,411 EPOCH 43
2020-06-30 05:34:54,230 Epoch  43 Step:  1370200 Batch Loss:     0.101865 Tokens per Sec:     4629, Lr: 0.000200
2020-06-30 05:35:08,641 Epoch  43 Step:  1370300 Batch Loss:     0.118721 Tokens per Sec:     4666, Lr: 0.000200
2020-06-30 05:35:22,650 Epoch  43 Step:  1370400 Batch Loss:     0.118880 Tokens per Sec:     4806, Lr: 0.000200
2020-06-30 05:35:24,037 Epoch  43: total training loss 25.09
2020-06-30 05:35:24,037 EPOCH 44
2020-06-30 05:35:37,122 Epoch  44 Step:  1370500 Batch Loss:     0.094484 Tokens per Sec:     4611, Lr: 0.000200
2020-06-30 05:35:51,332 Epoch  44 Step:  1370600 Batch Loss:     0.096647 Tokens per Sec:     4812, Lr: 0.000200
2020-06-30 05:35:58,879 Epoch  44: total training loss 23.81
2020-06-30 05:35:58,880 EPOCH 45
2020-06-30 05:36:06,048 Epoch  45 Step:  1370700 Batch Loss:     0.078475 Tokens per Sec:     4624, Lr: 0.000200
2020-06-30 05:36:20,812 Epoch  45 Step:  1370800 Batch Loss:     0.124071 Tokens per Sec:     4669, Lr: 0.000200
2020-06-30 05:36:33,565 Epoch  45: total training loss 22.82
2020-06-30 05:36:33,567 EPOCH 46
2020-06-30 05:36:34,591 Epoch  46 Step:  1370900 Batch Loss:     0.079190 Tokens per Sec:     5595, Lr: 0.000200
2020-06-30 05:36:48,670 Epoch  46 Step:  1371000 Batch Loss:     0.083307 Tokens per Sec:     4723, Lr: 0.000200
2020-06-30 05:37:27,029 Example #0
2020-06-30 05:37:27,029 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:37:27,030 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:37:27,030 	Source:     Hello.
2020-06-30 05:37:27,030 	Reference:  Hallo,
2020-06-30 05:37:27,030 	Hypothesis: Hallo.
2020-06-30 05:37:27,030 Example #1
2020-06-30 05:37:27,030 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:37:27,030 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:37:27,030 	Source:     Hi, how can I help you?
2020-06-30 05:37:27,030 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:37:27,030 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:37:27,030 Example #2
2020-06-30 05:37:27,030 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:37:27,030 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'M@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:37:27,030 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:37:27,030 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:37:27,030 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall in San Francisco, Kalifornien.
2020-06-30 05:37:27,030 Example #3
2020-06-30 05:37:27,030 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:37:27,030 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:37:27,030 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:37:27,030 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:37:27,030 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:37:27,030 Validation result (greedy) at epoch  46, step  1371000: bleu:  44.73, loss: 24257.3672, ppl:   2.5790, duration: 38.3601s
2020-06-30 05:37:41,461 Epoch  46 Step:  1371100 Batch Loss:     0.096266 Tokens per Sec:     4760, Lr: 0.000200
2020-06-30 05:37:46,501 Epoch  46: total training loss 22.01
2020-06-30 05:37:46,501 EPOCH 47
2020-06-30 05:37:56,377 Epoch  47 Step:  1371200 Batch Loss:     0.091115 Tokens per Sec:     4671, Lr: 0.000200
2020-06-30 05:38:10,696 Epoch  47 Step:  1371300 Batch Loss:     0.092394 Tokens per Sec:     4734, Lr: 0.000200
2020-06-30 05:38:21,030 Epoch  47: total training loss 21.26
2020-06-30 05:38:21,030 EPOCH 48
2020-06-30 05:38:24,797 Epoch  48 Step:  1371400 Batch Loss:     0.114273 Tokens per Sec:     4653, Lr: 0.000200
2020-06-30 05:38:38,962 Epoch  48 Step:  1371500 Batch Loss:     0.098078 Tokens per Sec:     4745, Lr: 0.000200
2020-06-30 05:38:53,706 Epoch  48 Step:  1371600 Batch Loss:     0.097293 Tokens per Sec:     4626, Lr: 0.000200
2020-06-30 05:38:55,829 Epoch  48: total training loss 21.16
2020-06-30 05:38:55,829 EPOCH 49
2020-06-30 05:39:07,919 Epoch  49 Step:  1371700 Batch Loss:     0.105066 Tokens per Sec:     4701, Lr: 0.000200
2020-06-30 05:39:22,567 Epoch  49 Step:  1371800 Batch Loss:     0.090973 Tokens per Sec:     4581, Lr: 0.000200
2020-06-30 05:39:30,618 Epoch  49: total training loss 20.88
2020-06-30 05:39:30,618 EPOCH 50
2020-06-30 05:39:36,741 Epoch  50 Step:  1371900 Batch Loss:     0.060043 Tokens per Sec:     4633, Lr: 0.000200
2020-06-30 05:39:51,470 Epoch  50 Step:  1372000 Batch Loss:     0.079878 Tokens per Sec:     4519, Lr: 0.000200
2020-06-30 05:40:30,460 Example #0
2020-06-30 05:40:30,460 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:40:30,460 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:40:30,460 	Source:     Hello.
2020-06-30 05:40:30,460 	Reference:  Hallo,
2020-06-30 05:40:30,460 	Hypothesis: Hallo.
2020-06-30 05:40:30,460 Example #1
2020-06-30 05:40:30,460 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:40:30,460 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:40:30,460 	Source:     Hi, how can I help you?
2020-06-30 05:40:30,460 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:40:30,460 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:40:30,460 Example #2
2020-06-30 05:40:30,461 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:40:30,461 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:40:30,461 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:40:30,461 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:40:30,461 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:40:30,461 Example #3
2020-06-30 05:40:30,461 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:40:30,461 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:40:30,461 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:40:30,461 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:40:30,461 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:40:30,461 Validation result (greedy) at epoch  50, step  1372000: bleu:  44.43, loss: 24843.4824, ppl:   2.6387, duration: 38.9901s
2020-06-30 05:40:44,816 Epoch  50: total training loss 19.86
2020-06-30 05:40:44,816 EPOCH 51
2020-06-30 05:40:44,951 Epoch  51 Step:  1372100 Batch Loss:     0.095354 Tokens per Sec:     5563, Lr: 0.000200
2020-06-30 05:40:59,344 Epoch  51 Step:  1372200 Batch Loss:     0.076794 Tokens per Sec:     4699, Lr: 0.000200
2020-06-30 05:41:14,428 Epoch  51 Step:  1372300 Batch Loss:     0.091615 Tokens per Sec:     4537, Lr: 0.000200
2020-06-30 05:41:20,125 Epoch  51: total training loss 19.28
2020-06-30 05:41:20,125 EPOCH 52
2020-06-30 05:41:29,378 Epoch  52 Step:  1372400 Batch Loss:     0.078639 Tokens per Sec:     4612, Lr: 0.000200
2020-06-30 05:41:43,965 Epoch  52 Step:  1372500 Batch Loss:     0.088686 Tokens per Sec:     4689, Lr: 0.000200
2020-06-30 05:41:55,404 Epoch  52: total training loss 18.65
2020-06-30 05:41:55,404 EPOCH 53
2020-06-30 05:41:58,519 Epoch  53 Step:  1372600 Batch Loss:     0.071509 Tokens per Sec:     4706, Lr: 0.000200
2020-06-30 05:42:12,802 Epoch  53 Step:  1372700 Batch Loss:     0.076830 Tokens per Sec:     4747, Lr: 0.000200
2020-06-30 05:42:27,617 Epoch  53 Step:  1372800 Batch Loss:     0.095394 Tokens per Sec:     4519, Lr: 0.000200
2020-06-30 05:42:30,325 Epoch  53: total training loss 18.79
2020-06-30 05:42:30,325 EPOCH 54
2020-06-30 05:42:41,981 Epoch  54 Step:  1372900 Batch Loss:     0.080240 Tokens per Sec:     4580, Lr: 0.000200
2020-06-30 05:42:56,785 Epoch  54 Step:  1373000 Batch Loss:     0.077474 Tokens per Sec:     4574, Lr: 0.000200
2020-06-30 05:43:35,956 Example #0
2020-06-30 05:43:35,957 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:43:35,957 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:43:35,957 	Source:     Hello.
2020-06-30 05:43:35,957 	Reference:  Hallo,
2020-06-30 05:43:35,957 	Hypothesis: Hallo.
2020-06-30 05:43:35,957 Example #1
2020-06-30 05:43:35,957 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:43:35,957 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:43:35,957 	Source:     Hi, how can I help you?
2020-06-30 05:43:35,957 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:43:35,957 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:43:35,957 Example #2
2020-06-30 05:43:35,957 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:43:35,957 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'M@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:43:35,957 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:43:35,957 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:43:35,957 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall in San Francisco, Kalifornien.
2020-06-30 05:43:35,957 Example #3
2020-06-30 05:43:35,957 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:43:35,957 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:43:35,957 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:43:35,957 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:43:35,957 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:43:35,957 Validation result (greedy) at epoch  54, step  1373000: bleu:  43.88, loss: 25343.4336, ppl:   2.6908, duration: 39.1715s
2020-06-30 05:43:44,734 Epoch  54: total training loss 18.76
2020-06-30 05:43:44,735 EPOCH 55
2020-06-30 05:43:49,815 Epoch  55 Step:  1373100 Batch Loss:     0.097662 Tokens per Sec:     4775, Lr: 0.000200
2020-06-30 05:44:03,881 Epoch  55 Step:  1373200 Batch Loss:     0.068512 Tokens per Sec:     4794, Lr: 0.000200
2020-06-30 05:44:18,664 Epoch  55 Step:  1373300 Batch Loss:     0.093779 Tokens per Sec:     4581, Lr: 0.000200
2020-06-30 05:44:19,576 Epoch  55: total training loss 18.10
2020-06-30 05:44:19,576 EPOCH 56
2020-06-30 05:44:33,349 Epoch  56 Step:  1373400 Batch Loss:     0.076474 Tokens per Sec:     4691, Lr: 0.000200
2020-06-30 05:44:47,983 Epoch  56 Step:  1373500 Batch Loss:     0.078834 Tokens per Sec:     4625, Lr: 0.000200
2020-06-30 05:44:54,788 Epoch  56: total training loss 17.48
2020-06-30 05:44:54,789 EPOCH 57
2020-06-30 05:45:02,625 Epoch  57 Step:  1373600 Batch Loss:     0.089952 Tokens per Sec:     4616, Lr: 0.000200
2020-06-30 05:45:16,937 Epoch  57 Step:  1373700 Batch Loss:     0.084944 Tokens per Sec:     4719, Lr: 0.000200
2020-06-30 05:45:29,708 Epoch  57: total training loss 17.22
2020-06-30 05:45:29,708 EPOCH 58
2020-06-30 05:45:31,064 Epoch  58 Step:  1373800 Batch Loss:     0.070799 Tokens per Sec:     5713, Lr: 0.000200
2020-06-30 05:45:45,006 Epoch  58 Step:  1373900 Batch Loss:     0.075287 Tokens per Sec:     4830, Lr: 0.000200
2020-06-30 05:45:58,906 Epoch  58 Step:  1374000 Batch Loss:     0.060592 Tokens per Sec:     4848, Lr: 0.000200
2020-06-30 05:46:37,382 Example #0
2020-06-30 05:46:37,382 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:46:37,382 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:46:37,383 	Source:     Hello.
2020-06-30 05:46:37,383 	Reference:  Hallo,
2020-06-30 05:46:37,383 	Hypothesis: Hallo.
2020-06-30 05:46:37,383 Example #1
2020-06-30 05:46:37,383 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:46:37,383 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:46:37,383 	Source:     Hi, how can I help you?
2020-06-30 05:46:37,383 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:46:37,383 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:46:37,383 Example #2
2020-06-30 05:46:37,383 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:46:37,383 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:46:37,383 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:46:37,383 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:46:37,383 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:46:37,383 Example #3
2020-06-30 05:46:37,383 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:46:37,383 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:46:37,383 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:46:37,384 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:46:37,384 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:46:37,384 Validation result (greedy) at epoch  58, step  1374000: bleu:  45.13, loss: 25220.9531, ppl:   2.6779, duration: 38.4762s
2020-06-30 05:46:41,395 Epoch  58: total training loss 16.73
2020-06-30 05:46:41,395 EPOCH 59
2020-06-30 05:46:50,711 Epoch  59 Step:  1374100 Batch Loss:     0.070041 Tokens per Sec:     4982, Lr: 0.000140
2020-06-30 05:47:04,142 Epoch  59 Step:  1374200 Batch Loss:     0.061323 Tokens per Sec:     5010, Lr: 0.000140
2020-06-30 05:47:14,233 Epoch  59: total training loss 15.50
2020-06-30 05:47:14,233 EPOCH 60
2020-06-30 05:47:17,642 Epoch  60 Step:  1374300 Batch Loss:     0.062499 Tokens per Sec:     5253, Lr: 0.000140
2020-06-30 05:47:31,390 Epoch  60 Step:  1374400 Batch Loss:     0.074693 Tokens per Sec:     4838, Lr: 0.000140
2020-06-30 05:47:44,935 Epoch  60 Step:  1374500 Batch Loss:     0.032610 Tokens per Sec:     4959, Lr: 0.000140
2020-06-30 05:47:47,067 Epoch  60: total training loss 14.71
2020-06-30 05:47:47,068 EPOCH 61
2020-06-30 05:47:58,754 Epoch  61 Step:  1374600 Batch Loss:     0.029315 Tokens per Sec:     4707, Lr: 0.000140
2020-06-30 05:48:11,841 Epoch  61 Step:  1374700 Batch Loss:     0.073930 Tokens per Sec:     5139, Lr: 0.000140
2020-06-30 05:48:20,186 Epoch  61: total training loss 14.27
2020-06-30 05:48:20,187 EPOCH 62
2020-06-30 05:48:25,772 Epoch  62 Step:  1374800 Batch Loss:     0.066548 Tokens per Sec:     4919, Lr: 0.000140
2020-06-30 05:48:39,198 Epoch  62 Step:  1374900 Batch Loss:     0.071243 Tokens per Sec:     4994, Lr: 0.000140
2020-06-30 05:48:53,086 Epoch  62 Step:  1375000 Batch Loss:     0.027811 Tokens per Sec:     4885, Lr: 0.000140
2020-06-30 05:49:32,070 Example #0
2020-06-30 05:49:32,070 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:49:32,071 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:49:32,071 	Source:     Hello.
2020-06-30 05:49:32,071 	Reference:  Hallo,
2020-06-30 05:49:32,071 	Hypothesis: Hallo.
2020-06-30 05:49:32,071 Example #1
2020-06-30 05:49:32,071 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:49:32,071 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:49:32,071 	Source:     Hi, how can I help you?
2020-06-30 05:49:32,071 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:49:32,071 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:49:32,071 Example #2
2020-06-30 05:49:32,071 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:49:32,071 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:49:32,071 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:49:32,071 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:49:32,071 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:49:32,071 Example #3
2020-06-30 05:49:32,072 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:49:32,072 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:49:32,072 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:49:32,072 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:49:32,072 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:49:32,072 Validation result (greedy) at epoch  62, step  1375000: bleu:  45.17, loss: 25096.0684, ppl:   2.6649, duration: 38.9846s
2020-06-30 05:49:32,187 Epoch  62: total training loss 13.61
2020-06-30 05:49:32,188 EPOCH 63
2020-06-30 05:49:45,752 Epoch  63 Step:  1375100 Batch Loss:     0.054191 Tokens per Sec:     4905, Lr: 0.000140
2020-06-30 05:49:59,231 Epoch  63 Step:  1375200 Batch Loss:     0.056376 Tokens per Sec:     4979, Lr: 0.000140
2020-06-30 05:50:05,437 Epoch  63: total training loss 13.63
2020-06-30 05:50:05,438 EPOCH 64
2020-06-30 05:50:13,187 Epoch  64 Step:  1375300 Batch Loss:     0.046492 Tokens per Sec:     4979, Lr: 0.000140
2020-06-30 05:50:26,635 Epoch  64 Step:  1375400 Batch Loss:     0.055734 Tokens per Sec:     5012, Lr: 0.000140
2020-06-30 05:50:38,021 Epoch  64: total training loss 13.20
2020-06-30 05:50:38,021 EPOCH 65
2020-06-30 05:50:39,955 Epoch  65 Step:  1375500 Batch Loss:     0.063278 Tokens per Sec:     5152, Lr: 0.000140
2020-06-30 05:50:54,058 Epoch  65 Step:  1375600 Batch Loss:     0.065752 Tokens per Sec:     4799, Lr: 0.000140
2020-06-30 05:51:07,170 Epoch  65 Step:  1375700 Batch Loss:     0.050612 Tokens per Sec:     5082, Lr: 0.000140
2020-06-30 05:51:11,025 Epoch  65: total training loss 13.12
2020-06-30 05:51:11,026 EPOCH 66
2020-06-30 05:51:20,443 Epoch  66 Step:  1375800 Batch Loss:     0.057495 Tokens per Sec:     5075, Lr: 0.000140
2020-06-30 05:51:34,126 Epoch  66 Step:  1375900 Batch Loss:     0.060096 Tokens per Sec:     4906, Lr: 0.000140
2020-06-30 05:51:43,814 Epoch  66: total training loss 12.95
2020-06-30 05:51:43,815 EPOCH 67
2020-06-30 05:51:47,834 Epoch  67 Step:  1376000 Batch Loss:     0.060619 Tokens per Sec:     5004, Lr: 0.000140
2020-06-30 05:52:26,059 Example #0
2020-06-30 05:52:26,060 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:52:26,060 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:52:26,060 	Source:     Hello.
2020-06-30 05:52:26,060 	Reference:  Hallo,
2020-06-30 05:52:26,060 	Hypothesis: Hallo.
2020-06-30 05:52:26,060 Example #1
2020-06-30 05:52:26,060 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:52:26,060 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:52:26,060 	Source:     Hi, how can I help you?
2020-06-30 05:52:26,060 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:52:26,061 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:52:26,061 Example #2
2020-06-30 05:52:26,061 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:52:26,061 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'M@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:52:26,061 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:52:26,061 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:52:26,061 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall in San Francisco, Kalifornien.
2020-06-30 05:52:26,061 Example #3
2020-06-30 05:52:26,061 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:52:26,061 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:52:26,061 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:52:26,061 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:52:26,061 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:52:26,061 Validation result (greedy) at epoch  67, step  1376000: bleu:  45.26, loss: 25466.7480, ppl:   2.7037, duration: 38.2268s
2020-06-30 05:52:39,511 Epoch  67 Step:  1376100 Batch Loss:     0.052721 Tokens per Sec:     4913, Lr: 0.000140
2020-06-30 05:52:53,012 Epoch  67 Step:  1376200 Batch Loss:     0.058387 Tokens per Sec:     5090, Lr: 0.000140
2020-06-30 05:52:55,136 Epoch  67: total training loss 12.93
2020-06-30 05:52:55,137 EPOCH 68
2020-06-30 05:53:07,004 Epoch  68 Step:  1376300 Batch Loss:     0.047297 Tokens per Sec:     4844, Lr: 0.000140
2020-06-30 05:53:20,254 Epoch  68 Step:  1376400 Batch Loss:     0.064875 Tokens per Sec:     5088, Lr: 0.000140
2020-06-30 05:53:28,087 Epoch  68: total training loss 12.91
2020-06-30 05:53:28,088 EPOCH 69
2020-06-30 05:53:34,175 Epoch  69 Step:  1376500 Batch Loss:     0.053419 Tokens per Sec:     4838, Lr: 0.000140
2020-06-30 05:53:48,960 Epoch  69 Step:  1376600 Batch Loss:     0.055523 Tokens per Sec:     4554, Lr: 0.000140
2020-06-30 05:54:02,872 Epoch  69 Step:  1376700 Batch Loss:     0.057862 Tokens per Sec:     4757, Lr: 0.000140
2020-06-30 05:54:02,873 Epoch  69: total training loss 12.60
2020-06-30 05:54:02,873 EPOCH 70
2020-06-30 05:54:17,856 Epoch  70 Step:  1376800 Batch Loss:     0.045902 Tokens per Sec:     4567, Lr: 0.000140
2020-06-30 05:54:32,155 Epoch  70 Step:  1376900 Batch Loss:     0.051381 Tokens per Sec:     4727, Lr: 0.000140
2020-06-30 05:54:37,777 Epoch  70: total training loss 12.40
2020-06-30 05:54:37,777 EPOCH 71
2020-06-30 05:54:46,231 Epoch  71 Step:  1377000 Batch Loss:     0.057590 Tokens per Sec:     4801, Lr: 0.000140
2020-06-30 05:55:24,359 Example #0
2020-06-30 05:55:24,359 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:55:24,359 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:55:24,359 	Source:     Hello.
2020-06-30 05:55:24,359 	Reference:  Hallo,
2020-06-30 05:55:24,360 	Hypothesis: Hallo.
2020-06-30 05:55:24,360 Example #1
2020-06-30 05:55:24,360 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:55:24,360 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:55:24,360 	Source:     Hi, how can I help you?
2020-06-30 05:55:24,360 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:55:24,360 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:55:24,360 Example #2
2020-06-30 05:55:24,360 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:55:24,360 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:55:24,360 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:55:24,360 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:55:24,360 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:55:24,360 Example #3
2020-06-30 05:55:24,360 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:55:24,360 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:55:24,360 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:55:24,360 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:55:24,360 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:55:24,360 Validation result (greedy) at epoch  71, step  1377000: bleu:  45.02, loss: 25869.6777, ppl:   2.7466, duration: 38.1274s
2020-06-30 05:55:38,797 Epoch  71 Step:  1377100 Batch Loss:     0.052552 Tokens per Sec:     4698, Lr: 0.000140
2020-06-30 05:55:50,494 Epoch  71: total training loss 12.01
2020-06-30 05:55:50,494 EPOCH 72
2020-06-30 05:55:53,450 Epoch  72 Step:  1377200 Batch Loss:     0.036419 Tokens per Sec:     4342, Lr: 0.000140
2020-06-30 05:56:07,823 Epoch  72 Step:  1377300 Batch Loss:     0.047322 Tokens per Sec:     4677, Lr: 0.000140
2020-06-30 05:56:22,132 Epoch  72 Step:  1377400 Batch Loss:     0.052874 Tokens per Sec:     4736, Lr: 0.000140
2020-06-30 05:56:25,292 Epoch  72: total training loss 11.88
2020-06-30 05:56:25,292 EPOCH 73
2020-06-30 05:56:36,368 Epoch  73 Step:  1377500 Batch Loss:     0.062208 Tokens per Sec:     4608, Lr: 0.000140
2020-06-30 05:56:50,663 Epoch  73 Step:  1377600 Batch Loss:     0.050557 Tokens per Sec:     4726, Lr: 0.000140
2020-06-30 05:56:59,998 Epoch  73: total training loss 11.88
2020-06-30 05:56:59,998 EPOCH 74
2020-06-30 05:57:04,821 Epoch  74 Step:  1377700 Batch Loss:     0.050775 Tokens per Sec:     5053, Lr: 0.000140
2020-06-30 05:57:19,651 Epoch  74 Step:  1377800 Batch Loss:     0.060692 Tokens per Sec:     4557, Lr: 0.000140
2020-06-30 05:57:33,804 Epoch  74 Step:  1377900 Batch Loss:     0.059904 Tokens per Sec:     4769, Lr: 0.000140
2020-06-30 05:57:34,624 Epoch  74: total training loss 11.94
2020-06-30 05:57:34,624 EPOCH 75
2020-06-30 05:57:48,005 Epoch  75 Step:  1378000 Batch Loss:     0.055236 Tokens per Sec:     4714, Lr: 0.000140
2020-06-30 05:58:27,052 Example #0
2020-06-30 05:58:27,053 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 05:58:27,053 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 05:58:27,053 	Source:     Hello.
2020-06-30 05:58:27,053 	Reference:  Hallo,
2020-06-30 05:58:27,053 	Hypothesis: Hallo.
2020-06-30 05:58:27,053 Example #1
2020-06-30 05:58:27,053 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 05:58:27,053 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 05:58:27,053 	Source:     Hi, how can I help you?
2020-06-30 05:58:27,053 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:58:27,053 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 05:58:27,053 Example #2
2020-06-30 05:58:27,053 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 05:58:27,053 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 05:58:27,053 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 05:58:27,053 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 05:58:27,053 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 05:58:27,053 Example #3
2020-06-30 05:58:27,053 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 05:58:27,053 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 05:58:27,053 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 05:58:27,053 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 05:58:27,053 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 05:58:27,053 Validation result (greedy) at epoch  75, step  1378000: bleu:  45.12, loss: 25733.1465, ppl:   2.7320, duration: 39.0470s
2020-06-30 05:58:41,526 Epoch  75 Step:  1378100 Batch Loss:     0.055702 Tokens per Sec:     4721, Lr: 0.000140
2020-06-30 05:58:48,421 Epoch  75: total training loss 11.62
2020-06-30 05:58:48,421 EPOCH 76
2020-06-30 05:58:55,972 Epoch  76 Step:  1378200 Batch Loss:     0.034157 Tokens per Sec:     4823, Lr: 0.000140
2020-06-30 05:59:10,466 Epoch  76 Step:  1378300 Batch Loss:     0.059064 Tokens per Sec:     4672, Lr: 0.000140
2020-06-30 05:59:23,682 Epoch  76: total training loss 11.94
2020-06-30 05:59:23,683 EPOCH 77
2020-06-30 05:59:25,336 Epoch  77 Step:  1378400 Batch Loss:     0.038122 Tokens per Sec:     4359, Lr: 0.000140
2020-06-30 05:59:40,079 Epoch  77 Step:  1378500 Batch Loss:     0.048127 Tokens per Sec:     4621, Lr: 0.000140
2020-06-30 05:59:54,574 Epoch  77 Step:  1378600 Batch Loss:     0.050799 Tokens per Sec:     4675, Lr: 0.000140
2020-06-30 05:59:58,736 Epoch  77: total training loss 11.33
2020-06-30 05:59:58,736 EPOCH 78
2020-06-30 06:00:09,386 Epoch  78 Step:  1378700 Batch Loss:     0.062304 Tokens per Sec:     4556, Lr: 0.000140
2020-06-30 06:00:24,220 Epoch  78 Step:  1378800 Batch Loss:     0.036913 Tokens per Sec:     4566, Lr: 0.000140
2020-06-30 06:00:33,518 Epoch  78: total training loss 11.28
2020-06-30 06:00:33,519 EPOCH 79
2020-06-30 06:00:37,718 Epoch  79 Step:  1378900 Batch Loss:     0.049828 Tokens per Sec:     4699, Lr: 0.000140
2020-06-30 06:00:51,284 Epoch  79 Step:  1379000 Batch Loss:     0.046559 Tokens per Sec:     4952, Lr: 0.000140
2020-06-30 06:01:30,317 Example #0
2020-06-30 06:01:30,317 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 06:01:30,317 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 06:01:30,317 	Source:     Hello.
2020-06-30 06:01:30,318 	Reference:  Hallo,
2020-06-30 06:01:30,318 	Hypothesis: Hallo.
2020-06-30 06:01:30,318 Example #1
2020-06-30 06:01:30,318 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 06:01:30,318 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 06:01:30,318 	Source:     Hi, how can I help you?
2020-06-30 06:01:30,318 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:01:30,318 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:01:30,318 Example #2
2020-06-30 06:01:30,318 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 06:01:30,318 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 06:01:30,318 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 06:01:30,318 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 06:01:30,318 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 06:01:30,318 Example #3
2020-06-30 06:01:30,318 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 06:01:30,318 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 06:01:30,318 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 06:01:30,318 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 06:01:30,318 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 06:01:30,319 Validation result (greedy) at epoch  79, step  1379000: bleu:  45.29, loss: 25923.6484, ppl:   2.7524, duration: 39.0334s
2020-06-30 06:01:43,663 Epoch  79 Step:  1379100 Batch Loss:     0.042083 Tokens per Sec:     5070, Lr: 0.000140
2020-06-30 06:01:45,280 Epoch  79: total training loss 11.17
2020-06-30 06:01:45,280 EPOCH 80
2020-06-30 06:01:57,128 Epoch  80 Step:  1379200 Batch Loss:     0.031961 Tokens per Sec:     4974, Lr: 0.000140
2020-06-30 06:02:11,329 Epoch  80 Step:  1379300 Batch Loss:     0.044399 Tokens per Sec:     4753, Lr: 0.000140
2020-06-30 06:02:18,834 Epoch  80: total training loss 11.07
2020-06-30 06:02:18,835 EPOCH 81
2020-06-30 06:02:25,150 Epoch  81 Step:  1379400 Batch Loss:     0.049665 Tokens per Sec:     5027, Lr: 0.000140
2020-06-30 06:02:38,571 Epoch  81 Step:  1379500 Batch Loss:     0.047574 Tokens per Sec:     5044, Lr: 0.000140
2020-06-30 06:02:52,224 Epoch  81: total training loss 10.84
2020-06-30 06:02:52,224 EPOCH 82
2020-06-30 06:02:53,018 Epoch  82 Step:  1379600 Batch Loss:     0.033286 Tokens per Sec:     4662, Lr: 0.000140
2020-06-30 06:03:07,395 Epoch  82 Step:  1379700 Batch Loss:     0.061773 Tokens per Sec:     4587, Lr: 0.000140
2020-06-30 06:03:21,006 Epoch  82 Step:  1379800 Batch Loss:     0.054698 Tokens per Sec:     4983, Lr: 0.000140
2020-06-30 06:03:26,147 Epoch  82: total training loss 10.95
2020-06-30 06:03:26,147 EPOCH 83
2020-06-30 06:03:34,347 Epoch  83 Step:  1379900 Batch Loss:     0.044607 Tokens per Sec:     5203, Lr: 0.000140
2020-06-30 06:03:48,197 Epoch  83 Step:  1380000 Batch Loss:     0.049176 Tokens per Sec:     4862, Lr: 0.000140
2020-06-30 06:04:27,092 Example #0
2020-06-30 06:04:27,093 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 06:04:27,093 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 06:04:27,093 	Source:     Hello.
2020-06-30 06:04:27,093 	Reference:  Hallo,
2020-06-30 06:04:27,093 	Hypothesis: Hallo.
2020-06-30 06:04:27,093 Example #1
2020-06-30 06:04:27,093 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 06:04:27,093 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 06:04:27,093 	Source:     Hi, how can I help you?
2020-06-30 06:04:27,093 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:04:27,093 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:04:27,093 Example #2
2020-06-30 06:04:27,093 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 06:04:27,093 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 06:04:27,093 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 06:04:27,093 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 06:04:27,093 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 06:04:27,093 Example #3
2020-06-30 06:04:27,093 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 06:04:27,093 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 06:04:27,093 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 06:04:27,093 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 06:04:27,093 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 06:04:27,093 Validation result (greedy) at epoch  83, step  1380000: bleu:  45.04, loss: 25925.4824, ppl:   2.7526, duration: 38.8955s
2020-06-30 06:04:38,104 Epoch  83: total training loss 10.61
2020-06-30 06:04:38,105 EPOCH 84
2020-06-30 06:04:40,783 Epoch  84 Step:  1380100 Batch Loss:     0.040593 Tokens per Sec:     4665, Lr: 0.000140
2020-06-30 06:04:54,227 Epoch  84 Step:  1380200 Batch Loss:     0.040433 Tokens per Sec:     5054, Lr: 0.000140
2020-06-30 06:05:08,003 Epoch  84 Step:  1380300 Batch Loss:     0.038616 Tokens per Sec:     4839, Lr: 0.000140
2020-06-30 06:05:10,984 Epoch  84: total training loss 10.58
2020-06-30 06:05:10,985 EPOCH 85
2020-06-30 06:05:21,499 Epoch  85 Step:  1380400 Batch Loss:     0.046094 Tokens per Sec:     4947, Lr: 0.000140
2020-06-30 06:05:34,938 Epoch  85 Step:  1380500 Batch Loss:     0.031282 Tokens per Sec:     5031, Lr: 0.000140
2020-06-30 06:05:43,758 Epoch  85: total training loss 10.37
2020-06-30 06:05:43,759 EPOCH 86
2020-06-30 06:05:48,055 Epoch  86 Step:  1380600 Batch Loss:     0.042855 Tokens per Sec:     5432, Lr: 0.000140
2020-06-30 06:06:01,612 Epoch  86 Step:  1380700 Batch Loss:     0.049168 Tokens per Sec:     4985, Lr: 0.000140
2020-06-30 06:06:15,309 Epoch  86 Step:  1380800 Batch Loss:     0.041812 Tokens per Sec:     4951, Lr: 0.000140
2020-06-30 06:06:16,218 Epoch  86: total training loss 10.09
2020-06-30 06:06:16,219 EPOCH 87
2020-06-30 06:06:28,617 Epoch  87 Step:  1380900 Batch Loss:     0.047901 Tokens per Sec:     5092, Lr: 0.000140
2020-06-30 06:06:42,459 Epoch  87 Step:  1381000 Batch Loss:     0.039799 Tokens per Sec:     4889, Lr: 0.000140
2020-06-30 06:07:21,743 Example #0
2020-06-30 06:07:21,743 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 06:07:21,743 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 06:07:21,743 	Source:     Hello.
2020-06-30 06:07:21,743 	Reference:  Hallo,
2020-06-30 06:07:21,743 	Hypothesis: Hallo.
2020-06-30 06:07:21,743 Example #1
2020-06-30 06:07:21,744 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 06:07:21,744 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 06:07:21,744 	Source:     Hi, how can I help you?
2020-06-30 06:07:21,744 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:07:21,744 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:07:21,744 Example #2
2020-06-30 06:07:21,744 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 06:07:21,744 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 06:07:21,744 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 06:07:21,744 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 06:07:21,744 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 06:07:21,744 Example #3
2020-06-30 06:07:21,744 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 06:07:21,744 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 06:07:21,744 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 06:07:21,744 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 06:07:21,744 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 06:07:21,744 Validation result (greedy) at epoch  87, step  1381000: bleu:  45.05, loss: 26079.2617, ppl:   2.7692, duration: 39.2844s
2020-06-30 06:07:28,498 Epoch  87: total training loss 10.06
2020-06-30 06:07:28,498 EPOCH 88
2020-06-30 06:07:35,518 Epoch  88 Step:  1381100 Batch Loss:     0.045641 Tokens per Sec:     4973, Lr: 0.000140
2020-06-30 06:07:49,421 Epoch  88 Step:  1381200 Batch Loss:     0.048701 Tokens per Sec:     4836, Lr: 0.000140
2020-06-30 06:08:01,270 Epoch  88: total training loss 10.11
2020-06-30 06:08:01,271 EPOCH 89
2020-06-30 06:08:02,774 Epoch  89 Step:  1381300 Batch Loss:     0.029958 Tokens per Sec:     3809, Lr: 0.000140
2020-06-30 06:08:16,304 Epoch  89 Step:  1381400 Batch Loss:     0.042838 Tokens per Sec:     5078, Lr: 0.000140
2020-06-30 06:08:30,270 Epoch  89 Step:  1381500 Batch Loss:     0.036756 Tokens per Sec:     4815, Lr: 0.000140
2020-06-30 06:08:34,348 Epoch  89: total training loss 9.93
2020-06-30 06:08:34,348 EPOCH 90
2020-06-30 06:08:43,772 Epoch  90 Step:  1381600 Batch Loss:     0.037087 Tokens per Sec:     4916, Lr: 0.000140
2020-06-30 06:08:57,595 Epoch  90 Step:  1381700 Batch Loss:     0.038683 Tokens per Sec:     4836, Lr: 0.000140
2020-06-30 06:09:07,338 Epoch  90: total training loss 9.91
2020-06-30 06:09:07,339 EPOCH 91
2020-06-30 06:09:10,871 Epoch  91 Step:  1381800 Batch Loss:     0.037851 Tokens per Sec:     4877, Lr: 0.000140
2020-06-30 06:09:24,884 Epoch  91 Step:  1381900 Batch Loss:     0.035389 Tokens per Sec:     4827, Lr: 0.000140
2020-06-30 06:09:38,134 Epoch  91 Step:  1382000 Batch Loss:     0.034634 Tokens per Sec:     5141, Lr: 0.000140
2020-06-30 06:10:17,956 Example #0
2020-06-30 06:10:17,957 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 06:10:17,957 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 06:10:17,957 	Source:     Hello.
2020-06-30 06:10:17,957 	Reference:  Hallo,
2020-06-30 06:10:17,957 	Hypothesis: Hallo.
2020-06-30 06:10:17,957 Example #1
2020-06-30 06:10:17,957 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 06:10:17,957 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 06:10:17,957 	Source:     Hi, how can I help you?
2020-06-30 06:10:17,957 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:10:17,957 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:10:17,957 Example #2
2020-06-30 06:10:17,957 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 06:10:17,957 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 06:10:17,957 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 06:10:17,957 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 06:10:17,957 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 06:10:17,957 Example #3
2020-06-30 06:10:17,957 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 06:10:17,957 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 06:10:17,957 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 06:10:17,957 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 06:10:17,957 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 06:10:17,957 Validation result (greedy) at epoch  91, step  1382000: bleu:  44.71, loss: 26372.1250, ppl:   2.8011, duration: 39.8222s
2020-06-30 06:10:20,333 Epoch  91: total training loss 9.90
2020-06-30 06:10:20,334 EPOCH 92
2020-06-30 06:10:31,796 Epoch  92 Step:  1382100 Batch Loss:     0.041444 Tokens per Sec:     4977, Lr: 0.000140
2020-06-30 06:10:45,293 Epoch  92 Step:  1382200 Batch Loss:     0.036561 Tokens per Sec:     4918, Lr: 0.000140
2020-06-30 06:10:53,377 Epoch  92: total training loss 9.91
2020-06-30 06:10:53,377 EPOCH 93
2020-06-30 06:10:59,279 Epoch  93 Step:  1382300 Batch Loss:     0.047921 Tokens per Sec:     4901, Lr: 0.000140
2020-06-30 06:11:12,660 Epoch  93 Step:  1382400 Batch Loss:     0.032828 Tokens per Sec:     5054, Lr: 0.000140
2020-06-30 06:11:26,103 Epoch  93: total training loss 9.52
2020-06-30 06:11:26,103 EPOCH 94
2020-06-30 06:11:26,215 Epoch  94 Step:  1382500 Batch Loss:     0.042561 Tokens per Sec:     6158, Lr: 0.000140
2020-06-30 06:11:39,863 Epoch  94 Step:  1382600 Batch Loss:     0.041392 Tokens per Sec:     4914, Lr: 0.000140
2020-06-30 06:11:53,692 Epoch  94 Step:  1382700 Batch Loss:     0.045504 Tokens per Sec:     4859, Lr: 0.000140
2020-06-30 06:11:59,020 Epoch  94: total training loss 9.58
2020-06-30 06:11:59,020 EPOCH 95
2020-06-30 06:12:06,890 Epoch  95 Step:  1382800 Batch Loss:     0.041945 Tokens per Sec:     5014, Lr: 0.000140
2020-06-30 06:12:20,477 Epoch  95 Step:  1382900 Batch Loss:     0.038643 Tokens per Sec:     5014, Lr: 0.000140
2020-06-30 06:12:31,751 Epoch  95: total training loss 9.35
2020-06-30 06:12:31,751 EPOCH 96
2020-06-30 06:12:34,298 Epoch  96 Step:  1383000 Batch Loss:     0.031822 Tokens per Sec:     4631, Lr: 0.000140
2020-06-30 06:13:13,184 Example #0
2020-06-30 06:13:13,185 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 06:13:13,185 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 06:13:13,185 	Source:     Hello.
2020-06-30 06:13:13,185 	Reference:  Hallo,
2020-06-30 06:13:13,185 	Hypothesis: Hallo.
2020-06-30 06:13:13,185 Example #1
2020-06-30 06:13:13,185 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 06:13:13,185 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 06:13:13,185 	Source:     Hi, how can I help you?
2020-06-30 06:13:13,185 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:13:13,185 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:13:13,185 Example #2
2020-06-30 06:13:13,185 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 06:13:13,185 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 06:13:13,185 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 06:13:13,185 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 06:13:13,185 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 06:13:13,185 Example #3
2020-06-30 06:13:13,185 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 06:13:13,185 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 06:13:13,185 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 06:13:13,185 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 06:13:13,185 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 06:13:13,185 Validation result (greedy) at epoch  96, step  1383000: bleu:  45.31, loss: 26293.5195, ppl:   2.7925, duration: 38.8869s
2020-06-30 06:13:26,514 Epoch  96 Step:  1383100 Batch Loss:     0.043282 Tokens per Sec:     5144, Lr: 0.000098
2020-06-30 06:13:40,219 Epoch  96 Step:  1383200 Batch Loss:     0.036954 Tokens per Sec:     4959, Lr: 0.000098
2020-06-30 06:13:43,507 Epoch  96: total training loss 8.96
2020-06-30 06:13:43,508 EPOCH 97
2020-06-30 06:13:53,971 Epoch  97 Step:  1383300 Batch Loss:     0.043393 Tokens per Sec:     5038, Lr: 0.000098
2020-06-30 06:14:07,334 Epoch  97 Step:  1383400 Batch Loss:     0.033880 Tokens per Sec:     5071, Lr: 0.000098
2020-06-30 06:14:16,056 Epoch  97: total training loss 8.73
2020-06-30 06:14:16,056 EPOCH 98
2020-06-30 06:14:21,110 Epoch  98 Step:  1383500 Batch Loss:     0.036944 Tokens per Sec:     5001, Lr: 0.000098
2020-06-30 06:14:34,573 Epoch  98 Step:  1383600 Batch Loss:     0.035642 Tokens per Sec:     5006, Lr: 0.000098
2020-06-30 06:14:48,121 Epoch  98 Step:  1383700 Batch Loss:     0.033907 Tokens per Sec:     4972, Lr: 0.000098
2020-06-30 06:14:48,937 Epoch  98: total training loss 8.35
2020-06-30 06:14:48,938 EPOCH 99
2020-06-30 06:15:02,025 Epoch  99 Step:  1383800 Batch Loss:     0.028007 Tokens per Sec:     4878, Lr: 0.000098
2020-06-30 06:15:15,604 Epoch  99 Step:  1383900 Batch Loss:     0.041828 Tokens per Sec:     4978, Lr: 0.000098
2020-06-30 06:15:22,013 Epoch  99: total training loss 8.28
2020-06-30 06:15:22,013 EPOCH 100
2020-06-30 06:15:28,990 Epoch 100 Step:  1384000 Batch Loss:     0.030426 Tokens per Sec:     5026, Lr: 0.000098
2020-06-30 06:16:08,363 Example #0
2020-06-30 06:16:08,363 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 06:16:08,363 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 06:16:08,363 	Source:     Hello.
2020-06-30 06:16:08,363 	Reference:  Hallo,
2020-06-30 06:16:08,363 	Hypothesis: Hallo.
2020-06-30 06:16:08,363 Example #1
2020-06-30 06:16:08,363 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 06:16:08,363 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 06:16:08,363 	Source:     Hi, how can I help you?
2020-06-30 06:16:08,363 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:16:08,363 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:16:08,363 Example #2
2020-06-30 06:16:08,363 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 06:16:08,363 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 06:16:08,363 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 06:16:08,364 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 06:16:08,364 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 06:16:08,364 Example #3
2020-06-30 06:16:08,364 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 06:16:08,364 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 06:16:08,364 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 06:16:08,364 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 06:16:08,364 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 06:16:08,364 Validation result (greedy) at epoch 100, step  1384000: bleu:  45.06, loss: 26370.2832, ppl:   2.8009, duration: 39.3729s
2020-06-30 06:16:22,103 Epoch 100 Step:  1384100 Batch Loss:     0.042402 Tokens per Sec:     4999, Lr: 0.000098
2020-06-30 06:16:34,245 Epoch 100: total training loss 8.17
2020-06-30 06:16:34,245 EPOCH 101
2020-06-30 06:16:35,749 Epoch 101 Step:  1384200 Batch Loss:     0.027364 Tokens per Sec:     5090, Lr: 0.000098
2020-06-30 06:16:49,907 Epoch 101 Step:  1384300 Batch Loss:     0.037551 Tokens per Sec:     4683, Lr: 0.000098
2020-06-30 06:17:03,334 Epoch 101 Step:  1384400 Batch Loss:     0.033616 Tokens per Sec:     5042, Lr: 0.000098
2020-06-30 06:17:07,621 Epoch 101: total training loss 8.08
2020-06-30 06:17:07,621 EPOCH 102
2020-06-30 06:17:17,175 Epoch 102 Step:  1384500 Batch Loss:     0.029263 Tokens per Sec:     4783, Lr: 0.000098
2020-06-30 06:17:30,397 Epoch 102 Step:  1384600 Batch Loss:     0.038767 Tokens per Sec:     5137, Lr: 0.000098
2020-06-30 06:17:40,699 Epoch 102: total training loss 8.21
2020-06-30 06:17:40,700 EPOCH 103
2020-06-30 06:17:44,178 Epoch 103 Step:  1384700 Batch Loss:     0.033570 Tokens per Sec:     5105, Lr: 0.000098
2020-06-30 06:17:58,117 Epoch 103 Step:  1384800 Batch Loss:     0.031942 Tokens per Sec:     4863, Lr: 0.000098
2020-06-30 06:18:11,428 Epoch 103 Step:  1384900 Batch Loss:     0.042805 Tokens per Sec:     5078, Lr: 0.000098
2020-06-30 06:18:13,467 Epoch 103: total training loss 8.23
2020-06-30 06:18:13,467 EPOCH 104
2020-06-30 06:18:24,997 Epoch 104 Step:  1385000 Batch Loss:     0.036538 Tokens per Sec:     5017, Lr: 0.000098
2020-06-30 06:19:03,792 Example #0
2020-06-30 06:19:03,793 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 06:19:03,793 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 06:19:03,793 	Source:     Hello.
2020-06-30 06:19:03,793 	Reference:  Hallo,
2020-06-30 06:19:03,793 	Hypothesis: Hallo.
2020-06-30 06:19:03,793 Example #1
2020-06-30 06:19:03,793 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 06:19:03,793 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 06:19:03,793 	Source:     Hi, how can I help you?
2020-06-30 06:19:03,793 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:19:03,793 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:19:03,793 Example #2
2020-06-30 06:19:03,794 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 06:19:03,794 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 06:19:03,794 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 06:19:03,794 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 06:19:03,794 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 06:19:03,794 Example #3
2020-06-30 06:19:03,794 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 06:19:03,794 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 06:19:03,794 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 06:19:03,794 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 06:19:03,794 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 06:19:03,794 Validation result (greedy) at epoch 104, step  1385000: bleu:  45.22, loss: 26499.1113, ppl:   2.8150, duration: 38.7965s
2020-06-30 06:19:18,050 Epoch 104 Step:  1385100 Batch Loss:     0.025529 Tokens per Sec:     4738, Lr: 0.000098
2020-06-30 06:19:25,745 Epoch 104: total training loss 7.98
2020-06-30 06:19:25,745 EPOCH 105
2020-06-30 06:19:31,834 Epoch 105 Step:  1385200 Batch Loss:     0.024383 Tokens per Sec:     4834, Lr: 0.000098
2020-06-30 06:19:46,159 Epoch 105 Step:  1385300 Batch Loss:     0.038254 Tokens per Sec:     4693, Lr: 0.000098
2020-06-30 06:20:00,262 Epoch 105: total training loss 7.94
2020-06-30 06:20:00,262 EPOCH 106
2020-06-30 06:20:00,556 Epoch 106 Step:  1385400 Batch Loss:     0.027964 Tokens per Sec:     4447, Lr: 0.000098
2020-06-30 06:20:14,979 Epoch 106 Step:  1385500 Batch Loss:     0.029647 Tokens per Sec:     4746, Lr: 0.000098
2020-06-30 06:20:29,858 Epoch 106 Step:  1385600 Batch Loss:     0.033893 Tokens per Sec:     4542, Lr: 0.000098
2020-06-30 06:20:35,233 Epoch 106: total training loss 7.74
2020-06-30 06:20:35,234 EPOCH 107
2020-06-30 06:20:44,004 Epoch 107 Step:  1385700 Batch Loss:     0.023570 Tokens per Sec:     4694, Lr: 0.000098
2020-06-30 06:20:58,316 Epoch 107 Step:  1385800 Batch Loss:     0.031096 Tokens per Sec:     4738, Lr: 0.000098
2020-06-30 06:21:09,760 Epoch 107: total training loss 7.67
2020-06-30 06:21:09,760 EPOCH 108
2020-06-30 06:21:12,534 Epoch 108 Step:  1385900 Batch Loss:     0.038284 Tokens per Sec:     4706, Lr: 0.000098
2020-06-30 06:21:26,483 Epoch 108 Step:  1386000 Batch Loss:     0.023116 Tokens per Sec:     4817, Lr: 0.000098
2020-06-30 06:22:05,930 Example #0
2020-06-30 06:22:05,930 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 06:22:05,930 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 06:22:05,930 	Source:     Hello.
2020-06-30 06:22:05,930 	Reference:  Hallo,
2020-06-30 06:22:05,930 	Hypothesis: Hallo.
2020-06-30 06:22:05,930 Example #1
2020-06-30 06:22:05,930 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 06:22:05,930 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 06:22:05,930 	Source:     Hi, how can I help you?
2020-06-30 06:22:05,930 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:22:05,930 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:22:05,930 Example #2
2020-06-30 06:22:05,930 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 06:22:05,930 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 06:22:05,930 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 06:22:05,930 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 06:22:05,930 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 06:22:05,930 Example #3
2020-06-30 06:22:05,930 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 06:22:05,931 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 06:22:05,931 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 06:22:05,931 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 06:22:05,931 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 06:22:05,931 Validation result (greedy) at epoch 108, step  1386000: bleu:  45.25, loss: 26660.9316, ppl:   2.8328, duration: 39.4468s
2020-06-30 06:22:20,679 Epoch 108 Step:  1386100 Batch Loss:     0.027975 Tokens per Sec:     4525, Lr: 0.000098
2020-06-30 06:22:23,906 Epoch 108: total training loss 7.75
2020-06-30 06:22:23,906 EPOCH 109
2020-06-30 06:22:34,590 Epoch 109 Step:  1386200 Batch Loss:     0.034511 Tokens per Sec:     4712, Lr: 0.000098
2020-06-30 06:22:49,232 Epoch 109 Step:  1386300 Batch Loss:     0.035055 Tokens per Sec:     4619, Lr: 0.000098
2020-06-30 06:22:58,946 Epoch 109: total training loss 7.58
2020-06-30 06:22:58,946 EPOCH 110
2020-06-30 06:23:03,947 Epoch 110 Step:  1386400 Batch Loss:     0.028760 Tokens per Sec:     4508, Lr: 0.000098
2020-06-30 06:23:18,280 Epoch 110 Step:  1386500 Batch Loss:     0.030148 Tokens per Sec:     4731, Lr: 0.000098
2020-06-30 06:23:32,075 Epoch 110 Step:  1386600 Batch Loss:     0.031532 Tokens per Sec:     4985, Lr: 0.000098
2020-06-30 06:23:32,911 Epoch 110: total training loss 7.54
2020-06-30 06:23:32,911 EPOCH 111
2020-06-30 06:23:45,520 Epoch 111 Step:  1386700 Batch Loss:     0.033674 Tokens per Sec:     5027, Lr: 0.000098
2020-06-30 06:23:59,658 Epoch 111 Step:  1386800 Batch Loss:     0.015137 Tokens per Sec:     4767, Lr: 0.000098
2020-06-30 06:24:06,097 Epoch 111: total training loss 7.54
2020-06-30 06:24:06,098 EPOCH 112
2020-06-30 06:24:13,383 Epoch 112 Step:  1386900 Batch Loss:     0.038243 Tokens per Sec:     4802, Lr: 0.000098
2020-06-30 06:24:27,122 Epoch 112 Step:  1387000 Batch Loss:     0.031163 Tokens per Sec:     5001, Lr: 0.000098
2020-06-30 06:25:06,742 Example #0
2020-06-30 06:25:06,742 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 06:25:06,742 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 06:25:06,742 	Source:     Hello.
2020-06-30 06:25:06,742 	Reference:  Hallo,
2020-06-30 06:25:06,742 	Hypothesis: Hallo.
2020-06-30 06:25:06,743 Example #1
2020-06-30 06:25:06,743 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 06:25:06,743 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 06:25:06,743 	Source:     Hi, how can I help you?
2020-06-30 06:25:06,743 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:25:06,743 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:25:06,743 Example #2
2020-06-30 06:25:06,743 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 06:25:06,743 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 06:25:06,743 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 06:25:06,743 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 06:25:06,743 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 06:25:06,743 Example #3
2020-06-30 06:25:06,743 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 06:25:06,743 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 06:25:06,743 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 06:25:06,743 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 06:25:06,743 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 06:25:06,743 Validation result (greedy) at epoch 112, step  1387000: bleu:  45.21, loss: 26764.4922, ppl:   2.8443, duration: 39.6200s
2020-06-30 06:25:18,549 Epoch 112: total training loss 7.46
2020-06-30 06:25:18,549 EPOCH 113
2020-06-30 06:25:20,214 Epoch 113 Step:  1387100 Batch Loss:     0.032650 Tokens per Sec:     4774, Lr: 0.000098
2020-06-30 06:25:33,496 Epoch 113 Step:  1387200 Batch Loss:     0.029070 Tokens per Sec:     5127, Lr: 0.000098
2020-06-30 06:25:47,168 Epoch 113 Step:  1387300 Batch Loss:     0.022089 Tokens per Sec:     4931, Lr: 0.000098
2020-06-30 06:25:51,393 Epoch 113: total training loss 7.48
2020-06-30 06:25:51,393 EPOCH 114
2020-06-30 06:26:00,793 Epoch 114 Step:  1387400 Batch Loss:     0.027349 Tokens per Sec:     5091, Lr: 0.000098
2020-06-30 06:26:14,953 Epoch 114 Step:  1387500 Batch Loss:     0.031114 Tokens per Sec:     4782, Lr: 0.000098
2020-06-30 06:26:24,314 Epoch 114: total training loss 7.33
2020-06-30 06:26:24,314 EPOCH 115
2020-06-30 06:26:28,334 Epoch 115 Step:  1387600 Batch Loss:     0.033486 Tokens per Sec:     5210, Lr: 0.000098
2020-06-30 06:26:42,161 Epoch 115 Step:  1387700 Batch Loss:     0.029652 Tokens per Sec:     4883, Lr: 0.000098
2020-06-30 06:26:55,222 Epoch 115 Step:  1387800 Batch Loss:     0.024995 Tokens per Sec:     5105, Lr: 0.000098
2020-06-30 06:26:57,103 Epoch 115: total training loss 7.75
2020-06-30 06:26:57,104 EPOCH 116
2020-06-30 06:27:09,218 Epoch 116 Step:  1387900 Batch Loss:     0.032724 Tokens per Sec:     4816, Lr: 0.000098
2020-06-30 06:27:22,938 Epoch 116 Step:  1388000 Batch Loss:     0.048823 Tokens per Sec:     4965, Lr: 0.000098
2020-06-30 06:28:01,733 Example #0
2020-06-30 06:28:01,733 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 06:28:01,733 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 06:28:01,733 	Source:     Hello.
2020-06-30 06:28:01,733 	Reference:  Hallo,
2020-06-30 06:28:01,734 	Hypothesis: Hallo.
2020-06-30 06:28:01,734 Example #1
2020-06-30 06:28:01,734 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 06:28:01,734 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 06:28:01,734 	Source:     Hi, how can I help you?
2020-06-30 06:28:01,734 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:28:01,734 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:28:01,734 Example #2
2020-06-30 06:28:01,734 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 06:28:01,734 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 06:28:01,734 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 06:28:01,734 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 06:28:01,734 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 06:28:01,735 Example #3
2020-06-30 06:28:01,735 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 06:28:01,735 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 06:28:01,735 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 06:28:01,735 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 06:28:01,735 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 06:28:01,735 Validation result (greedy) at epoch 116, step  1388000: bleu:  44.85, loss: 26998.8750, ppl:   2.8705, duration: 38.7956s
2020-06-30 06:28:09,190 Epoch 116: total training loss 7.60
2020-06-30 06:28:09,190 EPOCH 117
2020-06-30 06:28:15,566 Epoch 117 Step:  1388100 Batch Loss:     0.023607 Tokens per Sec:     4866, Lr: 0.000098
2020-06-30 06:28:29,079 Epoch 117 Step:  1388200 Batch Loss:     0.034119 Tokens per Sec:     5033, Lr: 0.000098
2020-06-30 06:28:42,056 Epoch 117: total training loss 7.41
2020-06-30 06:28:42,057 EPOCH 118
2020-06-30 06:28:42,503 Epoch 118 Step:  1388300 Batch Loss:     0.034059 Tokens per Sec:     6416, Lr: 0.000098
2020-06-30 06:28:56,209 Epoch 118 Step:  1388400 Batch Loss:     0.026026 Tokens per Sec:     4962, Lr: 0.000098
2020-06-30 06:29:10,110 Epoch 118 Step:  1388500 Batch Loss:     0.030453 Tokens per Sec:     4874, Lr: 0.000098
2020-06-30 06:29:14,911 Epoch 118: total training loss 7.24
2020-06-30 06:29:14,911 EPOCH 119
2020-06-30 06:29:23,686 Epoch 119 Step:  1388600 Batch Loss:     0.029705 Tokens per Sec:     4858, Lr: 0.000098
2020-06-30 06:29:37,341 Epoch 119 Step:  1388700 Batch Loss:     0.034132 Tokens per Sec:     4997, Lr: 0.000098
2020-06-30 06:29:47,771 Epoch 119: total training loss 7.20
2020-06-30 06:29:47,771 EPOCH 120
2020-06-30 06:29:50,754 Epoch 120 Step:  1388800 Batch Loss:     0.023743 Tokens per Sec:     5191, Lr: 0.000098
2020-06-30 06:30:04,327 Epoch 120 Step:  1388900 Batch Loss:     0.030874 Tokens per Sec:     5038, Lr: 0.000098
2020-06-30 06:30:18,098 Epoch 120 Step:  1389000 Batch Loss:     0.027989 Tokens per Sec:     4931, Lr: 0.000098
2020-06-30 06:30:57,739 Example #0
2020-06-30 06:30:57,740 	Raw source:     ['Hel@@', 'lo@@', '.']
2020-06-30 06:30:57,740 	Raw hypothesis: ['Hal@@', 'lo@@', '.']
2020-06-30 06:30:57,740 	Source:     Hello.
2020-06-30 06:30:57,740 	Reference:  Hallo,
2020-06-30 06:30:57,740 	Hypothesis: Hallo.
2020-06-30 06:30:57,740 Example #1
2020-06-30 06:30:57,740 	Raw source:     ['Hi@@', ',', 'how', 'can', 'I', 'help', 'you@@', '?']
2020-06-30 06:30:57,740 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'wie', 'kann', 'ich', 'Ihnen', 'hel@@', 'fen@@', '?']
2020-06-30 06:30:57,740 	Source:     Hi, how can I help you?
2020-06-30 06:30:57,740 	Reference:  Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:30:57,740 	Hypothesis: Hallo, wie kann ich Ihnen helfen?
2020-06-30 06:30:57,740 Example #2
2020-06-30 06:30:57,740 	Raw source:     ['Hi@@', ',', 'I@@', "'m", 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'Ar@@', 'den', 'Fair', 'm@@', 'all', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Califor@@', 'ni@@', 'a.']
2020-06-30 06:30:57,740 	Raw hypothesis: ['Hal@@', 'lo@@', ',', 'ich', 'suche', 'ein', 'Restaurant', 'in', 'der', 'Ar@@', 'den', 'Fair', 'Mall@@', ',', 'in', 'San', 'Franc@@', 'is@@', 'co@@', ',', 'Kalifor@@', 'ni@@', 'en@@', '.']
2020-06-30 06:30:57,740 	Source:     Hi, I'm looking for a restaurant inside the Arden Fair mall in San Francisco, California.
2020-06-30 06:30:57,740 	Reference:  Hallo, ich bin auf der Suche nach einem Restaurant im Arden Fair Einkaufszentrum in San Francisco, Kalifornien.
2020-06-30 06:30:57,740 	Hypothesis: Hallo, ich suche ein Restaurant in der Arden Fair Mall, in San Francisco, Kalifornien.
2020-06-30 06:30:57,740 Example #3
2020-06-30 06:30:57,741 	Raw source:     ['Ok@@', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for@@', '?']
2020-06-30 06:30:57,741 	Raw hypothesis: ['Ok@@', ',', 'nach', 'welcher', 'Art', 'von', 'Restaurant', 'suchen', 'Sie@@', '?']
2020-06-30 06:30:57,741 	Source:     Ok, what type of restaurant are you looking for?
2020-06-30 06:30:57,741 	Reference:  Ok. Welche Art von Restaurant suchen Sie denn genau?
2020-06-30 06:30:57,741 	Hypothesis: Ok, nach welcher Art von Restaurant suchen Sie?
2020-06-30 06:30:57,741 Validation result (greedy) at epoch 120, step  1389000: bleu:  44.91, loss: 26826.8262, ppl:   2.8513, duration: 39.6423s
2020-06-30 06:31:00,390 Epoch 120: total training loss 7.09
2020-06-30 06:31:00,391 Training ended after 120 epochs.
2020-06-30 06:31:00,391 Best validation result (greedy) at step  1365000:   2.29 ppl.
2020-06-30 06:32:08,107  dev bleu:  45.70 [Beam search decoding with beam size = 5 and alpha = 1.0]
2020-06-30 06:32:08,112 Translations saved to: models/transformer_multi_enc_ende-tune-dropout/01365000.hyps.dev
2020-06-30 06:32:40,736 test bleu:  42.42 [Beam search decoding with beam size = 5 and alpha = 1.0]
2020-06-30 06:32:40,741 Translations saved to: models/transformer_multi_enc_ende-tune-dropout/01365000.hyps.test
